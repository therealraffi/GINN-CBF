{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from copy import deepcopy\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved to: /scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/adapter/layer_sizes_2025-02-28_22-36-50_Area_1\n",
      "Check graphs at\n",
      "tensorboard --logdir /scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/adapter/layer_sizes_2025-02-28_22-36-50_Area_1\n"
     ]
    }
   ],
   "source": [
    "def get_bash_cmd(script_path, slurm_args: tuple[str, str], args: list[str]):\n",
    "    slurm_list = [\"--\" + a + \"=\"  + b for a, b in slurm_args]\n",
    "    cmd_list = [\"sbatch\"] + slurm_list + [script_path] + args\n",
    "    return cmd_list\n",
    "\n",
    "def run_cmd(cmd_list): subprocess.run(cmd_list, check=True)\n",
    "\n",
    "def run_bash_script(script_path, slurm_args: tuple[str, str], args: list[str], do_run=True):\n",
    "    cmd = get_bash_cmd(script_path, slurm_args, args)\n",
    "    print(cmd)\n",
    "    if do_run: run_cmd(cmd)\n",
    "\n",
    "def zip_dicts(global_hp_args):\n",
    "    keys = global_hp_args.keys()\n",
    "    values = zip(*global_hp_args.values())  # Transpose the values\n",
    "    return [dict(zip(keys, v)) for v in values]\n",
    "\n",
    "def iterate_in_tuples(lst, n=2):\n",
    "    it = iter(lst)\n",
    "    tuples = list(zip(*[it] * n))  # Groups elements into n-sized tuples\n",
    "    remainder = lst[len(tuples) * n:]  # Get remaining elements, if any\n",
    "    if remainder:\n",
    "        tuples.append(tuple(remainder))  # Add remainder as a smaller tuple\n",
    "    return tuples\n",
    "\n",
    "def generate_hp_permutations(global_hp_args):\n",
    "    if not global_hp_args:\n",
    "        return [{}]\n",
    "    keys, values = zip(*global_hp_args.items())  # Extract keys and value lists\n",
    "    permutations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "    return permutations\n",
    "    \n",
    "exp_name = \"layer_sizes\"\n",
    "datetime_str = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "config_folder = \"/scratch/rhm4nj/cral/cral-ginn/ginn/configs\"\n",
    "config_name = \"adapter_config.yml\"\n",
    "adapter_config_path = os.path.join(config_folder, config_name)\n",
    "\n",
    "pretrained_directory = \"/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1\"\n",
    "base_directory = \"/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/S3D/Area_1\"\n",
    "script_path = \"/scratch/rhm4nj/cral/cral-ginn/slurm_scripts/ginn_script_adapter.sh\"\n",
    "\n",
    "slurm_path = os.path.join(\n",
    "    \"/scratch/rhm4nj/cral/cral-ginn/slurm_scripts/adapter_logs\",\n",
    "    exp_name + \"_\" + datetime_str + \"_\" + base_directory.split(\"/\")[-1]\n",
    ")\n",
    "slurm_out = os.path.join(slurm_path, \"out\")\n",
    "slurm_err = os.path.join(slurm_path, \"err\")\n",
    "\n",
    "model_out = os.path.join(\n",
    "    \"/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/adapter\",  exp_name + \"_\" + datetime_str + \"_\" + base_directory.split(\"/\")[-1]\n",
    ")\n",
    "\n",
    "tensorboard_dir = os.path.join(\n",
    "    \"/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/adapter\",  exp_name + \"_\" + datetime_str + \"_\" + base_directory.split(\"/\")[-1]\n",
    ")\n",
    "\n",
    "print(\"Models saved to:\", model_out)\n",
    "print(\"Check graphs at\\ntensorboard --logdir\", tensorboard_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found for 20_table\n",
      "4_wall Using max epoch 160\n",
      "7_beam Using max epoch 100\n",
      "8_beam Using max epoch 170\n",
      "9_door Using max epoch 160\n"
     ]
    }
   ],
   "source": [
    "config_name = \"config.yml\"\n",
    "target_epoch = 200\n",
    "\n",
    "pretrained_models = []\n",
    "config_paths = []\n",
    "obj_names = []\n",
    "\n",
    "for dirname in sorted(os.listdir(pretrained_directory)):\n",
    "    dir_path = os.path.join(pretrained_directory, dirname)\n",
    "    config_path = \"\"\n",
    "    model_path = \"\"\n",
    "    model_max_path = \"\"\n",
    "    max_epoch = 0\n",
    "\n",
    "    for root, _, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            if file == config_name:\n",
    "                config_path = os.path.join(root, config_name)\n",
    "            \n",
    "            if \".pth\" not in file: continue \n",
    "            try:\n",
    "                epoch = int(file.split(\"_\")[-1].split(\".\")[0])\n",
    "            except:\n",
    "                print(\"Invalid file name:\", file)\n",
    "                continue\n",
    "            \n",
    "            if epoch == target_epoch:\n",
    "                model_path = os.path.join(root, file)\n",
    "                break\n",
    "\n",
    "            if epoch > max_epoch:\n",
    "                model_max_path = os.path.join(root, file)\n",
    "                max_epoch = epoch\n",
    "\n",
    "    if not model_path:\n",
    "        if max_epoch:\n",
    "            print(dirname, \"Using max epoch\", max_epoch)\n",
    "            model_path = model_max_path\n",
    "    \n",
    "    if not (model_path and config_path):\n",
    "        print(\"Nothing found for\", dirname)\n",
    "        continue\n",
    "\n",
    "    pretrained_models.append(model_path)\n",
    "    config_paths.append(config_path)\n",
    "    obj_names.append(dirname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sbatch', '--output=/scratch/rhm4nj/cral/cral-ginn/slurm_scripts/adapter_logs/layer_sizes_2025-02-28_22-36-50_Area_1/out/[512, 256, 256, 1]_[512, 256, 128, 1]_[256, 128, 64, 1]_output_%a.out', '--error=/scratch/rhm4nj/cral/cral-ginn/slurm_scripts/adapter_logs/layer_sizes_2025-02-28_22-36-50_Area_1/err/[512, 256, 256, 1]_[512, 256, 128, 1]_[256, 128, 64, 1]_error_%a.err', '--job-name=[512, 256, 256, 1]_[512, 256, 128, 1]_[256, 128, 64, 1]', '--array=0-2', '/scratch/rhm4nj/cral/cral-ginn/slurm_scripts/ginn_script_adapter.sh', '/scratch/rhm4nj/cral/cral-ginn/ginn/configs/adapter_config.yml', 'siren_config_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/config.yml;pretrained_siren_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/cond_siren/2025_02_24-11_55_43/2025_02_24-11_55_45-zj2kjfib_200.pth;obj_name:22_table;adapter_mid_layers:[512, 256, 256, 1];model_save_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[512, 256, 256, 1];tensorboard_log_dir:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[512, 256, 256, 1]', 'siren_config_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/config.yml;pretrained_siren_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/cond_siren/2025_02_24-11_55_43/2025_02_24-11_55_45-zj2kjfib_200.pth;obj_name:22_table;adapter_mid_layers:[512, 256, 128, 1];model_save_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[512, 256, 128, 1];tensorboard_log_dir:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[512, 256, 128, 1]', 'siren_config_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/config.yml;pretrained_siren_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/cond_siren/2025_02_24-11_55_43/2025_02_24-11_55_45-zj2kjfib_200.pth;obj_name:22_table;adapter_mid_layers:[256, 128, 64, 1];model_save_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[256, 128, 64, 1];tensorboard_log_dir:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[256, 128, 64, 1]']\n",
      "Submitted batch job 2654694\n",
      "['sbatch', '--output=/scratch/rhm4nj/cral/cral-ginn/slurm_scripts/adapter_logs/layer_sizes_2025-02-28_22-36-50_Area_1/out/[512, 128, 1]_[256, 128, 1]_[256, 256, 1]_output_%a.out', '--error=/scratch/rhm4nj/cral/cral-ginn/slurm_scripts/adapter_logs/layer_sizes_2025-02-28_22-36-50_Area_1/err/[512, 128, 1]_[256, 128, 1]_[256, 256, 1]_error_%a.err', '--job-name=[512, 128, 1]_[256, 128, 1]_[256, 256, 1]', '--array=0-2', '/scratch/rhm4nj/cral/cral-ginn/slurm_scripts/ginn_script_adapter.sh', '/scratch/rhm4nj/cral/cral-ginn/ginn/configs/adapter_config.yml', 'siren_config_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/config.yml;pretrained_siren_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/cond_siren/2025_02_24-11_55_43/2025_02_24-11_55_45-zj2kjfib_200.pth;obj_name:22_table;adapter_mid_layers:[512, 128, 1];model_save_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[512, 128, 1];tensorboard_log_dir:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[512, 128, 1]', 'siren_config_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/config.yml;pretrained_siren_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/cond_siren/2025_02_24-11_55_43/2025_02_24-11_55_45-zj2kjfib_200.pth;obj_name:22_table;adapter_mid_layers:[256, 128, 1];model_save_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[256, 128, 1];tensorboard_log_dir:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[256, 128, 1]', 'siren_config_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/config.yml;pretrained_siren_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/cond_siren/2025_02_24-11_55_43/2025_02_24-11_55_45-zj2kjfib_200.pth;obj_name:22_table;adapter_mid_layers:[256, 256, 1];model_save_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[256, 256, 1];tensorboard_log_dir:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[256, 256, 1]']\n",
      "Submitted batch job 2654695\n",
      "['sbatch', '--output=/scratch/rhm4nj/cral/cral-ginn/slurm_scripts/adapter_logs/layer_sizes_2025-02-28_22-36-50_Area_1/out/[128, 64, 1]_[256, 1]_output_%a.out', '--error=/scratch/rhm4nj/cral/cral-ginn/slurm_scripts/adapter_logs/layer_sizes_2025-02-28_22-36-50_Area_1/err/[128, 64, 1]_[256, 1]_error_%a.err', '--job-name=[128, 64, 1]_[256, 1]', '--array=0-1', '/scratch/rhm4nj/cral/cral-ginn/slurm_scripts/ginn_script_adapter.sh', '/scratch/rhm4nj/cral/cral-ginn/ginn/configs/adapter_config.yml', 'siren_config_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/config.yml;pretrained_siren_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/cond_siren/2025_02_24-11_55_43/2025_02_24-11_55_45-zj2kjfib_200.pth;obj_name:22_table;adapter_mid_layers:[128, 64, 1];model_save_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[128, 64, 1];tensorboard_log_dir:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[128, 64, 1]', 'siren_config_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/config.yml;pretrained_siren_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-02-24_11-27-03_Area_1/22_table/cond_siren/2025_02_24-11_55_43/2025_02_24-11_55_45-zj2kjfib_200.pth;obj_name:22_table;adapter_mid_layers:[256, 1];model_save_path:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[256, 1];tensorboard_log_dir:/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/adapter/layer_sizes_2025-02-28_22-36-50_Area_1/[256, 1]']\n",
      "Submitted batch job 2654696\n",
      "Individual: 8\n",
      "Total Calls: 3\n",
      "Classes ['22_table']\n"
     ]
    }
   ],
   "source": [
    "group_size = 3\n",
    "n_groups = 100\n",
    "class_start_idx = 13\n",
    "class_end_idx = 14\n",
    "skip_names = [\"activation_name\", \"obj_name\", \"adapter_mid_layers\"]\n",
    "tag_keys = [\"lambda_lie_norm\", \"lambda_control\", \"lambda_descent\", \"lambda_recon\", \"activation_name\", \"adapter_mid_layers\"]\n",
    "do_perm = True\n",
    "abbrv = False\n",
    "do_run = True\n",
    "\n",
    "if do_run:\n",
    "    if not os.path.exists(slurm_out):\n",
    "        os.makedirs(slurm_out)\n",
    "    if not os.path.exists(slurm_err):\n",
    "        os.makedirs(slurm_err)\n",
    "    if not os.path.exists(model_out):\n",
    "        os.makedirs(model_out)\n",
    "\n",
    "\n",
    "global_hp_args = {\n",
    "    \"siren_config_path\": config_paths[class_start_idx:class_end_idx],\n",
    "    \"pretrained_siren_path\": pretrained_models[class_start_idx:class_end_idx],\n",
    "    \"obj_name\": obj_names[class_start_idx:class_end_idx],\n",
    "    # \"lambda_recon\": [0.25, 0.5, 1],\n",
    "    # \"lambda_descent\": [0.5, 1],\n",
    "    # \"lambda_control\": [1.0e-1],\n",
    "    # \"lambda_lie_norm\": [1.0e-3, 1.0e-2],\n",
    "    # \"activation_name\": ['tanh', 'gelu', 'relu', 'leaky_relu', 'softplus']\n",
    "    # \"activation_name\": ['leaky_relu', 'gelu']\n",
    "    \"adapter_mid_layers\": [[512, 256, 256, 1], [512, 256, 128, 1], [256, 128, 64, 1], [512, 128, 1], [256, 128, 1], \n",
    "        [256, 256, 1], [128, 64, 1], [256, 1]\n",
    "    ]\n",
    "}\n",
    "\n",
    "if do_perm:\n",
    "    # do permutations\n",
    "    hp_permutations = generate_hp_permutations(global_hp_args)\n",
    "    for i, perm in enumerate(hp_permutations):\n",
    "        for key in perm:\n",
    "            if isinstance(perm[key], float):\n",
    "                hp_permutations[i][key] = format(perm[key], \".10f\").rstrip('0').rstrip('.')  # Adjust decimal places as needed\n",
    "else:\n",
    "    # do tuples\n",
    "    hp_permutations = zip_dicts(global_hp_args)\n",
    "\n",
    "if abbrv:\n",
    "    tag_keys_abrv = {key: ''.join([k[0] for k in key.split(\"_\")]) for key in global_hp_args.keys()}\n",
    "else:\n",
    "    tag_keys_abrv = {key: key for key in global_hp_args.keys()}\n",
    "\n",
    "if len(hp_permutations) > 100:\n",
    "    print(\"ARE YOU SURE about\", len(hp_permutations), \"runs?\")\n",
    "else:\n",
    "    hp_strs = []\n",
    "    tags = []\n",
    "    for k, hp_args in enumerate(hp_permutations):\n",
    "        if len(global_hp_args) >= 1: \n",
    "            for key, val in hp_args.items():\n",
    "                if not tag_keys: \n",
    "                    tag_keys = [k for k in global_hp_args]\n",
    "                tag = '_'.join([tag_keys_abrv[key] + \"_\" + str(val) for key, val in hp_args.items() if key in tag_keys])\n",
    "                for name in skip_names:\n",
    "                    if abbrv:\n",
    "                        tag = tag.replace(tag_keys_abrv[name] + \"_\", \"\")\n",
    "                    else:\n",
    "                        tag = tag.replace(name + \"_\", \"\")\n",
    "\n",
    "        else: \n",
    "            tag = datetime_str\n",
    "        \n",
    "        hp_args[\"model_save_path\"] = os.path.join(model_out, tag)\n",
    "        hp_args[\"tensorboard_log_dir\"] = os.path.join(tensorboard_dir, tag)\n",
    "        hp_str = ';'.join([key + \":\" + str(val) for key, val in hp_args.items()])\n",
    "\n",
    "        hp_strs.append(hp_str)\n",
    "        tags.append(tag)\n",
    "            \n",
    "    hp_strs_groups = iterate_in_tuples(hp_strs, n=group_size)[:n_groups]\n",
    "    tag_groups = iterate_in_tuples(tags, n=group_size)[:n_groups]\n",
    "\n",
    "    for tag_group, hp_strs_group in zip(tag_groups, hp_strs_groups):\n",
    "        job_name = \"_\".join(tag_group)\n",
    "        my_slurm_err = os.path.join(slurm_err, job_name + f\"_error_%a.err\")\n",
    "        my_slurm_out = os.path.join(slurm_out, job_name + f\"_output_%a.out\")\n",
    "        array_str = \"0\"\n",
    "        if len(tag_group) > 1: \n",
    "            array_str += \"-\" + str(len(hp_strs_group) - 1)\n",
    "        \n",
    "        run_bash_script(script_path, \n",
    "            slurm_args=[(\"output\", my_slurm_out), (\"error\", my_slurm_err), (\"job-name\", job_name), (\"array\", array_str)], \n",
    "            args=[adapter_config_path] + list(hp_strs_group),\n",
    "            do_run=do_run\n",
    "        )\n",
    "\n",
    "    print(\"Individual:\", len(hp_strs))\n",
    "    print(\"Total Calls:\", len(hp_strs_groups))\n",
    "\n",
    "print(\"Classes\", obj_names[class_start_idx:class_end_idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ginn_env11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
