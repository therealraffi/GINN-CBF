{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sfs/weka/scratch/rhm4nj/cral/cral-ginn/ginn/neural_clbf/neural_clbf/systems/f16.py:22: UserWarning: Could not import F16 module; is AeroBench installed?\n",
      "  warn(\"Could not import F16 module; is AeroBench installed?\")\n",
      "/home/rhm4nj/.local/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/sfs/weka/scratch/rhm4nj/cral/cral-ginn/ginn/neural_clbf/neural_clbf/experiments/__init__.py:44: UserWarning: Could not import HW module; is ROS installed?\n",
      "  warn(\"Could not import HW module; is ROS installed?\")\n"
     ]
    }
   ],
   "source": [
    "# standard library\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "from itertools import cycle\n",
    "\n",
    "# scientific / data\n",
    "import numpy as np\n",
    "import torch\n",
    "import trimesh\n",
    "import networkx as nx\n",
    "\n",
    "# plotting / widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import k3d\n",
    "\n",
    "# progress bars\n",
    "from tqdm.notebook import tqdm  # or `from tqdm import tqdm` if you prefer the console version\n",
    "\n",
    "# SciPy / sklearn\n",
    "from scipy.spatial import cKDTree, ConvexHull, Delaunay\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# your neural-CBF system\n",
    "from neural_clbf.systems import ControlAffineSystem\n",
    "from neural_clbf.controllers.cbf_controller import CBFController\n",
    "from neural_clbf.controllers.controller_utils import normalize_with_angles\n",
    "from neural_clbf.datamodules.episodic_datamodule import EpisodicDataModule\n",
    "from neural_clbf.experiments import ExperimentSuite\n",
    "\n",
    "from configs.get_config import get_config_from_yml\n",
    "from GINN.shape_boundary_helper import ShapeBoundaryHelper\n",
    "from GINN.helpers.mp_manager import MPManager\n",
    "from GINN.helpers.timer_helper import TimerHelper\n",
    "from GINN.morse.scc_surfacenet_manager import SCCSurfaceNetManager\n",
    "from GINN.problem_sampler import ProblemSampler\n",
    "from GINN.visualize.plotter_3d import Plotter3d\n",
    "\n",
    "from train.train_utils.autoclip import AutoClip\n",
    "from train.train_utils.latent_sampler import sample_new_z\n",
    "\n",
    "from utils import get_model, get_stateless_net_with_partials, set_all_seeds, get_is_out_mask\n",
    "from notebooks.notebook_utils import get_mesh_for_latent\n",
    "\n",
    "from models.model_utils import tensor_product_xz\n",
    "from cbf import CBFModel\n",
    "from simple_cbf import SimpleCBFModel\n",
    "\n",
    "from torch.func import functional_call, jacrev, jacfwd, vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room_0\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects\"\n",
    "env_name = \"_\".join(data_directory.split(\"/\")[-1].split(\"_\")[:2])\n",
    "points_name = \"original.npy\"\n",
    "points = {}\n",
    "\n",
    "print(env_name)\n",
    "\n",
    "for dirname in sorted(os.listdir(data_directory)):\n",
    "    points_path = os.path.join(data_directory, dirname, points_name)\n",
    "    points[dirname] = np.load(points_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5884798c84af4fe294e5b90a448694b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df94a30ea76c4c989dc902e41b822c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=-0.85, description='Z Height', max=10.0, min=-10.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d03a71c47542daa1bf787cfaa49059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=3.1390911861831197, description='X', max=50.0, min=-50.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a33b22615a4f2da61753c716738af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=1.1446799255634938, description='Y', max=50.0, min=-50.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd2e88346ed4e04a9bc95fdab3308f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=-0.2663193481873407, description='Z', max=50.0, min=-50.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class PointsManager:\n",
    "    def __init__(self, points_dict):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            points_dict: dict[str, np.ndarray], each array is (N_i, 3)\n",
    "        \"\"\"\n",
    "        self.original_points = {k: v.copy() for k, v in points_dict.items()}\n",
    "        self.translations = {k: np.zeros(3) for k in points_dict}\n",
    "        self._combined_tree = None\n",
    "        self._combined_tree_needs_update = True\n",
    "\n",
    "    def _get_translated_points(self, name):\n",
    "        return self.original_points[name] + self.translations[name]\n",
    "\n",
    "    def _rebuild_combined_tree(self):\n",
    "        all_points = np.vstack([\n",
    "            self._get_translated_points(name) for name in self.original_points\n",
    "        ])\n",
    "        self._combined_tree = cKDTree(all_points)\n",
    "        self._combined_tree_needs_update = False\n",
    "\n",
    "    def move(self, name, translation):\n",
    "        \"\"\"Move a point cloud by translation (x, y, z).\"\"\"\n",
    "        if name not in self.translations:\n",
    "            raise KeyError(f\"No point cloud named '{name}'\")\n",
    "        self.translations[name] += np.asarray(translation)\n",
    "        self._combined_tree_needs_update = True\n",
    "\n",
    "    def get_all_points(self):\n",
    "        \"\"\"Return all translated points from all clouds as a single (N, 3) array.\"\"\"\n",
    "        return np.vstack([self.get_points(name) for name in self.original_points])\n",
    "\n",
    "    def get_points(self, name):\n",
    "        \"\"\"Get the current (translated) points for a named point cloud.\"\"\"\n",
    "        if name not in self.original_points:\n",
    "            raise KeyError(f\"No point cloud named '{name}'\")\n",
    "        return self._get_translated_points(name)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset all point clouds to their original position.\"\"\"\n",
    "        for name in self.translations:\n",
    "            self.translations[name] = np.zeros(3)\n",
    "        self._combined_tree_needs_update = True\n",
    "\n",
    "    def get_closest_distance(self, point):\n",
    "        \"\"\"\n",
    "        Returns the distance to the closest point across all clouds using the fastest method.\n",
    "        \"\"\"\n",
    "        point = np.asarray(point).reshape(1, 3)\n",
    "\n",
    "        if self._combined_tree is None or self._combined_tree_needs_update:\n",
    "            self._rebuild_combined_tree()\n",
    "\n",
    "        dist, _ = self._combined_tree.query(point)\n",
    "        return dist[0]\n",
    "\n",
    "    def plot(self, plot=None, point_size=0.02, display=False):\n",
    "        \"\"\"Plot all point clouds with k3d, using different colors.\"\"\"\n",
    "        if not plot:\n",
    "            plot = k3d.plot()\n",
    "        color_cycle = cycle([\n",
    "            0xff0000, 0x00ff00, 0x0000ff, 0xffff00, 0xff00ff,\n",
    "            0x00ffff, 0x888888, 0xff8800, 0x8800ff, 0x00ff88\n",
    "        ])\n",
    "        for name, pts in self.original_points.items():\n",
    "            translated_pts = self.get_points(name)\n",
    "            color = next(color_cycle)\n",
    "            plot += k3d.points(translated_pts.astype(np.float32), color=color, point_size=point_size, name=name)\n",
    "        if display:\n",
    "            plot.display()\n",
    "        return plot\n",
    "\n",
    "class InteractivePlane:\n",
    "    def __init__(self, point_on_plane, normal, plot, point_size=0.01, size=5, color=0x00FF00):\n",
    "        self.size = size\n",
    "        self.color = color\n",
    "        self.plot = plot\n",
    "\n",
    "        self.z_slider = widgets.FloatSlider(value=point_on_plane[2], min=-10, max=10, step=0.1, description=\"Z Height\")\n",
    "        self.nx_slider = widgets.FloatSlider(value=normal[0], min=-1, max=1, step=0.1, description=\"Normal X\")\n",
    "        self.ny_slider = widgets.FloatSlider(value=normal[1], min=-1, max=1, step=0.1, description=\"Normal Y\")\n",
    "        self.nz_slider = widgets.FloatSlider(value=normal[2], min=-1, max=1, step=0.1, description=\"Normal Z\")\n",
    "\n",
    "        self.z_slider.observe(self.update_plane, names=\"value\")\n",
    "        self.nx_slider.observe(self.update_plane, names=\"value\")\n",
    "        self.ny_slider.observe(self.update_plane, names=\"value\")\n",
    "        self.nz_slider.observe(self.update_plane, names=\"value\")\n",
    "\n",
    "        self.point_on_plane = np.array([point_on_plane[0], point_on_plane[1], self.z_slider.value])\n",
    "        self.normal = np.array([self.nx_slider.value, self.ny_slider.value, self.nz_slider.value])\n",
    "        self.mesh = self.create_plane()\n",
    "\n",
    "        self.plot += self.mesh\n",
    "        display(self.z_slider)\n",
    "\n",
    "    def create_plane(self):\n",
    "        normal = self.normal / np.linalg.norm(self.normal)\n",
    "        v1 = np.cross(normal, np.array([1, 0, 0]))\n",
    "        if np.linalg.norm(v1) < 1e-6:\n",
    "            v1 = np.cross(normal, np.array([0, 1, 0]))\n",
    "        v1 = v1 / np.linalg.norm(v1) * self.size\n",
    "        v2 = np.cross(normal, v1)\n",
    "        v2 = v2 / np.linalg.norm(v2) * self.size\n",
    "\n",
    "        p1 = self.point_on_plane - v1 - v2\n",
    "        p2 = self.point_on_plane + v1 - v2\n",
    "        p3 = self.point_on_plane + v1 + v2\n",
    "        p4 = self.point_on_plane - v1 + v2\n",
    "\n",
    "        self.vertices = np.array([p1, p2, p3, p4], dtype=np.float32)\n",
    "        faces = np.array([[0, 1, 2], [0, 2, 3]], dtype=np.uint32)\n",
    "\n",
    "        return k3d.mesh(self.vertices, faces, color=self.color, wireframe=False, name=\"interactive plane\")\n",
    "\n",
    "    def update_plane(self, _):\n",
    "        self.point_on_plane[2] = self.z_slider.value\n",
    "        self.normal = np.array([self.nx_slider.value, self.ny_slider.value, self.nz_slider.value])\n",
    "        self.normal = self.normal / np.linalg.norm(self.normal)\n",
    "        self.vertices[:, 2] = self.point_on_plane[2]\n",
    "        self.mesh.vertices = self.vertices\n",
    "        print(self.normal, self.point_on_plane)\n",
    "\n",
    "class InteractivePoint:\n",
    "    def __init__(self, point, plot, point_size=0.1, color=0xFF0000):\n",
    "        self.plot = plot\n",
    "        self.color = color\n",
    "        self.point_size = point_size\n",
    "\n",
    "        self.x_slider = widgets.FloatSlider(value=point[0], min=-50, max=50, step=0.01, description=\"X\")\n",
    "        self.y_slider = widgets.FloatSlider(value=point[1], min=-50, max=50, step=0.01, description=\"Y\")\n",
    "        self.z_slider = widgets.FloatSlider(value=point[2], min=-50, max=50, step=0.01, description=\"Z\")\n",
    "\n",
    "        self.x_slider.observe(self.update_point, names=\"value\")\n",
    "        self.y_slider.observe(self.update_point, names=\"value\")\n",
    "        self.z_slider.observe(self.update_point, names=\"value\")\n",
    "\n",
    "        self.point = np.array([self.x_slider.value, self.y_slider.value, self.z_slider.value]).astype(np.float32)\n",
    "        self.k3d_point = self.create_point()\n",
    "\n",
    "        self.plot += self.k3d_point\n",
    "        display(self.x_slider, self.y_slider, self.z_slider)\n",
    "\n",
    "    def create_point(self):\n",
    "        return k3d.points(positions=[self.point], point_size=self.point_size, color=self.color, name=\"interactive point\")\n",
    "\n",
    "    def update_point(self, _):\n",
    "        self.point = np.array([self.x_slider.value, self.y_slider.value, self.z_slider.value]).astype(np.float32)\n",
    "        self.k3d_point.positions = [self.point]\n",
    "\n",
    "plot = k3d.plot()\n",
    "plot.display()\n",
    "\n",
    "# Clean previous interactive objects from plot\n",
    "for obj in list(plot.objects):\n",
    "    print(obj.name)\n",
    "    if \"interactive\" in str(obj.name):\n",
    "        plot -= obj\n",
    "\n",
    "pm = PointsManager(points)\n",
    "point_cloud = pm.get_all_points()\n",
    "pm.plot(plot=plot)\n",
    "\n",
    "# Create interactive elements\n",
    "point_on_plane = np.mean(point_cloud, axis=0)\n",
    "# office_3: z = -1\n",
    "# room_0: -0.8\n",
    "# office_4: -0.85\n",
    "\n",
    "point_on_plane[2] = -0.85\n",
    "normal = np.array([0, 0, 1])\n",
    "my_plane = InteractivePlane(point_on_plane, normal, plot, size=5)\n",
    "\n",
    "# initial_point = np.array([-14, 39, 0.6])\n",
    "initial_point = point_cloud.mean(axis=0)\n",
    "interactive_point = InteractivePoint(initial_point, plot, point_size=0.15, color=0xFF0000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_inside_oriented_bbox(corners, num_points=1000):\n",
    "    origin = corners[0]\n",
    "    edge_x = corners[1] - corners[0]  # along x\n",
    "    edge_y = corners[3] - corners[0]  # along y\n",
    "    edge_z = corners[4] - corners[0]  # along z\n",
    "    u = np.random.uniform(0, 1, (num_points, 1))\n",
    "    v = np.random.uniform(0, 1, (num_points, 1))\n",
    "    w = np.random.uniform(0, 1, (num_points, 1))\n",
    "    samples = origin + u * edge_x + v * edge_y + w * edge_z\n",
    "    return samples\n",
    "\n",
    "def estimate_room_corners(point_cloud, scale=0.9):\n",
    "    \"\"\"\n",
    "    Compute the oriented bounding box using PCA.\n",
    "    \n",
    "    Args:\n",
    "        point_cloud (np.ndarray): Nx3 array of points\n",
    "        scale (float): scale factor to shrink/expand box relative to center\n",
    "\n",
    "    Returns:\n",
    "        corners (8, 3): world-space coordinates of the bounding box corners\n",
    "    \"\"\"\n",
    "    center = point_cloud.mean(axis=0)\n",
    "    centered = point_cloud - center\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(centered)\n",
    "    R = pca.components_.T  # principal axes as columns\n",
    "\n",
    "    rotated = centered @ R\n",
    "    min_corner = rotated.min(axis=0)\n",
    "    max_corner = rotated.max(axis=0)\n",
    "\n",
    "    # Scale down corners in PCA space\n",
    "    scaled_min = center + scale * (min_corner @ R.T)\n",
    "    scaled_max = center + scale * (max_corner @ R.T)\n",
    "\n",
    "    corners_pca = np.array([\n",
    "        [min_corner[0], min_corner[1], min_corner[2]],\n",
    "        [max_corner[0], min_corner[1], min_corner[2]],\n",
    "        [max_corner[0], max_corner[1], min_corner[2]],\n",
    "        [min_corner[0], max_corner[1], min_corner[2]],\n",
    "        [min_corner[0], min_corner[1], max_corner[2]],\n",
    "        [max_corner[0], min_corner[1], max_corner[2]],\n",
    "        [max_corner[0], max_corner[1], max_corner[2]],\n",
    "        [min_corner[0], max_corner[1], max_corner[2]],\n",
    "    ])\n",
    "\n",
    "    # Scale corners toward the center\n",
    "    corners_pca_scaled = scale * corners_pca\n",
    "\n",
    "    # Transform back to world space\n",
    "    corners_world = (corners_pca_scaled @ R.T) + center\n",
    "    return corners_world\n",
    "\n",
    "def sample_point_pairs(point_cloud, num_pairs=10, num_samples=1000, min_pcd_dist=0.5,\n",
    "                       min_dist_range=[1.0, 2.0], plane=None, max_iterations=10,\n",
    "                       p1=np.array([]), reverse=False, plot=None, corner_scale=0.85):\n",
    "    \"\"\"\n",
    "    Sample pairs of points from inside a rotated bounding box or plane slice.\n",
    "    \"\"\"\n",
    "    bbox_corners = estimate_room_corners(point_cloud, corner_scale)\n",
    "    tree = cKDTree(point_cloud)\n",
    "    og_p1 = p1.copy()\n",
    "\n",
    "    def generate_candidates(plot=plot):\n",
    "        plane_pt, _ = plane\n",
    "        points = sample_inside_oriented_bbox(bbox_corners, num_samples)\n",
    "\n",
    "        if plane is not None:\n",
    "            points[:, 2] = plane_pt[2]\n",
    "            if plot is not None:\n",
    "                plot += k3d.points(points, name=\"canidates\", point_size=0.025)\n",
    "            return points\n",
    "        else:\n",
    "            return points\n",
    "\n",
    "    pairs = []\n",
    "    iterations = 0\n",
    "\n",
    "    progress_bar = tqdm(total=num_pairs+1, desc=\"Sampling pair\")\n",
    "\n",
    "    while len(pairs) < num_pairs and iterations < max_iterations:\n",
    "        candidate_points = generate_candidates()\n",
    "        distances, _ = tree.query(candidate_points)\n",
    "        valid_points = candidate_points[distances >= min_pcd_dist]\n",
    "        remaining_points = list(valid_points)\n",
    "\n",
    "        i = 0\n",
    "        while len(remaining_points) > 1 and len(pairs) < num_pairs:\n",
    "            for i, p2 in enumerate(remaining_points):\n",
    "                if og_p1.shape[0] == 0:\n",
    "                    p1 = random.choice(remaining_points)\n",
    "                    while np.array_equal(p1, p2):\n",
    "                        p1 = random.choice(remaining_points)\n",
    "                else:\n",
    "                    p1 = og_p1\n",
    "\n",
    "                min_dist = random.uniform(min_dist_range[0], min_dist_range[1])\n",
    "                if np.linalg.norm(p1 - p2) >= min_dist:\n",
    "                    pairs.append([p1, p2])\n",
    "                    remaining_points.pop(i)\n",
    "                    progress_bar.update(1)\n",
    "                    break\n",
    "\n",
    "            if i > max_iterations:\n",
    "                break\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    if reverse:\n",
    "        pairs = [p[::-1] for p in pairs]\n",
    "\n",
    "    return np.array(pairs[:num_pairs])\n",
    "\n",
    "for obj in list(plot.objects):\n",
    "    to_check = [\"Points\", \"Line\", \"bbox_corners\", \"canidates\"]\n",
    "    if True in [c in str(obj.name) for c in to_check]:\n",
    "        plot -= obj\n",
    "        print(\"Removing\", obj.name)\n",
    "\n",
    "# office_3: z = -1\n",
    "plane = (my_plane.point_on_plane, (normal))  \n",
    "\n",
    "# n_points = 10\n",
    "# num_pairs = 100\n",
    "# min_pcd_dist = 0.2\n",
    "# test_traj_pairs = sample_point_pairs(point_cloud, num_pairs=num_pairs, num_samples=750, min_pcd_dist=min_pcd_dist, \n",
    "#     min_dist_range=[1, 5], plane=plane, max_iterations=500, reverse=True, plot=plot, corner_scale=0.8)\n",
    "\n",
    "# corners = estimate_room_corners(point_cloud)\n",
    "# plot += k3d.points(positions=corners.astype(np.float32), point_size=0.05, color=0x00ffff, name=\"bbox_corners\")\n",
    "\n",
    "# for pair in test_traj_pairs:\n",
    "#     plot += k3d.points(pair, color=0xffff00, point_size=0.05)\n",
    "#     plot += k3d.line(pair, color=0xffff00, width=0.05)\n",
    "#     start = torch.tensor(pair[0], dtype=torch.float32)\n",
    "#     goal = torch.tensor(pair[1], dtype=torch.float32)\n",
    "\n",
    "    # waypoints = generate_safe_path(pm, start, goal, num_samples=2000)\n",
    "    # print(waypoints)\n",
    "\n",
    "    # # waypoints = pm.generate_safe_path_prm(pair[0], pair[1], N=n_points, D=min_pcd_dist)\n",
    "    # # print(waypoints.shape)\n",
    "    # plot += k3d.line(waypoints, color=0xffddf0, width=0.05)\n",
    "    # plot += k3d.points(waypoints, color=0x00ff00, point_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounds torch.Size([14, 3, 2]) bounds_obj torch.Size([14, 3, 2])\n",
      "scale_factors torch.Size([14])\n",
      "centers_for_translations torch.Size([14, 3])\n",
      "14 ['/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/0_wall/cond_siren/2025_04_30-11_11_53/2025_04_30-11_11_54-875n7ept_best_248.pth', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/1_lamp/cond_siren/2025_04_30-11_11_58/2025_04_30-11_11_59-5kciqr6s_best.pth', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/2_table/cond_siren/2025_04_30-11_12_06/2025_04_30-11_12_08-ieijh8pr_best.pth', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/3_table/cond_siren/2025_04_30-11_11_56/2025_04_30-11_11_57-4dkdsmwq_best_247.pth', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/4_table/cond_siren/2025_04_30-11_11_53/2025_04_30-11_11_54-z4npbxyh_best_246.pth', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/5_stool/cond_siren/2025_04_30-11_11_54/2025_04_30-11_11_55-qaso5ark_best_245.pth', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/6_chair/cond_siren/2025_04_30-11_11_53/2025_04_30-11_11_54-jktsb8tp_best_240.pth', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/7_sofa/cond_siren/2025_04_30-11_11_53/2025_04_30-11_11_54-24qou3a8_best_194.pth', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/8_stool/cond_siren/2025_04_30-11_11_58/2025_04_30-11_12_01-wn3vzvkx_best_216.pth', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/9_chair/cond_siren/2025_04_30-11_11_48/2025_04_30-11_11_53-zq9g1e8l_best.pth', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/10_table/cond_siren/2025_04_30-11_11_48/2025_04_30-11_11_53-x6l12tyu_best_214.pth', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/11_lamp/cond_siren/2025_04_30-11_11_48/2025_04_30-11_11_53-5ojbo2lq_best.pth', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/12_ceiling/cond_siren/2025_04_30-11_11_47/2025_04_30-11_11_48-bvnr03gm_best_196.pth', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/13_floor/cond_siren/2025_04_30-11_11_47/2025_04_30-11_11_48-njn6a7il_best_235.pth']\n",
      "14 ['/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/0_wall/config.yml', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/1_lamp/config.yml', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/2_table/config.yml', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/3_table/config.yml', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/4_table/config.yml', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/5_stool/config.yml', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/6_chair/config.yml', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/7_sofa/config.yml', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/8_stool/config.yml', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/9_chair/config.yml', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/10_table/config.yml', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/11_lamp/config.yml', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/12_ceiling/config.yml', '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/13_floor/config.yml']\n",
      "14 ['0_wall', '1_lamp', '2_table', '3_table', '4_table', '5_stool', '6_chair', '7_sofa', '8_stool', '9_chair', '10_table', '11_lamp', '12_ceiling', '13_floor']\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "#\n",
    "#   LOADING IN DATA\n",
    "#   LOADING IN DATA\n",
    "#   LOADING IN DATA\n",
    "#\n",
    "##################################################\n",
    "\n",
    "# # office_4\n",
    "# model_directory = \"/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-29_13-24-46_office_4_objects\"\n",
    "\n",
    "# # office_3\n",
    "# model_directory = \"/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-29_11-45-38_office_3_objects\"\n",
    "\n",
    "# room_0 objects\n",
    "model_directory = \"/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final\"\n",
    "\n",
    "\n",
    "# # small - WORKS with overhead\n",
    "# model_directory = \"/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-28_22-06-30_room_0_single\"\n",
    "\n",
    "# # was good? not working now\n",
    "# model_directory = \"/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-27_03-11-17_room_0_single\"\n",
    "\n",
    "# data_directory = \"/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects\" # set earlier\n",
    "config_name = \"config.yml\"\n",
    "device = 'cuda:0'\n",
    "\n",
    "scale_name = \"scale_factor.npy\"\n",
    "center_translation_name = \"center_for_translation.npy\"\n",
    "bounds_name = \"bounds.npy\"\n",
    "bounds_obj_name = \"bounds_obj.npy\"\n",
    "\n",
    "config_paths = []\n",
    "obj_names = []\n",
    "model_paths = []\n",
    "bounds=[]\n",
    "bounds_objs=[]\n",
    "scale_factors = []\n",
    "centers_for_translations=[]\n",
    "\n",
    "target_epoch = 990\n",
    "use_best = True\n",
    "\n",
    "dirs = os.listdir(model_directory)\n",
    "dirs_sorted = sorted(dirs, key=lambda name: int(name.split('_', 1)[0]))\n",
    "for dirname in dirs_sorted:\n",
    "    classname = \"_\".join(dirname.split(\"_\")[:2])\n",
    "    dir_path = os.path.join(model_directory, dirname)\n",
    "    config_path = \"\"\n",
    "    model_path = \"\"\n",
    "    model_max_path = \"\"\n",
    "    max_epoch = 0\n",
    "\n",
    "    for root, _, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            if \".yml\" in file:\n",
    "                config_path = os.path.join(root, file)\n",
    "            if \".pth\" not in file: continue \n",
    "\n",
    "            if use_best and \"best\" in file:\n",
    "                model_path = os.path.join(root, file)\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                epoch = int(file.split(\"_\")[-1].split(\".\")[0])\n",
    "            except:\n",
    "                if 'best' not in file:\n",
    "                    print(\"Invalid file name:\", file)\n",
    "                continue\n",
    "\n",
    "            if epoch == target_epoch:\n",
    "                model_path = os.path.join(root, file)\n",
    "\n",
    "            if epoch > max_epoch:\n",
    "                model_max_path = os.path.join(root, file)\n",
    "                max_epoch = epoch\n",
    "\n",
    "    if not model_path:\n",
    "        if max_epoch:\n",
    "            print(dirname, \"Using max epoch\", max_epoch)\n",
    "            model_path = model_max_path\n",
    "    \n",
    "    if not (model_path and config_path):\n",
    "        print(\"Nothing found for\", dirname, (model_path, config_path))\n",
    "        continue\n",
    " \n",
    "    config_paths.append(config_path)\n",
    "    obj_names.append(dirname)\n",
    "    model_paths.append(os.path.join(root, model_path))\n",
    "\n",
    "    point_path = os.path.join(data_directory, classname)\n",
    "    scale_factor = torch.from_numpy(np.load(os.path.join(point_path, scale_name))).float().to(device)\n",
    "    centers_for_translation = torch.from_numpy(np.load(os.path.join(point_path, center_translation_name))).float().to(device)\n",
    "    bound = torch.from_numpy(np.load(os.path.join(point_path, bounds_name))).float().to(device)\n",
    "    bound_obj = torch.from_numpy(np.load(os.path.join(point_path, bounds_obj_name))).float().to(device)\n",
    "\n",
    "    bounds_objs.append(bound_obj)    \n",
    "    bounds.append(bound)    \n",
    "    scale_factors.append(scale_factor)    \n",
    "    centers_for_translations.append(centers_for_translation)    \n",
    "\n",
    "bounds = torch.stack(bounds)\n",
    "bounds_objs = torch.stack(bounds_objs)\n",
    "scale_factors = torch.stack(scale_factors)\n",
    "centers_for_translations = torch.stack(centers_for_translations)\n",
    "\n",
    "print(\"bounds\", bounds.shape, \"bounds_obj\", bounds_objs.shape)\n",
    "print(\"scale_factors\", scale_factors.shape)\n",
    "print(\"centers_for_translations\", centers_for_translations.shape)\n",
    "print(len(model_paths), model_paths)\n",
    "print(len(config_paths), config_paths)\n",
    "print(len(obj_names), obj_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#\n",
    "#   CLASSES\n",
    "#   CLASSES\n",
    "#   CLASSES\n",
    "#\n",
    "##################################################\n",
    "\n",
    "import torch.nn as nn\n",
    "from typing import Tuple, Optional\n",
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "\n",
    "DEFAULT_Z_VAL = 1.0\n",
    "\n",
    "def batch_jacobian(f, x, z):\n",
    "    \"\"\"\n",
    "    Compute the Jacobian using forward-mode differentiation (jacrev).\n",
    "    \"\"\"\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    z = z.clone().detach()\n",
    "\n",
    "    return jacrev(f, argnums=0)(x, z)  # Computes d(f)/dx efficiently\n",
    "\n",
    "# def smooth_mask(x, a, b, k):\n",
    "#     sig_a = torch.sigmoid(k * (x - a))\n",
    "#     sig_b = torch.sigmoid(k * (b - x))\n",
    "#     return sig_a * sig_b\n",
    "\n",
    "def get_adapter_model(config):\n",
    "    # config = load_yaml_to_dict(adapter_config_path)\n",
    "    config_siren = get_config_from_yml(config[\"paths\"][\"siren_config_path\"])\n",
    "    config_siren[\"device\"] = device\n",
    "\n",
    "    siren_model = get_model(config_siren).to(device)\n",
    "    siren_model.load_state_dict(torch.load(config[\"paths\"][\"pretrained_siren_path\"], map_location=device))\n",
    "\n",
    "    final_layer_size = list(siren_model.network.children())[-3].out_features\n",
    "    layer_sizes = [final_layer_size] + config[\"training\"][\"adapter_mid_layers\"]\n",
    "    activation_name = config[\"training\"][\"activation_name\"]\n",
    "\n",
    "    adapter_model = create_adapter_mlp(layer_sizes, activation_name=activation_name, siren_config=config_siren).to(device)\n",
    "    model = ConditionalSIRENWithAdapter(siren_model, adapter_model).to(device)\n",
    "    return model\n",
    "\n",
    "def load_yaml_to_dict(filename: str) -> dict:\n",
    "    with open(filename, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "    return data\n",
    "\n",
    "from torch.func import jacrev, vmap\n",
    "\n",
    "def smooth_mask(x, a, b, k):\n",
    "    # k is a distance metric now\n",
    "    sig_a = torch.sigmoid((x - a) * (4.0 / k))\n",
    "    sig_b = torch.sigmoid((b - x) * (4.0 / k))\n",
    "    return sig_a * sig_b\n",
    "\n",
    "# Define the combined 3D mask for a prism\n",
    "def prism_mask(coords, x_range, y_range, z_range, k):\n",
    "    x_mask = smooth_mask(coords[..., 0], x_range[0], x_range[1], k)\n",
    "    y_mask = smooth_mask(coords[..., 1], y_range[0], y_range[1], k)\n",
    "    z_mask = smooth_mask(coords[..., 2], z_range[0], z_range[1], k)\n",
    "    \n",
    "    mask = x_mask * y_mask * z_mask\n",
    "    return mask\n",
    "    \n",
    "class CBFModel(nn.Module):\n",
    "    def __init__(self, n, configs, bounds=[], scale_factors = [], centers_for_translations=[], alpha=50, device='cpu', scale = 10, mask_dist=8, upper_bound=1, do_mask=True, use_adapters=False, netp=None):\n",
    "        super(CBFModel, self).__init__()\n",
    "\n",
    "        self.n = n\n",
    "        self.configs = configs\n",
    "        self.bounds = bounds  # active bounds (may be subset)\n",
    "        self.scale_factors = scale_factors\n",
    "        self.centers_for_translations = centers_for_translations\n",
    "        if not use_adapters:\n",
    "            self.models = nn.ModuleList([get_model(config).to(device) for config in configs])\n",
    "            self.all_models = nn.ModuleList([get_model(config).to(device) for config in configs])\n",
    "        else:\n",
    "            self.models = nn.ModuleList([get_adapter_model(config).to(device) for config in configs])\n",
    "            self.all_models = nn.ModuleList([get_adapter_model(config).to(device) for config in configs])\n",
    "\n",
    "        self.all_n = n\n",
    "        self.all_configs = configs.copy() if isinstance(configs, list) else configs\n",
    "        self.all_bounds = bounds.copy() if isinstance(bounds, list) else bounds\n",
    "        self.all_scale_factors = scale_factors.copy() if isinstance(scale_factors, list) else scale_factors\n",
    "        self.all_centers_for_translations = centers_for_translations.copy() if isinstance(centers_for_translations, list) else centers_for_translations\n",
    "        self.all_models = self.models  # original full list of submodels\n",
    "\n",
    "        self.scale = 1\n",
    "        self.alpha = alpha\n",
    "        self.mask_dist = mask_dist\n",
    "        self.device = device\n",
    "        self.jacobian = None\n",
    "        self.upper_bound = upper_bound\n",
    "        self.do_mask = do_mask\n",
    "        self.netp = netp\n",
    "        self.model2mesh = {}\n",
    "\n",
    "        self.netp = get_stateless_net_with_partials(self, use_x_and_z_arg=True)\n",
    "\n",
    "    def compute_spectral_norm(self) -> float:\n",
    "        total_L = 0.0\n",
    "        for submodel in self.models:\n",
    "            submodel_L = 1.0\n",
    "            for layer in submodel.modules():\n",
    "                if isinstance(layer, torch.nn.Linear):\n",
    "                    W = layer.weight\n",
    "                    s = torch.linalg.svdvals(W)[0].item()  # largest singular value\n",
    "                    print(s)\n",
    "                    submodel_L *= s\n",
    "            total_L += submodel_L  # could use max/submodel_L if using max-based aggregation\n",
    "        return total_L\n",
    "\n",
    "    def compute_softmax_lipschitz(self, x: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Estimate an upper bound on the gradient norm of h(x)  \n",
    "        using the softmax-weighted Jacobians from get_jacobian.  \n",
    "        Returns a (B,1) tensor of ∥∇h(x_i)∥ for each sample i.\n",
    "        \"\"\"\n",
    "        for m in self.models:\n",
    "            m.eval()\n",
    "\n",
    "        x = x.to(self.device)\n",
    "        z = z.to(self.device)\n",
    "\n",
    "        alpha = self.alpha\n",
    "        B = x.shape[0]\n",
    "\n",
    "        outputs, jacobians = [], []\n",
    "        for i, submodel in enumerate(self.models):\n",
    "            x_pre = (x - self.centers_for_translations[i]) / self.scale_factors[i]\n",
    "            out = submodel(x_pre, z)            # (B,1)\n",
    "            outputs.append(-alpha * out)\n",
    "\n",
    "            J = self.get_jacobian(x_pre, z)     # (B,3)\n",
    "            J_scaled = J / self.scale_factors[i]\n",
    "            jacobians.append(J_scaled)\n",
    "\n",
    "        outputs   = torch.stack(outputs, dim=0)    # (M, B, 1)\n",
    "        jacobians = torch.stack(jacobians, dim=0)  # (M, B, 3)\n",
    "\n",
    "        weights = torch.softmax(outputs, dim=0)    # (M, B, 1)\n",
    "        weighted_jacobian = (weights * jacobians).sum(dim=0)  # (B, 3)\n",
    "\n",
    "        # per-sample norm → shape (B,1)\n",
    "        lips = torch.norm(weighted_jacobian, dim=1, keepdim=True)\n",
    "        return lips\n",
    "\n",
    "    def get_jacobian(self, x, z):\n",
    "        def f_closed(x, z):\n",
    "            return self.netp.f(x, z)\n",
    "\n",
    "        vf_x_closed = vmap(jacrev(f_closed, argnums=0), in_dims=(0, 0), out_dims=0)\n",
    "        jacobian_vf_x = vf_x_closed(x, z)\n",
    "        if torch.isnan(jacobian_vf_x).any():\n",
    "            jacobian_vf_x = torch.nan_to_num(jacobian_vf_x, nan=0.0)\n",
    "            # print(\"NaN Jacobian, V:\", self.forward(x, z))\n",
    "        return jacobian_vf_x\n",
    "\n",
    "    def forward(self, xog, z, mask_dist=None):\n",
    "        # xog.requires_grad_(True)  # Ensure gradients are tracked\n",
    "        outs = torch.zeros(len(self.models), xog.shape[0], 1)\n",
    "        if not mask_dist: mask_dist = self.mask_dist\n",
    "\n",
    "        self.centers_for_translations = torch.stack([c.to(self.device) for c in self.centers_for_translations])\n",
    "        self.bounds = torch.stack([b.to(self.device) for b in self.bounds])\n",
    "        self.scale_factors = torch.stack([s.to(self.device) for s in self.scale_factors])\n",
    "        xog = xog.to(self.device)\n",
    "        z = z.to(self.device)\n",
    "\n",
    "        def output_func(x, z):\n",
    "            # x: input tensor (could be batched)\n",
    "            # z: additional argument to the network\n",
    "            out_list = []\n",
    "            for i, model in enumerate(self.models):\n",
    "                # Compute mask if masking is enabled\n",
    "                if self.do_mask:\n",
    "                    m = prism_mask(x, self.bounds[i][0], self.bounds[i][1], self.bounds[i][2], mask_dist)\n",
    "                    # When x is a single sample (0D case), m may be 0D.\n",
    "                    if m.dim() == 0:\n",
    "                        mask = m.unsqueeze(0)\n",
    "                    else:\n",
    "                        mask = m.unsqueeze(1)\n",
    "                else:\n",
    "                    mask = 1\n",
    "\n",
    "                # Preprocess x for the current submodel\n",
    "                x_preprocessed = (x - self.centers_for_translations[i]) / self.scale_factors[i]\n",
    "                model_output = model(x_preprocessed, z)\n",
    "                temp = mask * torch.exp(-self.alpha * model_output)\n",
    "\n",
    "                # Avoid in-place squeeze issues: if temp is scalar or has a singleton batch dim,\n",
    "                # adjust accordingly.\n",
    "                if temp.dim() == 0:\n",
    "                    out_list.append(temp.unsqueeze(0))\n",
    "                elif temp.size(0) == 1:\n",
    "                    out_list.append(temp.squeeze(0))\n",
    "                else:\n",
    "                    out_list.append(temp)\n",
    "            \n",
    "            # Stack along a new dimension so that out_values has shape: (num_models, ..., output_dim)\n",
    "            out_values = torch.stack(out_list, dim=0)\n",
    "            # Sum across models, then take the log and scale\n",
    "            output = self.scale * -1 / self.alpha * torch.log(torch.sum(out_values, axis=0))\n",
    "            output = torch.clamp(output, max=self.upper_bound)\n",
    "            return output\n",
    "\n",
    "\n",
    "        output = output_func(xog, z)\n",
    "        return output\n",
    "\n",
    "    def named_parameters(self, recurse=True, remove_duplicate=False):\n",
    "        for i in range(self.n):\n",
    "            for name, param in self.models[i].named_parameters(recurse=recurse, remove_duplicate=remove_duplicate):\n",
    "                yield f'models.{i}.{name}', param\n",
    "\n",
    "    def named_buffers(self, recurse=True, remove_duplicate=False):\n",
    "        for i in range(self.n):\n",
    "            for name, buffer in self.models[i].named_buffers(recurse=recurse, remove_duplicate=remove_duplicate):\n",
    "                yield f'models.{i}.{name}', buffer\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.models)\n",
    "    \n",
    "    def shift_models(self, indices: list[int], step: torch.Tensor):\n",
    "        # step: (3,)\n",
    "        step = step.to(device)\n",
    "        for idx in indices:\n",
    "            self.centers_for_translations[idx] += step\n",
    "            self.bounds[idx] += step.unsqueeze(1)\n",
    "    \n",
    "    def move_model(self, index: int, new_center: torch.Tensor):\n",
    "        new_center = new_center.to(self.device)\n",
    "        current_center = self.centers_for_translations[index].to(self.device)\n",
    "        translation = new_center - current_center\n",
    "\n",
    "        self.centers_for_translations[index] = new_center\n",
    "        self.bounds[index] = self.bounds[index] + translation.unsqueeze(1)\n",
    "\n",
    "    \n",
    "    def get_dist_to_submodel(self, model_idx: int, point: torch.Tensor):\n",
    "        point = point.to(self.device)  # Ensure correct device\n",
    "        bounds = self.bounds[model_idx]\n",
    "\n",
    "        clamped_point = torch.clamp(point, bounds[:, 0], bounds[:, 1])\n",
    "        return torch.norm(point - clamped_point, dim=0)\n",
    "\n",
    "    def get_submodel_in_rad(self, points: torch.Tensor, radius=0.5):\n",
    "        points = points.to(self.device)\n",
    "        if points.dim() == 1:\n",
    "            points = points.unsqueeze(0)  # Convert (3,) → (1,3) for single point case\n",
    "        indices = set()\n",
    "\n",
    "        for i in range(len(self.bounds)):\n",
    "            distances = torch.stack([self.get_dist_to_submodel(i, point) for point in points])\n",
    "            if torch.any(distances < radius):\n",
    "                indices.add(i)\n",
    "\n",
    "        return sorted(indices) \n",
    "\n",
    "    def set_submodels(self, indices: list[int]):\n",
    "        if len(indices) == 0:\n",
    "            indices = [0]\n",
    "        self.configs = [self.all_configs[i] for i in indices]\n",
    "        self.bounds = [self.bounds[i] for i in indices]\n",
    "        self.scale_factors = [self.all_scale_factors[i] for i in indices]\n",
    "        self.centers_for_translations = [self.all_centers_for_translations[i] for i in indices]\n",
    "        self.models = nn.ModuleList([self.all_models[i] for i in indices])\n",
    "        self.n = len(indices)\n",
    "        self.netp = get_stateless_net_with_partials(self, use_x_and_z_arg=True)\n",
    "\n",
    "    def reset_submodels(self):\n",
    "        self.configs = self.all_configs.copy() if isinstance(self.all_configs, list) else self.all_configs\n",
    "        self.bounds = self.bounds.copy() if isinstance(self.bounds, list) else self.bounds\n",
    "        self.scale_factors = self.all_scale_factors.copy() if isinstance(self.all_scale_factors, list) else self.all_scale_factors\n",
    "        self.centers_for_translations = self.all_centers_for_translations.copy() if isinstance(self.all_centers_for_translations, list) else self.all_centers_for_translations\n",
    "        self.models = nn.ModuleList(self.all_models)  # Ensure self.models remains an nn.ModuleList\n",
    "        self.n = self.all_n\n",
    "        self.netp = get_stateless_net_with_partials(self, use_x_and_z_arg=True)\n",
    "\n",
    "    @classmethod\n",
    "    def create_model(_, config_paths, sub_model_paths, alpha=50, device='cpu', upper_bound=8, all_scale_factors=torch.empty(0), all_center_translations=torch.empty(0), all_bounds=torch.empty(0), use_adapters=False):\n",
    "        scale_name = \"scale_factor.npy\"\n",
    "        center_translation_name = \"center_for_translation.npy\"\n",
    "        bounds_name = \"bounds.npy\"\n",
    "\n",
    "        if use_adapters:\n",
    "            configs = [load_yaml_to_dict(path) for path in config_paths]\n",
    "        else:\n",
    "            configs = [get_config_from_yml(path) for path in config_paths]\n",
    "\n",
    "        if all_scale_factors.shape[0] == 0:\n",
    "            all_scale_factors = torch.stack([\n",
    "                torch.from_numpy(np.load(os.path.join(config['dataset_dir'], scale_name))).float().to(device)\n",
    "                for config in configs\n",
    "            ])\n",
    "            print(\"WARNING - Using from config\")\n",
    "\n",
    "        if all_center_translations.shape[0] == 0:\n",
    "            all_center_translations = torch.stack([\n",
    "                torch.from_numpy(np.load(os.path.join(config['dataset_dir'], center_translation_name))).float().to(device)\n",
    "                for config in configs\n",
    "            ])\n",
    "            print(\"WARNING - Using from config\")\n",
    "\n",
    "        if all_bounds.shape[0] == 0:\n",
    "            all_bounds = torch.stack([\n",
    "                torch.from_numpy(np.load(os.path.join(config['dataset_dir'], bounds_name))).float().to(device)\n",
    "                for config in configs\n",
    "            ])\n",
    "            print(\"WARNING - Using from config\")\n",
    "\n",
    "        model = CBFModel(len(configs), configs, bounds=all_bounds, scale_factors = all_scale_factors, centers_for_translations=all_center_translations, alpha=alpha, device=device, use_adapters=use_adapters)\n",
    "        model.netp = get_stateless_net_with_partials(model, use_x_and_z_arg=True)\n",
    "\n",
    "        for i in range(model.n): \n",
    "            model.models[i].load_state_dict(torch.load(sub_model_paths[i], map_location=device))\n",
    "\n",
    "        # sub_model_netps = [get_stateless_net_with_partials(model.models[i], use_x_and_z_arg=configs[i]['use_x_and_z_arg']) for i in range(model.n)]\n",
    "\n",
    "        z = torch.tensor([float(DEFAULT_Z_VAL)]).to(device)\n",
    "        return model, z\n",
    "\n",
    "    @classmethod\n",
    "    def update_plot(_, model, z, plot, n = None, w = 35, mc_resolution=32, device='cpu'):\n",
    "        for obj in list(plot.objects):\n",
    "            if \"cbf\" in str(obj.name):\n",
    "                plot -= obj\n",
    "\n",
    "        if n:\n",
    "            xp = np.linspace(-w, w, n)\n",
    "            yp = np.linspace(-w, w, n)\n",
    "            zp = np.linspace(-w, w, n)\n",
    "\n",
    "            X, Y, Z = np.meshgrid(xp, yp, zp, indexing='ij')\n",
    "\n",
    "            points = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T\n",
    "            points_tensor = torch.from_numpy(points).float().to(device)\n",
    "\n",
    "            zs_tensor = torch.full((points.shape[0],), z.item()).unsqueeze(1).float()  # create z_tensor with same number of points\n",
    "\n",
    "            cbf_outs = np.zeros(points.shape[0])\n",
    "            cbf_outs = netp.f_(netp.params_, points_tensor, zs_tensor)\n",
    "            \n",
    "            colors = np.zeros(points.shape[0], dtype=np.uint32)\n",
    "\n",
    "            for i in range(points.shape[0]):\n",
    "                if cbf_outs[i] > 0: \n",
    "                    colors[i] = 0x00FF00  # Green for positive\n",
    "                else: \n",
    "                    colors[i] = 0x000000  # Black for negative\n",
    "            \n",
    "            point_size = 0.25\n",
    "            points_plot = k3d.points(positions=points.astype(np.float32), colors=colors, point_size = point_size)\n",
    "            plot += points_plot\n",
    "\n",
    "        # model.bounds[0] = torch.tensor([[-w, w], [-w, w], [-w, w]])\n",
    "        # print(model.bounds.shape)\n",
    "\n",
    "        # Compute global bounds\n",
    "        global_lower_bound = torch.min(model.bounds[..., 0], dim=0).values  # Min of all lower bounds\n",
    "        global_upper_bound = torch.max(model.bounds[..., 1], dim=0).values  # Max of all upper bounds\n",
    "        global_bounds = torch.stack([global_lower_bound, global_upper_bound], dim=-1)\n",
    "\n",
    "        delta = 2  # Amount to expand the bounds by\n",
    "        bounds = torch.stack([\n",
    "            global_bounds[..., 0] - delta,  # Lower bound decreases\n",
    "            global_bounds[..., 1] + delta   # Upper bound increases\n",
    "        ], dim=-1)\n",
    "\n",
    "        vert, faces = get_mesh_for_latent(model.netp.f_, model.netp.params_, z, bounds, mc_resolution=mc_resolution, device=device, chunks=1, flip_faces=True)\n",
    "        mesh_plot = k3d.mesh(vert, faces, color=0xff0000, side='double', opacity=1, name=\"cbf\")\n",
    "        plot += mesh_plot\n",
    "\n",
    "        # for i in range(model.bounds.shape[0]):\n",
    "        #     reshaped_bound = model.bounds[i].T.cpu().numpy()\n",
    "        #     plot += k3d.points(positions=reshaped_bound, point_size = 0.25, name=\"cbf\")\n",
    "\n",
    "        plot += k3d.points(positions=bounds.T.cpu().numpy(), point_size = 0.25, name=\"cbf\")\n",
    "\n",
    "    def get_dist_to_submodel(self, model_idx: int, point: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Returns the distance of the point to the submodel's bounding box.\n",
    "        Uses the currently active bounds.\n",
    "        \"\"\"\n",
    "        point = point.to(self.device)  # Ensure correct device\n",
    "        bounds = self.bounds[model_idx]\n",
    "        clamped_point = torch.clamp(point, bounds[:, 0], bounds[:, 1])\n",
    "        return torch.norm(point - clamped_point, dim=0)\n",
    "    \n",
    "    def get_dist_to_submodel_original(self, model_idx: int, point: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Returns the distance of the point to the submodel's bounding box,\n",
    "        using the original full configuration (self.all_bounds).\n",
    "        \"\"\"\n",
    "        point = point.to(self.device)\n",
    "        bounds = self.all_bounds[model_idx]\n",
    "        clamped_point = torch.clamp(point, bounds[:, 0], bounds[:, 1])\n",
    "        return torch.norm(point - clamped_point, dim=0)\n",
    "    \n",
    "    def get_submodel_in_rad(self, points: torch.Tensor, radius=0.5):\n",
    "        \"\"\"\n",
    "        Returns the indexes (from the original configuration) of all submodels\n",
    "        whose original bounds are within 'radius' of any of the provided points.\n",
    "        This always uses the original configuration.\n",
    "        \"\"\"\n",
    "        points = points.to(self.device)\n",
    "        if points.dim() == 1:\n",
    "            points = points.unsqueeze(0)  # (1,3) if a single point is provided\n",
    "        indices = set()\n",
    "        # Loop over the full set of submodels (original configuration)\n",
    "        for i in range(len(self.all_bounds)):\n",
    "            # Use the original bounds via the helper function\n",
    "            distances = torch.stack([self.get_dist_to_submodel_original(i, point) for point in points])\n",
    "            if torch.any(distances < radius):\n",
    "                indices.add(i)\n",
    "        return sorted(indices)\n",
    "\n",
    "    def set_submodels(self, indices: list[int]):\n",
    "        \"\"\"\n",
    "        Set the active submodels to only those whose original indices are given.\n",
    "        All active attributes (configs, bounds, etc.) are updated from the original full configuration.\n",
    "        \"\"\"\n",
    "        if len(indices) == 0:\n",
    "            indices = [0]\n",
    "        \n",
    "        self.configs = [self.all_configs[i] for i in indices]\n",
    "        self.bounds = [self.all_bounds[i] for i in indices]\n",
    "        self.scale_factors = [self.all_scale_factors[i] for i in indices]\n",
    "        self.centers_for_translations = [self.all_centers_for_translations[i] for i in indices]\n",
    "        self.models = nn.ModuleList([self.all_models[i] for i in indices])\n",
    "        self.n = len(indices)\n",
    "        self.netp = get_stateless_net_with_partials(self, use_x_and_z_arg=True)\n",
    "\n",
    "    def reset_submodels(self):\n",
    "        \"\"\"\n",
    "        Reset the active submodels to the original full configuration.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.configs = self.all_configs.copy() if isinstance(self.all_configs, list) else self.all_configs\n",
    "        self.bounds = self.all_bounds.copy() if isinstance(self.all_bounds, list) else self.all_bounds\n",
    "        self.scale_factors = self.all_scale_factors.copy() if isinstance(self.all_scale_factors, list) else self.all_scale_factors\n",
    "        self.centers_for_translations = self.all_centers_for_translations.copy() if isinstance(self.all_centers_for_translations, list) else self.all_centers_for_translations\n",
    "        self.models = nn.ModuleList(self.all_models)\n",
    "        self.n = self.all_n\n",
    "        self.netp = get_stateless_net_with_partials(self, use_x_and_z_arg=True)\n",
    "\n",
    "class SimpleNeuralCBFController(CBFController):\n",
    "    \"\"\"\n",
    "    A neural CBF controller. Differs from the CBFController in that it uses a\n",
    "    neural network to learn the CBF.\n",
    "\n",
    "    More specifically, the CBF controller looks for a V such that\n",
    "\n",
    "    V(safe) < 0\n",
    "    V(unsafe) > 0\n",
    "    dV/dt <= -lambda V\n",
    "\n",
    "    This proves forward invariance of the 0-sublevel set of V, and since the safe set is\n",
    "    a subset of this sublevel set, we prove that the unsafe region is not reachable from\n",
    "    the safe region.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dynamics_model: ControlAffineSystem,\n",
    "        scenarios,\n",
    "        V_nn: nn.Module,  # Pass the neural network as an argument\n",
    "        cbf_lambda: float = 1.0,\n",
    "        cbf_relaxation_penalty: float = 50.0,\n",
    "        small_control_penalty: float = 10.0,\n",
    "        small_control_thresh: float = 0.5,\n",
    "        scale_parameter: float = 10.0,\n",
    "        controller_period: float = 0.01,\n",
    "        disable_gurobi: bool = True,\n",
    "        z = torch.tensor([1]),\n",
    "        agent_rad = 0,\n",
    "        device = 'cpu',\n",
    "        xy_only=True\n",
    "    ):\n",
    "        \"\"\"Initialize the controller.\n",
    "\n",
    "        args:\n",
    "            dynamics_model: the control-affine dynamics of the underlying system\n",
    "            scenarios: a list of parameter scenarios to train on\n",
    "            experiment_suite: defines the experiments to run during training\n",
    "            cbf_hidden_layers: number of hidden layers to use for the CLBF network\n",
    "            cbf_hidden_size: number of neurons per hidden layer in the CLBF network\n",
    "            cbf_lambda: convergence rate for the CLBF\n",
    "            cbf_relaxation_penalty: the penalty for relaxing CLBF conditions.\n",
    "            controller_period: the timestep to use in simulating forward Vdot\n",
    "            primal_learning_rate: the learning rate for SGD for the network weights,\n",
    "                                  applied to the CLBF decrease loss\n",
    "            scale_parameter: normalize non-angle data points to between +/- this value.\n",
    "            learn_shape_epochs: number of epochs to spend just learning the shape\n",
    "            use_relu: if True, use a ReLU network instead of Tanh\n",
    "        \"\"\"\n",
    "        super(SimpleNeuralCBFController, self).__init__(\n",
    "            dynamics_model=dynamics_model,\n",
    "            scenarios=scenarios,\n",
    "            experiment_suite=None,\n",
    "            cbf_lambda=cbf_lambda,\n",
    "            cbf_relaxation_penalty=cbf_relaxation_penalty,\n",
    "            controller_period=controller_period\n",
    "        )\n",
    "        # self.save_hyperparameters()\n",
    "\n",
    "        # TODO: Resolve 'clf_relaxation_penalty_weight' vs 'cbf_relaxation_penalty'\n",
    "        self.clf_relaxation_penalty_weight = cbf_relaxation_penalty  # Default weight for CLF relaxation penalty\n",
    "        self.small_control_penalty_weight = small_control_penalty  # Default weight for small control penalty\n",
    "        self.small_control_threshold = small_control_thresh  # Threshold for small control magnitude\n",
    "\n",
    "        self.disable_gurobi = disable_gurobi\n",
    "        self.V_nn = V_nn\n",
    "        self.z = z\n",
    "        # self.qp_relaxation_penalty = None\n",
    "        self.device = device\n",
    "        self.small_control_penalty = small_control_penalty\n",
    "        self.small_control_thresh = small_control_thresh\n",
    "        self.lip = 0\n",
    "        self.agent_rad = agent_rad\n",
    "\n",
    "        # Save the provided model\n",
    "        # self.dynamics_model = dynamics_model\n",
    "        self.scenarios = scenarios\n",
    "        self.n_scenarios = len(scenarios)\n",
    "\n",
    "        # Some of the dimensions might represent angles. We want to replace these\n",
    "        # dimensions with two dimensions: sin and cos of the angle. To do this, we need\n",
    "        # to figure out how many numbers are in the expanded state\n",
    "        n_angles = len(self.dynamics_model.angle_dims)\n",
    "        self.n_dims_extended = self.dynamics_model.n_dims + n_angles\n",
    "\n",
    "        # Compute and save the center and range of the state variables\n",
    "        x_max, x_min = dynamics_model.state_limits\n",
    "        self.x_center = (x_max + x_min) / 2.0\n",
    "        self.x_range = (x_max - x_min) / 2.0\n",
    "        # Scale to get the input between (-k, k), centered at 0\n",
    "        self.k = scale_parameter\n",
    "        self.x_range = self.x_range / self.k\n",
    "        # We shouldn't scale or offset any angle dimensions\n",
    "        self.x_center[self.dynamics_model.angle_dims] = 0.0\n",
    "        self.x_range[self.dynamics_model.angle_dims] = 1.0\n",
    "\n",
    "        ########## optimization\n",
    "\n",
    "        # Save the other parameters\n",
    "        clf_lambda = cbf_lambda\n",
    "        clf_relaxation_penalty = cbf_relaxation_penalty\n",
    "\n",
    "        self.clf_lambda = clf_lambda\n",
    "        self.safe_level: Union[torch.Tensor, float]\n",
    "        self.unsafe_level: Union[torch.Tensor, float]\n",
    "        self.clf_relaxation_penalty = clf_relaxation_penalty\n",
    "\n",
    "        # Since we want to be able to solve the CLF-QP differentiably, we need to set\n",
    "        # up the CVXPyLayers optimization. First, we define variables for each control\n",
    "        # input and the relaxation in each scenario\n",
    "        u = cp.Variable(self.dynamics_model.n_controls)\n",
    "        clf_relaxations = []\n",
    "        for scenario in self.scenarios:\n",
    "            clf_relaxations.append(cp.Variable(1, nonneg=True))\n",
    "\n",
    "        V_param = cp.Parameter(1, nonneg=True)\n",
    "        Lf_V_params = []\n",
    "        Lg_V_params = []\n",
    "        for scenario in self.scenarios:\n",
    "            Lf_V_params.append(cp.Parameter(1))\n",
    "            Lg_V_params.append(cp.Parameter(self.dynamics_model.n_controls))\n",
    "\n",
    "        clf_relaxation_penalty_param = cp.Parameter(1, nonneg=True)\n",
    "        u_ref_param = cp.Parameter(self.dynamics_model.n_controls)\n",
    "        agent_rad_param = cp.Parameter(1)\n",
    "        lip_param = cp.Parameter(1)\n",
    "\n",
    "        # These allow us to define the constraints\n",
    "        constraints = []\n",
    "        for i in range(len(self.scenarios)):\n",
    "            constraints.append(\n",
    "                Lf_V_params[i]\n",
    "                + Lg_V_params[i] @ u\n",
    "                >= clf_lambda * (V_param - agent_rad_param) - clf_relaxations[i] + lip_param\n",
    "            )\n",
    "\n",
    "        upper_lim, lower_lim = self.dynamics_model.control_limits\n",
    "        for control_idx in range(self.dynamics_model.n_controls):\n",
    "            constraints.append(u[control_idx] >= lower_lim[control_idx])\n",
    "            constraints.append(u[control_idx] <= upper_lim[control_idx])\n",
    "        if xy_only:\n",
    "            constraints.append(u[2] == 0)\n",
    "\n",
    "        objective_expression = cp.norm(u - u_ref_param, p=2)\n",
    "        for r in clf_relaxations:\n",
    "            objective_expression += cp.multiply(clf_relaxation_penalty_param, r)\n",
    "        objective = cp.Minimize(objective_expression)\n",
    "\n",
    "        for r in clf_relaxations:\n",
    "            objective_expression += cp.multiply(clf_relaxation_penalty_param, r)\n",
    "\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        assert problem.is_dpp()\n",
    "        variables = [u] + clf_relaxations\n",
    "        parameters = Lf_V_params + Lg_V_params\n",
    "        parameters += [V_param, u_ref_param, clf_relaxation_penalty_param, agent_rad_param, lip_param]\n",
    "        self.differentiable_qp_solver = CvxpyLayer(\n",
    "            problem, variables=variables, parameters=parameters\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def cbf_lambda(self):\n",
    "        \"\"\"Rename clf lambda to cbf\"\"\"\n",
    "        return self.clf_lambda\n",
    "\n",
    "    def set_V_nn(self, V_nn: nn.Module):\n",
    "        self.V_nn = V_nn\n",
    "\n",
    "    def set_lipshitz(self, val):\n",
    "        self.lip = val\n",
    "\n",
    "    def _solve_CLF_QP_cvxpylayers(\n",
    "            self,\n",
    "            x: torch.Tensor,\n",
    "            u_ref: torch.Tensor,\n",
    "            V: torch.Tensor,\n",
    "            Lf_V: torch.Tensor,\n",
    "            Lg_V: torch.Tensor,\n",
    "            relaxation_penalty: float,\n",
    "            lip = 0,\n",
    "            agent_rad = 0\n",
    "        ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "            \"\"\"Determine the control input for a given state using a QP. Solves the QP using\n",
    "            CVXPyLayers, which does allow for backpropagation, but is slower and less\n",
    "            accurate than Gurobi.\n",
    "\n",
    "            args:\n",
    "                x: bs x self.dynamics_model.n_dims tensor of state\n",
    "                u_ref: bs x self.dynamics_model.n_controls tensor of reference controls\n",
    "                V: bs x 1 tensor of CLF values,\n",
    "                Lf_V: bs x 1 tensor of CLF Lie derivatives,\n",
    "                Lg_V: bs x self.dynamics_model.n_controls tensor of CLF Lie derivatives,\n",
    "                relaxation_penalty: the penalty to use for CLF relaxation.\n",
    "            returns:\n",
    "                u: bs x self.dynamics_model.n_controls tensor of control inputs\n",
    "                relaxation: bs x 1 tensor of how much the CLF had to be relaxed in each\n",
    "                            case\n",
    "            \"\"\"\n",
    "\n",
    "            # print(x.shape)\n",
    "            # print(u_ref.shape)\n",
    "            # print(V.shape)\n",
    "            # print(Lf_V.shape)\n",
    "            # print(Lg_V.shape)\n",
    "            # print(relaxation_penalty)\n",
    "\n",
    "            relaxation_penalty = min(relaxation_penalty, 1e6)\n",
    "\n",
    "            # print(\"l\", lip.reshape(-1, 1).shape)\n",
    "            # print(\"v\", V.reshape(-1, 1).shape)\n",
    "\n",
    "            params = []\n",
    "            for i in range(self.n_scenarios):\n",
    "                params.append(Lf_V[:, i, :])\n",
    "            for i in range(self.n_scenarios):\n",
    "                params.append(Lg_V[:, i, :])\n",
    "            params.append(V.reshape(-1, 1))\n",
    "            params.append(u_ref)\n",
    "            params.append(torch.tensor([relaxation_penalty]).type_as(x))\n",
    "            params.append(lip.reshape(-1, 1).type_as(x))\n",
    "            params.append(torch.tensor([agent_rad]).type_as(x))\n",
    "\n",
    "            # print()\n",
    "            # print(x)\n",
    "            # print(u_ref)\n",
    "            # print(V)\n",
    "            # print(Lf_V)\n",
    "            # print(Lg_V)\n",
    "\n",
    "            result = self.differentiable_qp_solver(\n",
    "                *params,\n",
    "                solver_args={\"max_iters\": 1500},\n",
    "            )\n",
    "\n",
    "            u_result = result[0]\n",
    "            r_result = torch.hstack(result[1:])\n",
    "\n",
    "            # print(\"res\", u_result.type_as(x))\n",
    "\n",
    "            return u_result.type_as(x), r_result.type_as(x)\n",
    "\n",
    "    def solve_CLF_QP(\n",
    "        self,\n",
    "        x,\n",
    "        relaxation_penalty: Optional[float] = None,\n",
    "        u_ref: Optional[torch.Tensor] = None,\n",
    "        requires_grad: bool = False,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Determine the control input for a given state using a QP\n",
    "\n",
    "        args:\n",
    "            x: bs x self.dynamics_model.n_dims tensor of state\n",
    "            relaxation_penalty: the penalty to use for CLF relaxation, defaults to\n",
    "                                self.clf_relaxation_penalty\n",
    "            u_ref: allows the user to supply a custom reference input, which will\n",
    "                   bypass the self.u_reference function. If provided, must have\n",
    "                   dimensions bs x self.dynamics_model.n_controls. If not provided,\n",
    "                   default to calling self.u_reference.\n",
    "            requires_grad: if True, use a differentiable layer\n",
    "        returns:\n",
    "            u: bs x self.dynamics_model.n_controls tensor of control inputs\n",
    "            relaxation: bs x 1 tensor of how much the CLF had to be relaxed in each\n",
    "                        case\n",
    "        \"\"\"\n",
    "\n",
    "        V = self.V(x).to(device)\n",
    "        Lf_V, Lg_V = self.V_lie_derivatives(x)\n",
    "\n",
    "        if u_ref is not None:\n",
    "            err_message = f\"u_ref must have {x.shape[0]} rows, but got {u_ref.shape[0]}\"\n",
    "            assert u_ref.shape[0] == x.shape[0], err_message\n",
    "            err_message = f\"u_ref must have {self.dynamics_model.n_controls} cols,\"\n",
    "            err_message += f\" but got {u_ref.shape[1]}\"\n",
    "            assert u_ref.shape[1] == self.dynamics_model.n_controls, err_message\n",
    "        else:\n",
    "            u_ref = self.u_reference(x)\n",
    "\n",
    "        if relaxation_penalty is None:\n",
    "            relaxation_penalty = self.clf_relaxation_penalty\n",
    "        \n",
    "        lip = self.lip\n",
    "        agent_rad = self.agent_rad\n",
    "\n",
    "        # print(V.device)\n",
    "        return self._solve_CLF_QP_cvxpylayers(\n",
    "            x, u_ref, V, Lf_V, Lg_V, relaxation_penalty, lip, agent_rad\n",
    "        )\n",
    "\n",
    "    def V_with_jacobian(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        new_shape = x.shape[:-1] + (1,)\n",
    "        z = torch.full(new_shape, self.z.item()).to(self.device)\n",
    "\n",
    "        out = self.V_nn(x, z).to(self.device)\n",
    "        jac = self.V_nn.get_jacobian(x, z).to(self.device)\n",
    "        return out, jac\n",
    "\n",
    "    def descent_loss(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        requires_grad: bool = False,\n",
    "        u_ref = None\n",
    "    ) -> list[tuple[str, torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Evaluate the loss on the CBF due to the descent condition.\n",
    "\n",
    "        args:\n",
    "            x: the points at which to evaluate the loss.\n",
    "            goal_mask: the points in x marked as part of the goal.\n",
    "            safe_mask: the points in x marked safe.\n",
    "            unsafe_mask: the points in x marked unsafe.\n",
    "            accuracy: if True, return the accuracy (from 0 to 1) as well as the losses.\n",
    "            requires_grad: if True, use a differentiable QP solver.\n",
    "        returns:\n",
    "            loss: a list of tuples containing (\"category_name\", loss_value).\n",
    "        \"\"\"\n",
    "        # Compute loss to encourage satisfaction of the descent condition.\n",
    "        loss = []\n",
    "\n",
    "        # Get the control input and relaxation from solving the QP, and aggregate\n",
    "        # the relaxation across scenarios.\n",
    "        u_qp, qp_relaxation = self.solve_CLF_QP(x, requires_grad=requires_grad, u_ref = u_ref)\n",
    "        qp_relaxation = torch.mean(qp_relaxation, dim=-1)\n",
    "\n",
    "        # Minimize the QP relaxation to encourage satisfying the decrease condition.\n",
    "        qp_relaxation_loss = qp_relaxation.mean()\n",
    "        loss.append((\"QP relaxation\", qp_relaxation_loss))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def get_optimal_control(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        requires_grad: bool = False,\n",
    "        u_ref = None\n",
    "    ) -> list[tuple[str, torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Evaluate the loss on the CBF due to the descent condition.\n",
    "\n",
    "        args:\n",
    "            x: the points at which to evaluate the loss.\n",
    "            goal_mask: the points in x marked as part of the goal.\n",
    "            safe_mask: the points in x marked safe.\n",
    "            unsafe_mask: the points in x marked unsafe.\n",
    "            accuracy: if True, return the accuracy (from 0 to 1) as well as the losses.\n",
    "            requires_grad: if True, use a differentiable QP solver.\n",
    "        returns:\n",
    "            loss: a list of tuples containing (\"category_name\", loss_value).\n",
    "        \"\"\"\n",
    "        # Compute loss to encourage satisfaction of the descent condition.\n",
    "        loss = []\n",
    "\n",
    "        # Get the control input and relaxation from solving the QP, and aggregate\n",
    "        # the relaxation across scenarios.\n",
    "        dev = self.device\n",
    "        self.device = 'cpu'\n",
    "        u_qp, qp_relaxation = self.solve_CLF_QP(x, requires_grad=requires_grad, u_ref=u_ref)\n",
    "        self.device = dev\n",
    "        qp_relaxation = torch.mean(qp_relaxation, dim=-1)\n",
    "        self.qp_relaxation_penalty = qp_relaxation\n",
    "\n",
    "        return u_qp\n",
    "  \n",
    "    def V_lie_derivatives(\n",
    "        self, x: torch.Tensor, scenarios = None\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Compute the Lie derivatives of the CLF V along the control-affine dynamics\n",
    "\n",
    "        args:\n",
    "            x: bs x self.dynamics_model.n_dims tensor of state\n",
    "            scenarios: optional list of scenarios. Defaults to self.scenarios\n",
    "        returns:\n",
    "            Lf_V: bs x len(scenarios) x 1 tensor of Lie derivatives of V\n",
    "                  along f\n",
    "            Lg_V: bs x len(scenarios) x self.dynamics_model.n_controls tensor\n",
    "                  of Lie derivatives of V along g\n",
    "        \"\"\"\n",
    "        if scenarios is None:\n",
    "            scenarios = self.scenarios\n",
    "        n_scenarios = len(scenarios)\n",
    "\n",
    "        # Get the Jacobian of V for each entry in the batch\n",
    "        _, gradV = self.V_with_jacobian(x)\n",
    "        gradV = gradV.to(device) # N x 3\n",
    "        gradV = gradV.unsqueeze(1) # N x 3 x 1\n",
    "\n",
    "        # We need to compute Lie derivatives for each scenario\n",
    "        batch_size = x.shape[0]\n",
    "        Lf_V = torch.zeros(batch_size, n_scenarios, 1)\n",
    "        Lg_V = torch.zeros(batch_size, n_scenarios, self.dynamics_model.n_controls)\n",
    "        Lf_V = Lf_V.type_as(x)\n",
    "        Lg_V = Lg_V.type_as(x)\n",
    "\n",
    "        for i in range(n_scenarios):\n",
    "            # Get the dynamics f and g for this scenario\n",
    "            s = scenarios[i]\n",
    "            f, g = self.dynamics_model.control_affine_dynamics(x, params=s)\n",
    "            f = f.to(device) # N x 3 x 1\n",
    "            g = g.to(device)\n",
    "            \n",
    "            Lf_V[:, i, :] = torch.bmm(gradV, f).squeeze(1)\n",
    "            Lg_V[:, i, :] = torch.bmm(gradV, g).squeeze(1)\n",
    "\n",
    "        # return the Lie derivatives\n",
    "        return Lf_V, Lg_V\n",
    "\n",
    "class Simple3DRobot(ControlAffineSystem):\n",
    "    \"\"\"\n",
    "    Represents a minimal 3D robot system.\n",
    "\n",
    "    The system has state:\n",
    "        x = [px, py, pz]\n",
    "\n",
    "    representing the position of the robot in 3D space, and control inputs:\n",
    "        u = [vx, vy, vz]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of states and controls\n",
    "    N_DIMS = 3\n",
    "    N_CONTROLS = 3\n",
    "\n",
    "    # State indices\n",
    "    PX = 0\n",
    "    PY = 1\n",
    "    PZ = 2\n",
    "    # PZZ = 3\n",
    "\n",
    "    # Control indices\n",
    "    VX = 0\n",
    "    VY = 1\n",
    "    VZ = 2\n",
    "    # VZZ = 3\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        nominal_params: dict = None,\n",
    "        dt: float = 0.01,\n",
    "        controller_dt = None,\n",
    "        scenarios = None,\n",
    "        device = 'cpu'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the robot system.\n",
    "\n",
    "        args:\n",
    "            nominal_params: optional parameters for the system (not used here).\n",
    "            dt: the timestep to use for the simulation.\n",
    "            controller_dt: the timestep for the LQR discretization. Defaults to dt.\n",
    "    \"\"\"\n",
    "        self.device = device\n",
    "        print(\"CREATED SIMPLE3D\")\n",
    "        super().__init__(nominal_params or {}, dt, controller_dt)\n",
    "\n",
    "    def validate_params(self, params: dict) -> bool:\n",
    "        \"\"\"Check if a given set of parameters is valid.\"\"\"\n",
    "        # No specific parameters to validate for this system.\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def n_dims(self) -> int:\n",
    "        return Simple3DRobot.N_DIMS\n",
    "    \n",
    "    @property\n",
    "    def angle_dims(self) -> list[int]:\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def n_controls(self) -> int:\n",
    "        return Simple3DRobot.N_CONTROLS\n",
    "\n",
    "    @property\n",
    "    def state_limits(self) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Return a tuple (upper, lower) describing the expected range of states for this\n",
    "        system.\n",
    "        \"\"\"\n",
    "        upper_limit = torch.tensor([50.0, 50.0, 50.0])\n",
    "        lower_limit = -upper_limit\n",
    "        return (upper_limit, lower_limit)\n",
    "\n",
    "    @property\n",
    "    def control_limits(self) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Return a tuple (upper, lower) describing the range of allowable control\n",
    "        limits for this system.\n",
    "        \"\"\"\n",
    "        upper_limit = torch.tensor([1.0, 1.0, 1.0])\n",
    "        lower_limit = -upper_limit\n",
    "        return (upper_limit, lower_limit)\n",
    "\n",
    "    def safe_mask(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Return the mask of x indicating safe regions.\"\"\"\n",
    "        # Assume the entire space is safe for simplicity.\n",
    "        return torch.ones_like(x[:, 0], dtype=torch.bool)\n",
    "\n",
    "    def unsafe_mask(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Return the mask of x indicating unsafe regions.\"\"\"\n",
    "        # Assume no unsafe regions for simplicity.\n",
    "        return torch.zeros_like(x[:, 0], dtype=torch.bool)\n",
    "\n",
    "    def goal_mask(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Return the mask of x indicating points in the goal set.\"\"\"\n",
    "        goal_radius = 0.2\n",
    "        goal_center = torch.tensor([0.0, 0.0, 0.0])\n",
    "        goal_mask = (x - goal_center).norm(dim=-1) <= goal_radius\n",
    "        return goal_mask\n",
    "\n",
    "    def _f(self, x: torch.Tensor, params: dict) -> torch.Tensor:\n",
    "        # \"\"\"\n",
    "        # Introduces a gravity-like force in the negative z-direction.\n",
    "        # This means that if no control is applied, the robot will fall.\n",
    "        # \"\"\"\n",
    "        # batch_size = x.shape[0]\n",
    "\n",
    "        # # Gravity acceleration (e.g., 9.81 m/s², but scaled by dt)\n",
    "        # g_z = -0.05  # m/s²\n",
    "        # gravity = torch.zeros((batch_size, self.n_dims), device=x.device)\n",
    "        # gravity[:, self.PZ] = g_z  # Apply gravity only in the z-direction\n",
    "\n",
    "        # f = gravity.unsqueeze(-1)  # bs x n_dims x 1\n",
    "        # return f\n",
    "\n",
    "        \"\"\"\n",
    "        No drift\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        force = torch.zeros((batch_size, self.n_dims), device=x.device)\n",
    "        f = force.unsqueeze(-1)  # bs x n_dims x 1\n",
    "        return f\n",
    "\n",
    "\n",
    "    def _g(self, x: torch.Tensor, params: dict) -> torch.Tensor:\n",
    "        # \"\"\"\n",
    "        # Return the control-dependent part of the dynamics.\n",
    "\n",
    "        # args:\n",
    "        #     x: bs x self.n_dims tensor of state.\n",
    "        #     params: parameters for the system (not used here).\n",
    "        # returns:\n",
    "        #     g: bs x self.n_dims x self.n_controls tensor.\n",
    "        # \"\"\"\n",
    "        # batch_size = x.shape[0]\n",
    "        # mat = torch.eye(self.n_dims)\n",
    "        # g = mat.expand(batch_size, -1, -1)\n",
    "        # return g\n",
    "\n",
    "        \"\"\"\n",
    "        no z-axis movement\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        mat = torch.eye(self.n_dims)\n",
    "        g = mat.expand(batch_size, -1, -1)\n",
    "        return g\n",
    "        \n",
    "    @property\n",
    "    def u_eq(self) -> torch.Tensor:\n",
    "        \"\"\"Return the equilibrium control input (zero for this system).\"\"\"\n",
    "        return torch.zeros((1, self.n_controls))\n",
    "\n",
    "    def next_state(self, x: torch.Tensor, u: torch.Tensor, params: dict = None) -> torch.Tensor:\n",
    "        # Get the control-independent and control-dependent dynamics\n",
    "        f = self._f(x, params).to(self.device)  # bs x n_dims x 1\n",
    "        g = self._g(x, params).to(self.device)  # bs x n_dims x n_controls\n",
    "        u = u.to(device)\n",
    "\n",
    "        dx = f.squeeze(-1) + torch.bmm(g, u.unsqueeze(-1)).squeeze(-1)  # bs x n_dims\n",
    "        next_x = x + self.dt * dx  # bs x n_dims\n",
    "\n",
    "        # print(\"dx\", dx, 'dt', self.dt, 'u', u, 'state', next_x)\n",
    "        return next_x\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_line_safe(p1, p2, points_manager, step=0.05, threshold=0.05, sdf=None, zs=None):\n",
    "    \"\"\"\n",
    "    p1, p2: torch.Tensor of shape (3,)\n",
    "    \"\"\"\n",
    "    direction = p2 - p1\n",
    "    dist = torch.norm(direction).item()\n",
    "    if dist == 0:\n",
    "        return True\n",
    "\n",
    "    direction = direction / dist\n",
    "    num_steps = int(dist / step)\n",
    "\n",
    "    for i in range(num_steps + 1):\n",
    "        pt = p1 + i * step * direction\n",
    "\n",
    "        if sdf is not None:\n",
    "            pt = pt.unsqueeze(0).float()\n",
    "            if sdf(pt, zs) <= 0:\n",
    "                return False\n",
    "\n",
    "        if points_manager.get_closest_distance(pt.detach().cpu().numpy()) < threshold:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def get_prm_samples(points_manager, start, goal, num_samples=1500, collision_threshold=0.05, z_range=0.5, sdf=None, zs=None, device='cpu'):\n",
    "    all_points = torch.from_numpy(points_manager.get_all_points())\n",
    "    bounds_min = all_points.min(dim=0).values\n",
    "    bounds_max = all_points.max(dim=0).values\n",
    "\n",
    "    samples = [start, goal]\n",
    "    while len(samples) < num_samples:\n",
    "        p = torch.rand(3) * (bounds_max - bounds_min) + bounds_min\n",
    "        p[2] = torch.rand(1) * z_range + start[2]\n",
    "\n",
    "        if sdf is not None:\n",
    "            pt = p.unsqueeze(0).float().to(device)\n",
    "            if sdf(pt, zs.to(device)) > 0.1:\n",
    "                samples.append(p)\n",
    "\n",
    "        elif sdf is None and points_manager.get_closest_distance(p) > collision_threshold:\n",
    "            samples.append(p)\n",
    "\n",
    "    return samples\n",
    "\n",
    "def build_prm(points_manager, start, goal, num_samples=1500, neighbor_radius=1.0,\n",
    "              collision_threshold=0.05, z_range=0, sdf=None, zs=None, device='cpu', samples=None):\n",
    "    \"\"\"\n",
    "    start, goal: torch.Tensor of shape (3,)\n",
    "    \"\"\"\n",
    "\n",
    "    if not samples:\n",
    "        samples = get_prm_samples(points_manager, start, goal, num_samples, collision_threshold, z_range, sdf, zs, device)\n",
    "    samples_tensor = torch.stack(samples)  # shape (N, 3)\n",
    "    samples_np = samples_tensor.detach().cpu().numpy()  # for KDTree / networkx\n",
    "\n",
    "    tree = cKDTree(samples_np)\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    for i, p in enumerate(samples_tensor):\n",
    "        graph.add_node(i, pos=p)\n",
    "        dists, indices = tree.query(samples_np[i], k=15)\n",
    "        for j in indices:\n",
    "            if i == j:\n",
    "                continue\n",
    "            q = samples_tensor[j]\n",
    "            if is_line_safe(p, q, points_manager, threshold=collision_threshold, sdf=sdf, zs=zs):\n",
    "                weight = torch.norm(p - q).item()\n",
    "                graph.add_edge(i, j, weight=weight)\n",
    "\n",
    "    return graph, samples_tensor\n",
    "\n",
    "def find_path(graph, samples, start, goal, max_waypoints=None):\n",
    "    start_idx, goal_idx = 0, 1\n",
    "    try:\n",
    "        path_indices = nx.shortest_path(graph, source=start_idx, target=goal_idx, weight='weight')\n",
    "        path = samples[path_indices]  # tensor slicing\n",
    "\n",
    "        if max_waypoints is not None and len(path) > max_waypoints:\n",
    "            idxs = torch.linspace(0, len(path) - 1, steps=max_waypoints).long()\n",
    "            path = path[idxs]\n",
    "\n",
    "        return path\n",
    "    except nx.NetworkXNoPath:\n",
    "        return None\n",
    "\n",
    "def generate_safe_path(points_manager, start, goal, num_samples=500, threshold=0.05,\n",
    "                       max_waypoints=None, sdf=None, zs=None, device='cpu', point_samples=None):\n",
    "\n",
    "    if not point_samples is None:\n",
    "        point_samples = get_prm_samples(\n",
    "            points_manager, start, goal,\n",
    "            num_samples=num_samples,\n",
    "            collision_threshold=threshold,\n",
    "            z_range=1e-10,\n",
    "            sdf=sdf,\n",
    "            zs=zs,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "    graph, samples = build_prm(\n",
    "        points_manager, start, goal,\n",
    "        num_samples=num_samples,\n",
    "        collision_threshold=threshold,\n",
    "        sdf=sdf,\n",
    "        zs=zs,\n",
    "        device=device,\n",
    "        samples=point_samples\n",
    "    )\n",
    "\n",
    "    path = find_path(graph, samples, start, goal, max_waypoints=max_waypoints)\n",
    "    return path\n",
    "\n",
    "def plan_single_pair(point_cloud, pm, plane, min_pcd_dist, max_waypoints, threshold, model, min_dist_range=[3, 5]):\n",
    "    while True:\n",
    "        num_pairs_left = num_pairs\n",
    "        test_traj_pairs = []\n",
    "        while num_pairs_left > 0:\n",
    "            test_traj_pairs_tmp = sample_point_pairs(point_cloud, num_pairs=num_pairs_left, num_samples=750, min_pcd_dist=min_pcd_dist, \n",
    "                min_dist_range=min_dist_range, plane=plane, max_iterations=5000, reverse=True, plot=None, corner_scale=0.8)\n",
    "\n",
    "            test_traj_pairs.append(test_traj_pairs_tmp)\n",
    "            break\n",
    "\n",
    "            start_positions = torch.tensor(test_traj_pairs_tmp[:, 0, :], dtype=torch.float32)\n",
    "            goal_positions = torch.tensor(test_traj_pairs_tmp[:, 1, :], dtype=torch.float32)\n",
    "\n",
    "            z_inputs = torch.full((start_positions.shape[0], 1), z_div.item())\n",
    "            V_starts = model(start_positions, z_inputs)\n",
    "            V_goals = model(goal_positions, z_inputs)\n",
    "            mask = ((V_starts > 0.01) & (V_goals > 0.01))\n",
    "            if len(mask.shape) > 1:\n",
    "                mask = mask.squeeze(1)\n",
    "            test_traj_pairs_tmp = test_traj_pairs_tmp[mask.cpu().numpy()]\n",
    "\n",
    "            test_traj_pairs.append(test_traj_pairs_tmp)\n",
    "            num_pairs_left -= len(test_traj_pairs_tmp)\n",
    "            print(\"Left:\", num_pairs_left)\n",
    "\n",
    "        traj_pairs = np.vstack(test_traj_pairs)\n",
    "        start_positions = traj_pairs[:, 0, :]\n",
    "        goal_positions = traj_pairs[:, 1, :]\n",
    "\n",
    "        start = torch.tensor(start_positions[0], dtype=torch.float32)\n",
    "        goal = torch.tensor(goal_positions[0], dtype=torch.float32)\n",
    "\n",
    "        waypoints = generate_safe_path(\n",
    "            pm, start, goal,\n",
    "            num_samples=2000,\n",
    "            max_waypoints=max_waypoints,\n",
    "            threshold=threshold\n",
    "        )\n",
    "\n",
    "        if waypoints is not None:\n",
    "            return traj_pairs, waypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_wall', '1_lamp', '2_table', '3_table', '4_table', '5_stool', '6_chair', '7_sofa', '8_stool', '9_chair', '10_table', '11_lamp']\n",
      "tensor([1.], device='cuda:0') torch.Size([1])\n",
      "12.0400390625\n",
      "2.78934907913208\n",
      "2.7642860412597656\n",
      "1.1761901378631592\n",
      "11.998461723327637\n",
      "2.7637178897857666\n",
      "2.7393476963043213\n",
      "1.0115344524383545\n",
      "11.98237419128418\n",
      "2.7677195072174072\n",
      "2.738888740539551\n",
      "1.028771162033081\n",
      "12.015559196472168\n",
      "2.772770881652832\n",
      "2.751063346862793\n",
      "1.0484939813613892\n",
      "11.964972496032715\n",
      "2.7538952827453613\n",
      "2.7435104846954346\n",
      "1.0575122833251953\n",
      "11.988473892211914\n",
      "2.737168073654175\n",
      "2.7323336601257324\n",
      "1.0281420946121216\n",
      "11.971397399902344\n",
      "2.7361273765563965\n",
      "2.734482765197754\n",
      "1.0225328207015991\n",
      "12.008108139038086\n",
      "2.7824547290802\n",
      "2.7613284587860107\n",
      "1.1321728229522705\n",
      "11.990635871887207\n",
      "2.743135690689087\n",
      "2.7399404048919678\n",
      "1.037063479423523\n",
      "11.965550422668457\n",
      "2.7408034801483154\n",
      "2.736138343811035\n",
      "1.024815320968628\n",
      "11.993101119995117\n",
      "2.7697863578796387\n",
      "2.7530040740966797\n",
      "1.0751173496246338\n",
      "11.967686653137207\n",
      "2.7471697330474854\n",
      "2.738107681274414\n",
      "1.0196435451507568\n",
      "spectral_norm 1149.9788457222053\n",
      "bounds torch.Size([12, 3, 2]) torch.Size([14, 3, 2]) torch.Size([14, 3, 2])\n",
      "torch.Size([12, 3])\n",
      "torch.Size([12])\n",
      "z_div tensor([1.], device='cuda:0')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 51\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz_div\u001b[39m\u001b[38;5;124m\"\u001b[39m, z_div)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_optimal:\n\u001b[1;32m     50\u001b[0m     point_samples \u001b[38;5;241m=\u001b[39m get_prm_samples(\n\u001b[0;32m---> 51\u001b[0m             pm, \u001b[43mstart\u001b[49m, goal,\n\u001b[1;32m     52\u001b[0m             num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m,\n\u001b[1;32m     53\u001b[0m             collision_threshold\u001b[38;5;241m=\u001b[39mmin_pcd_dist,\n\u001b[1;32m     54\u001b[0m             z_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m     zs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((start\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m), z_div\u001b[38;5;241m.\u001b[39mitem(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     58\u001b[0m     test_traj_pairs \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from joblib import Parallel, delayed\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "#################################################\n",
    "#\n",
    "#   TRAJECTORIES\n",
    "#   TRAJECTORIES\n",
    "#   TRAJECTORIES\n",
    "#\n",
    "##################################################\n",
    "\n",
    "device = 'cuda:0'\n",
    "n1 = 0\n",
    "n2 = len(config_paths) - 2\n",
    "use_adapters = False\n",
    "\n",
    "do_optimal = True\n",
    "max_attempts = 2000\n",
    "num_pairs = 1\n",
    "max_waypoints = 100\n",
    "min_pcd_dist = 0.2\n",
    "plane = (my_plane.point_on_plane, (my_plane.normal))  # Plane centered at (5,5,5), normal along Z\n",
    "# initial_point = np.array([-14.4, 39, 0.6])\n",
    "all_paths = []\n",
    "min_dist_range = [2.5, 7]\n",
    "\n",
    "model, z_div = CBFModel.create_model(config_paths[n1:n2], model_paths[n1:n2], alpha=2, device=device, \n",
    "    all_scale_factors=scale_factors[n1:n2], all_center_translations=centers_for_translations[n1:n2], all_bounds=bounds_objs[n1:n2], use_adapters=use_adapters)\n",
    "print(obj_names[n1:n2])\n",
    "print(z_div, z_div.shape)\n",
    "# z_div = torch.full_like(z_div, 1.0).to(device)\n",
    "\n",
    "spectral_norm = model.compute_spectral_norm()\n",
    "print(\"spectral_norm\", spectral_norm)\n",
    "\n",
    "all_bounds = model.bounds\n",
    "all_scale_factors = model.scale_factors\n",
    "all_center_translations = model.centers_for_translations\n",
    "\n",
    "print('bounds', all_bounds.shape, bounds_objs.shape, bounds.shape)\n",
    "print(model.centers_for_translations.shape)\n",
    "print(model.scale_factors.shape)\n",
    "print(\"z_div\", z_div)\n",
    "\n",
    "if do_optimal:\n",
    "    point_samples = get_prm_samples(\n",
    "            pm, start, goal,\n",
    "            num_samples=2000,\n",
    "            collision_threshold=min_pcd_dist,\n",
    "            z_range=0\n",
    "    )\n",
    "    zs = torch.full((start.shape[0], 1), z_div.item(), dtype=torch.float32)\n",
    "\n",
    "    test_traj_pairs = []\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(plan_single_pair)(\n",
    "            point_cloud, pm, plane, min_pcd_dist, max_waypoints, min_pcd_dist, model, min_dist_range\n",
    "        )\n",
    "        for _ in tqdm(range(num_pairs), desc=\"Planning trajectories in parallel\")\n",
    "    )\n",
    "\n",
    "    test_traj_pairs, all_paths = zip(*results)\n",
    "    test_traj_pairs = list(test_traj_pairs)\n",
    "    all_paths = list(all_paths)\n",
    "    test_traj_pairs = np.concatenate(test_traj_pairs, axis=0)\n",
    "    print(\"all_paths\", len(all_paths), all_paths)\n",
    "else:\n",
    "    bboxes = [\n",
    "        (torch.tensor([2.75, -0.5, -1.8]), torch.tensor([4.4, -0.5, -1.0])),\n",
    "    ]\n",
    "\n",
    "    num_pairs_left = num_pairs\n",
    "    test_traj_pairs = []\n",
    "    while num_pairs_left > 0:\n",
    "        # 1) sample raw pairs\n",
    "        test_traj_pairs_tmp = sample_point_pairs(\n",
    "            point_cloud,\n",
    "            num_pairs=num_pairs_left,\n",
    "            num_samples=750,\n",
    "            min_pcd_dist=min_pcd_dist,\n",
    "            min_dist_range=min_dist_range,\n",
    "            plane=plane,\n",
    "            max_iterations=5000,\n",
    "            reverse=True,\n",
    "            plot=None,\n",
    "            corner_scale=0.8\n",
    "        )\n",
    "\n",
    "        # 2) turn starts/goals into torch tensors for V-score & box tests\n",
    "        start_positions = torch.tensor(test_traj_pairs_tmp[:, 0, :], dtype=torch.float32)\n",
    "        goal_positions  = torch.tensor(test_traj_pairs_tmp[:, 1, :], dtype=torch.float32)\n",
    "\n",
    "        # 3) V-score filter\n",
    "        z_inputs = torch.full((start_positions.shape[0], 1), z_div.item())\n",
    "        V_starts = model(start_positions, z_inputs)\n",
    "        V_goals  = model(goal_positions,  z_inputs)\n",
    "        mask_v   = ((V_starts > 0) & (V_goals > 0)).detach().cpu()\n",
    "        if mask_v.dim() > 1:\n",
    "            mask_v = mask_v.squeeze(1)     # shape [N]\n",
    "\n",
    "        # 4) box filter: build a mask of any point INSIDE _any_ bbox\n",
    "        mask_box = torch.zeros_like(mask_v, dtype=torch.bool)\n",
    "        for bl, tr in bboxes:\n",
    "            bl, tr = bl, tr\n",
    "            inside_start = ((start_positions >= bl) & (start_positions <= tr)).all(dim=1)\n",
    "            inside_goal  = ((goal_positions  >= bl) & (goal_positions  <= tr)).all(dim=1)\n",
    "            mask_box |= (inside_start | inside_goal)\n",
    "\n",
    "        # 5) combine V-score _and_ “not in box”\n",
    "        mask_final = mask_v & (~mask_box)\n",
    "\n",
    "        # 6) apply to your numpy pairs\n",
    "        valid_pairs = test_traj_pairs_tmp[mask_final.cpu().numpy()]\n",
    "\n",
    "        test_traj_pairs.append(valid_pairs)\n",
    "        num_pairs_left -= valid_pairs.shape[0]\n",
    "        print(\"Left:\", num_pairs_left)\n",
    "        if num_pairs_left <= 0:\n",
    "            break\n",
    "\n",
    "        if max_attempts <= 0: break\n",
    "        max_attempts -= 1\n",
    "        \n",
    "    test_traj_pairs = np.vstack(test_traj_pairs)\n",
    "\n",
    "print(\"test_traj_pairs:\", test_traj_pairs.shape)\n",
    "\n",
    "# Extract start (N, 3) and goal (N, 3) positions\n",
    "start_positions = test_traj_pairs[:, 0, :]\n",
    "goal_positions = test_traj_pairs[:, 1, :]\n",
    "print(\"starting\",start_positions)\n",
    "print(\"goals\", goal_positions)\n",
    "\n",
    "# Track active indices\n",
    "active_mask = torch.ones(start_positions.shape[0], dtype=torch.bool)  # All initially active\n",
    "num_active = active_mask.sum().item()  # Count active states\n",
    "\n",
    "use_subset = False\n",
    "test_traj_pairs_cpy = test_traj_pairs.copy()\n",
    "\n",
    "print(config_paths[n1:n2], model_paths[n1:n2], scale_factors[n1:n2], centers_for_translations[n1:n2], bounds_objs[n1:n2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined = np.hstack([start_positions, goal_positions])\n",
    "# columns = ['start_x', 'start_y', 'start_z', 'goal_x', 'goal_y', 'goal_z']\n",
    "# df = pd.DataFrame(combined, columns=columns)\n",
    "\n",
    "# save_to = \"goal_csvs\"\n",
    "# prefix = f\"{env_name}\"\n",
    "# if do_optimal:\n",
    "#     prefix += \"_optimal\"\n",
    "# df.to_csv(f'{save_to}/{prefix}_start_goal.csv', index=False)\n",
    "\n",
    "# print(\"saving to...\", f'goal_csvs/{env_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "use_subset = False\n",
    "\n",
    "if use_subset:\n",
    "    if test_traj_pairs.shape[0] == test_traj_pairs_cpy.shape[0]:\n",
    "        test_traj_pairs_cpy = test_traj_pairs.copy()\n",
    "        test_traj_pairs = test_traj_pairs[[30]]\n",
    "else:\n",
    "    test_traj_pairs = test_traj_pairs_cpy.copy()\n",
    "\n",
    "\n",
    "print(test_traj_pairs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "CREATED SIMPLE3D\n",
      "{}\n",
      "cbf_lambda -0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to models 2 [0, 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 101/5000 [00:08<06:59, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - Did not move!\n",
      "inactivation_reasons: {0: 'Stopped moving'}\n",
      "durations: {0: 101}\n",
      "avg_time: 0.066375311683206\n",
      "avg control time: 0.05766040437361773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def point_in_bbox(bbox: torch.Tensor, point: torch.Tensor) -> bool:\n",
    "    lower, upper = bbox[0], bbox[1]\n",
    "    return torch.all(point >= lower) and torch.all(point <= upper)\n",
    "\n",
    "still = 0\n",
    "avg_time = 0\n",
    "# step_size = 1/2\n",
    "max_iterations = 2000\n",
    "threshold = 0.25\n",
    "still_limit = 50\n",
    "step_size = simulation_dt = 0.1\n",
    "\n",
    "# cbf_lambda = -0.175\n",
    "# min_cbf_lambda = -0.05\n",
    "cbf_lambda = -0.175\n",
    "min_cbf_lambda = -0.05\n",
    "\n",
    "\n",
    "model.alpha = 4\n",
    "model.mask_dist = 0.4\n",
    "# model.alpha = 25\n",
    "# model.mask_dist = 0.01\n",
    "\n",
    "model.do_mask = True\n",
    "model.upper_bound = 5\n",
    "model.scale = 1\n",
    "\n",
    "model_to_move = None # the chair\n",
    "move_model_t = 3\n",
    "move_counter = 10\n",
    "\n",
    "# Store states at each timestep\n",
    "states_over_time = []  \n",
    "values_over_time = []  \n",
    "lie_g_over_time = []  \n",
    "lie_f_over_time = []  \n",
    "u_over_time = []  \n",
    "urefs_over_time = []  \n",
    "inactivation_reasons = {}  # Track why each state became inactive\n",
    "durations = {}  # Track why each state became inactive\n",
    "lips = []\n",
    "\n",
    "total_control_time = 0\n",
    "\n",
    "start_positions = test_traj_pairs[:, 0, :]\n",
    "goal_positions = test_traj_pairs[:, 1, :]\n",
    "print(goal_positions.shape)\n",
    "# goal_positions[0][2] = start_positions[0][2] = -1.35\n",
    "wp_indices = [0] * len(all_paths)\n",
    "\n",
    "states = torch.tensor(start_positions, dtype=torch.float32).to(device)\n",
    "start_positions = goal_states = torch.tensor(goal_positions, dtype=torch.float32).to(device)\n",
    "states[:, 2] = -1.3\n",
    "goal_states[:, 2] = -1.3\n",
    "\n",
    "active_mask = torch.ones(states.shape[0], dtype=torch.bool).to(device)  # All initially active\n",
    "num_active = active_mask.sum().item()  # Count active states\n",
    "\n",
    "nominal_params = {}\n",
    "scenarios = [\n",
    "    nominal_params,\n",
    "]\n",
    "\n",
    "# Define the dynamics model\n",
    "dynamics_model = Simple3DRobot(\n",
    "    nominal_params,\n",
    "    dt=simulation_dt,\n",
    "    scenarios=scenarios,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "if num_pairs == 1 and not model_to_move is None:\n",
    "    print(\"WILL BE MOVING GINNs TO OBSTRUCT AGENT!\")\n",
    "\n",
    "# Initialize the controller\n",
    "cbf_controller = SimpleNeuralCBFController(\n",
    "    dynamics_model,\n",
    "    scenarios,\n",
    "    model.to(device),\n",
    "    cbf_lambda=cbf_lambda,\n",
    "    cbf_relaxation_penalty=3,\n",
    "    z = torch.tensor([[z_div.item()]]),\n",
    "    device = device,\n",
    "    agent_rad = 0\n",
    ")\n",
    "\n",
    "model.reset_submodels()\n",
    "prev_model_n = 0\n",
    "zs = torch.full((states.shape[0], 1), z_div.item()).to(device)\n",
    "\n",
    "print(\"cbf_lambda\", cbf_lambda)\n",
    "\n",
    "if os.path.exists(os.path.join(os.getcwd(),'stopnow')):\n",
    "    os.remove(os.path.join(os.getcwd(),'stopnow'))\n",
    "\n",
    "for iteration in tqdm(range(max_iterations)):\n",
    "    if os.path.exists(os.path.join(os.getcwd(),'stopnow')):\n",
    "        # /sfs/weka/scratch/rhm4nj/cral/cral-ginn/ginn/stopnow\n",
    "        print(\"Manual stop\")\n",
    "        break\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if active_mask.sum().item() == 0:  # Stop if all states have reached their goal\n",
    "        break\n",
    "\n",
    "    if not model_to_move:\n",
    "        model_indices = model.get_submodel_in_rad(states[active_mask], step_size * 4)\n",
    "        # print(\"Using submodels:\", len(model_indices), model_indices)\n",
    "        if len(model_indices) != 0:\n",
    "            model.set_submodels(model_indices)\n",
    "        else:\n",
    "            model.set_submodels([0])\n",
    "\n",
    "        if len(model_indices) != prev_model_n:\n",
    "            print(\"Switched to models\", len(model_indices), model_indices)\n",
    "        prev_model_n = len(model_indices)\n",
    "\n",
    "        cbf_controller.set_V_nn(model.to(device))\n",
    "\n",
    "    distances = torch.norm(states[active_mask] - goal_states[active_mask], dim=1)\n",
    "    reached_goal = distances < threshold\n",
    "\n",
    "    # Move GINN to block agent\n",
    "    if num_pairs == 1 and not model_to_move is None and do_optimal:\n",
    "        wp_idx = wp_indices[0]\n",
    "        move_to = all_paths[0][wp_idx].float()\n",
    "        agent_pos = states[0]\n",
    "\n",
    "        print(move_counter, move_model_t, wp_indices[0])\n",
    "        if move_counter >= move_model_t and wp_indices[0] >= wp_idx - 1:\n",
    "            model.move_model(model_to_move, move_to)\n",
    "\n",
    "            while point_in_bbox(agent_pos, model.bounds[model_to_move].T):\n",
    "                wp_idx = min(wp_idx + 1, len(all_paths[0]) - 1)\n",
    "                move_to = waypoints[0][wp_idx]\n",
    "                if wp_idx >= len(all_paths[0]):\n",
    "                    move_to = model.all_centers_for_translations[move_to_move]\n",
    "\n",
    "                model.move_model(model_to_move, move_to)\n",
    "            print(\"Moved model to:\", move_to)\n",
    "            move_counter = 0\n",
    "\n",
    "        move_counter += 1\n",
    "\n",
    "    # Mark states as inactive if they reached their goal\n",
    "    inactive_indices = torch.where(active_mask.clone())[0][reached_goal]\n",
    "    for idx in inactive_indices:\n",
    "        inactivation_reasons[int(idx)] = \"goal_reached\"\n",
    "        durations[int(idx)] = iteration\n",
    "        print(\"PASS\", int(idx), \"REMAINING\", active_mask.sum().item() - 1)\n",
    "        # print(\"active_mask\", active_mask)\n",
    "    active_mask[active_mask.clone()] = ~reached_goal  # Update active mask\n",
    "\n",
    "    if active_mask.sum().item() == 0:\n",
    "        print(\"DONE!\")\n",
    "        break\n",
    "\n",
    "    V = torch.full((states.shape[0], 1), -1.0).to(device)\n",
    "    V[active_mask] = model(states[active_mask], zs[active_mask])\n",
    "    # print(\"lipshitz\", model.compute_softmax_lipschitz(states, zs))\n",
    "\n",
    "    unsafe_mask = V < 0\n",
    "    unsafe_indices = torch.where(unsafe_mask.clone())[0]  # Get indices of active elements\n",
    "    for idx in unsafe_indices:\n",
    "        if active_mask[idx]:\n",
    "            inactivation_reasons[int(idx)] = \"unsafe_region\"\n",
    "            durations[int(idx)] = iteration\n",
    "            active_mask[idx] = 0\n",
    "            print(\"FAIL unsafe_region\", int(idx), \"TIME\", iteration, \"STATE\", states[idx], \"h(x)\", V[idx], \"MIs\", model_indices, \"REMAINING\", active_mask.sum())\n",
    "            if iteration == 0:\n",
    "                print(\"Initialized in an unsafe state!\")\n",
    "\n",
    "    if active_mask.sum().item() == 0:  # Stop if all states have reached their goal\n",
    "        break\n",
    "\n",
    "    if do_optimal:\n",
    "        wp_targets = torch.empty_like(states)\n",
    "        for i in range(states.shape[0]):\n",
    "            if not active_mask[i]:\n",
    "                wp_targets[i] = goal_states[i]\n",
    "                continue\n",
    "\n",
    "            path = all_paths[i]\n",
    "            if path is None or len(path) == 0:\n",
    "                wp_targets[i] = goal_states[i]\n",
    "                continue\n",
    "\n",
    "            wp_idx = wp_indices[i]\n",
    "            if wp_idx >= len(path):\n",
    "                wp_targets[i] = goal_states[i]\n",
    "                continue\n",
    "\n",
    "            dist_to_wp = torch.norm(states[i] - path[wp_idx])\n",
    "            if dist_to_wp < 0.2:\n",
    "                wp_idx += 1\n",
    "                wp_indices[i] = wp_idx\n",
    "\n",
    "            if wp_idx >= len(path):\n",
    "                wp_targets[i] = goal_states[i]\n",
    "            else:\n",
    "                wp_targets[i] = path[wp_idx]\n",
    "\n",
    "        wp = wp_targets.float()\n",
    "        u_ref = torch.nn.functional.normalize(wp - states) * step_size\n",
    "    else:\n",
    "        u_ref = torch.nn.functional.normalize(goal_states - states) * step_size\n",
    "\n",
    "    control_time = time.time()\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        lip = model.compute_softmax_lipschitz(states[active_mask], zs[active_mask]).unsqueeze(-1) * step_size\n",
    "    lip = lip.detach() \n",
    "    lip = lip.clamp(max=abs(cbf_lambda - min_cbf_lambda))\n",
    "    cbf_controller.set_lipshitz(lip)\n",
    "    lips.append(lip)\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        xs   = states[active_mask]   # (B, 3)\n",
    "        zs_b = zs[active_mask]       # (B, 1)\n",
    "        B    = xs.shape[0]\n",
    "        lips_batch = torch.zeros((B, 1), device=device)\n",
    "        for j in range(B):\n",
    "            xj = xs[j:j+1]      # shape (1,3)\n",
    "            zj = zs_b[j:j+1]    # shape (1,1)\n",
    "\n",
    "            nearby = model.get_submodel_in_rad(xj, radius=step_size * 4)\n",
    "            model.set_submodels(nearby)\n",
    "            lj = model.compute_softmax_lipschitz(xj, zj)  # → shape (1,1)\n",
    "            lips_batch[j] = lj\n",
    "            \n",
    "    lips_batch.mul_(step_size).detach().clamp_(max=abs(cbf_lambda - min_cbf_lambda))\n",
    "    cbf_controller.set_lipshitz(lips_batch)\n",
    "    lips.append(lips_batch)\n",
    "    \n",
    "    u = torch.zeros_like(u_ref)\n",
    "    u[active_mask] = cbf_controller.get_optimal_control(states[active_mask], u_ref=u_ref[active_mask], requires_grad=False)\n",
    "    \n",
    "    total_control_time += time.time() - control_time\n",
    "\n",
    "    deviation = (u[active_mask] - u_ref[active_mask]).mean()\n",
    "    new_states = states.clone()\n",
    "\n",
    "    new_states[active_mask] = cbf_controller.dynamics_model.next_state(states[active_mask], u[active_mask])\n",
    "\n",
    "    deviation_dist = torch.norm(states[active_mask] - new_states[active_mask], dim=1).mean()\n",
    "    if deviation_dist <= (step_size / num_pairs) / 50:\n",
    "        still += 1\n",
    "    else:\n",
    "        still = 0\n",
    "\n",
    "    avg_time += time.time() - start_time\n",
    "    states = new_states.clone()\n",
    "\n",
    "    # Logging\n",
    "    Lf_V, Lg_V = cbf_controller.V_lie_derivatives(states)  \n",
    "    lie_g_over_time.append(Lg_V.squeeze(1).detach().cpu().numpy())\n",
    "    lie_f_over_time.append(Lf_V.squeeze(1).detach().cpu().numpy())\n",
    "    values_over_time.append(V.clone().detach().cpu().numpy())\n",
    "    states_over_time.append(states.clone().detach().cpu().numpy())\n",
    "    u_over_time.append(u.detach().cpu().numpy())\n",
    "    urefs_over_time.append(u_ref.detach().cpu().numpy())\n",
    "\n",
    "    if still >= still_limit:\n",
    "        active_indices = torch.nonzero(active_mask == 1, as_tuple=False)\n",
    "        for idx in active_indices:\n",
    "            idx = int(idx)\n",
    "            inactivation_reasons[idx] = \"Stopped moving\"\n",
    "            durations[idx] = iteration\n",
    "        active_mask = torch.zeros_like(active_mask)\n",
    "        print(\"WARNING - Did not move!\")\n",
    "        break\n",
    "\n",
    "active_indices = torch.nonzero(active_mask == 1, as_tuple=False)\n",
    "for idx in active_indices:\n",
    "    idx = int(idx)\n",
    "    inactivation_reasons[idx] = \"Failed to reach goal in time\"\n",
    "    durations[idx] = iteration\n",
    "\n",
    "avg_time /= (iteration + 1)\n",
    "total_control_time /= (iteration + 1)\n",
    "# model.reset_submodels()\n",
    "\n",
    "# print(f\"states_over_time:\\n{states_over_time}\")\n",
    "print(f\"inactivation_reasons: {inactivation_reasons}\")\n",
    "print(f\"durations: {durations}\")\n",
    "print(f\"avg_time: {avg_time}\")\n",
    "print(f\"avg control time: {total_control_time}\")\n",
    "# print(f\"max lip:\", lips.max(), \"min\", lips.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.175\n",
      "Stopped moving 1: [0]\n",
      "durations {0: 101}\n",
      "Trajectory for index 0:\n",
      " [[ 1.7162038  2.6881225 -1.3      ]\n",
      " [ 1.7261846  2.688747  -1.3      ]\n",
      " [ 1.7361648  2.6893704 -1.3      ]\n",
      " [ 1.7461448  2.6899936 -1.3      ]\n",
      " [ 1.7561249  2.690617  -1.3      ]\n",
      " [ 1.7661058  2.6912415 -1.3      ]\n",
      " [ 1.7760866  2.6918657 -1.3      ]\n",
      " [ 1.7860668  2.6924894 -1.3      ]\n",
      " [ 1.7960417  2.6931088 -1.3      ]\n",
      " [ 1.806025   2.6937346 -1.3      ]\n",
      " [ 1.8160056  2.6943586 -1.3      ]\n",
      " [ 1.8259852  2.694982  -1.3      ]\n",
      " [ 1.8355498  2.6953995 -1.3      ]\n",
      " [ 1.8444499  2.6955526 -1.3      ]\n",
      " [ 1.8526845  2.6955032 -1.3      ]\n",
      " [ 1.86034    2.695326  -1.3      ]\n",
      " [ 1.867474   2.6950648 -1.3      ]\n",
      " [ 1.8741424  2.6947494 -1.3      ]\n",
      " [ 1.8803867  2.694397  -1.3      ]\n",
      " [ 1.886248   2.6940196 -1.3      ]\n",
      " [ 1.891795   2.6936314 -1.3      ]\n",
      " [ 1.8970722  2.693239  -1.3      ]\n",
      " [ 1.9020576  2.6928344 -1.3      ]\n",
      " [ 1.9068441  2.6924314 -1.3      ]\n",
      " [ 1.9113888  2.692019  -1.3      ]\n",
      " [ 1.9157336  2.6916015 -1.3      ]\n",
      " [ 1.9198912  2.6911783 -1.3      ]\n",
      " [ 1.9238843  2.6907506 -1.3      ]\n",
      " [ 1.9277127  2.6903164 -1.3      ]\n",
      " [ 1.9314058  2.6898787 -1.3      ]\n",
      " [ 1.9349631  2.6894364 -1.3      ]\n",
      " [ 1.9384247  2.6889937 -1.3      ]\n",
      " [ 1.94177    2.6885474 -1.3      ]\n",
      " [ 1.9450064  2.6880977 -1.3      ]\n",
      " [ 1.9481276  2.687644  -1.3      ]\n",
      " [ 1.9511508  2.6871886 -1.3      ]\n",
      " [ 1.9540765  2.6867309 -1.3      ]\n",
      " [ 1.9569182  2.6862726 -1.3      ]\n",
      " [ 1.9596802  2.6858146 -1.3      ]\n",
      " [ 1.9623512  2.685356  -1.3      ]\n",
      " [ 1.9649633  2.6848998 -1.3      ]\n",
      " [ 1.9675055  2.6844459 -1.3      ]\n",
      " [ 1.9699869  2.683995  -1.3      ]\n",
      " [ 1.9723923  2.6835463 -1.3      ]\n",
      " [ 1.9747351  2.6831012 -1.3      ]\n",
      " [ 1.9770185  2.68266   -1.3      ]\n",
      " [ 1.9792451  2.6822238 -1.3      ]\n",
      " [ 1.9814175  2.6817925 -1.3      ]\n",
      " [ 1.9835372  2.6813667 -1.3      ]\n",
      " [ 1.9856071  2.6809468 -1.3      ]\n",
      " [ 1.9876293  2.6805332 -1.3      ]\n",
      " [ 1.9896003  2.6801257 -1.3      ]\n",
      " [ 1.9915403  2.6797256 -1.3      ]\n",
      " [ 1.9934295  2.6793315 -1.3      ]\n",
      " [ 1.9952747  2.6789448 -1.3      ]\n",
      " [ 1.9970782  2.6785653 -1.3      ]\n",
      " [ 1.9988424  2.678193  -1.3      ]\n",
      " [ 2.0005689  2.6778283 -1.3      ]\n",
      " [ 2.0022593  2.6774712 -1.3      ]\n",
      " [ 2.003915   2.6771216 -1.3      ]\n",
      " [ 2.0055375  2.6767797 -1.3      ]\n",
      " [ 2.007128   2.6764455 -1.3      ]\n",
      " [ 2.0086877  2.6761189 -1.3      ]\n",
      " [ 2.0102177  2.6757998 -1.3      ]\n",
      " [ 2.011719   2.6754885 -1.3      ]\n",
      " [ 2.013193   2.6751847 -1.3      ]\n",
      " [ 2.0146403  2.6748886 -1.3      ]\n",
      " [ 2.016062   2.6746    -1.3      ]\n",
      " [ 2.0174587  2.6743186 -1.3      ]\n",
      " [ 2.018831   2.6740446 -1.3      ]\n",
      " [ 2.0201797  2.673778  -1.3      ]\n",
      " [ 2.0215056  2.6735187 -1.3      ]\n",
      " [ 2.022809   2.6732664 -1.3      ]\n",
      " [ 2.024101   2.673021  -1.3      ]\n",
      " [ 2.025368   2.6727827 -1.3      ]\n",
      " [ 2.0266104  2.6725512 -1.3      ]\n",
      " [ 2.0278292  2.6723263 -1.3      ]\n",
      " [ 2.029025   2.672108  -1.3      ]\n",
      " [ 2.0301988  2.671896  -1.3      ]\n",
      " [ 2.0313513  2.6716902 -1.3      ]\n",
      " [ 2.0324833  2.6714907 -1.3      ]\n",
      " [ 2.033608   2.6712976 -1.3      ]\n",
      " [ 2.0347152  2.6711104 -1.3      ]\n",
      " [ 2.0358057  2.6709292 -1.3      ]\n",
      " [ 2.0368798  2.670754  -1.3      ]\n",
      " [ 2.0379379  2.6705844 -1.3      ]\n",
      " [ 2.0389802  2.6704206 -1.3      ]\n",
      " [ 2.0400074  2.6702623 -1.3      ]\n",
      " [ 2.0410194  2.6701093 -1.3      ]\n",
      " [ 2.042017   2.6699617 -1.3      ]\n",
      " [ 2.0429957  2.6698213 -1.3      ]\n",
      " [ 2.0439596  2.6696858 -1.3      ]\n",
      " [ 2.0449092  2.6695554 -1.3      ]\n",
      " [ 2.045845   2.6694298 -1.3      ]\n",
      " [ 2.0467675  2.6693087 -1.3      ]\n",
      " [ 2.0476768  2.669192  -1.3      ]\n",
      " [ 2.0485814  2.669079  -1.3      ]\n",
      " [ 2.0494733  2.6689706 -1.3      ]\n",
      " [ 2.050353   2.6688666 -1.3      ]\n",
      " [ 2.0512207  2.668767  -1.3      ]\n",
      " [ 2.0520763  2.6686718 -1.3      ]\n",
      " [ 2.0529206  2.668581  -1.3      ]]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "print(cbf_controller.cbf_lambda)\n",
    "reason_counts = defaultdict(list)  # Dictionary to group by failure reason\n",
    "for idx in inactivation_reasons:\n",
    "    reason = inactivation_reasons[idx]\n",
    "    reason_counts[reason].append(idx)\n",
    "\n",
    "# print(\"len(states_over_time)\", len(states_over_time))\n",
    "# print(\"len(states_over_time[0])\", len(states_over_time[0]))\n",
    "# print(\"durations[0]\", durations[0])\n",
    "\n",
    "for reason, indices in reason_counts.items():\n",
    "    print(f\"{reason} {len(indices)}: {sorted(indices)}\")\n",
    "print(\"durations\", durations)\n",
    "\n",
    "all_trajectories = []\n",
    "for ti in range(len(states)):\n",
    "    all_trajectories.append(np.array([states[ti] for states in states_over_time])[:durations[ti]+1])\n",
    "\n",
    "# Choose trajectory\n",
    "target_index = 0\n",
    "# print([states[target_index] for states in states_over_time])\n",
    "# print(durations[target_index]+1)\n",
    "# print([states[target_index] for states in states_over_time][:durations[target_index]+1])\n",
    "trajectory = np.array([states[target_index] for states in states_over_time])[:durations[target_index]+1]\n",
    "trajectory_values = np.array([vals[target_index].item() for vals in values_over_time])[:durations[target_index]+1]\n",
    "trajectory_lie_g = np.array([vals[target_index] for vals in lie_g_over_time])[:durations[target_index]+1]\n",
    "trajectory_lie_f = np.array([vals[target_index] for vals in lie_f_over_time])[:durations[target_index]+1]\n",
    "trajectory_urefs = np.array([vals[target_index] for vals in urefs_over_time])[:durations[target_index]+1]\n",
    "trajectory_us = np.array([vals[target_index] for vals in u_over_time])[:durations[target_index]+1]\n",
    "\n",
    "\n",
    "# my_ls = [ls[target_index].item() for ls in lips]\n",
    "# print(\"lips\", my_ls)\n",
    "\n",
    "print(f\"Trajectory for index {target_index}:\\n\", trajectory)\n",
    "\n",
    "def to_py(x):\n",
    "    arr = np.asarray(x)\n",
    "    if arr.ndim == 0:\n",
    "        return arr.item()\n",
    "    else:\n",
    "        return arr.tolist()\n",
    "\n",
    "# all_output = []\n",
    "# # Iterate through each trajectory index and its stopping duration\n",
    "# for traj_idx, duration in sorted(durations.items()):\n",
    "#     reason = inactivation_reasons.get(traj_idx, \"unknown\")\n",
    "#     steps = []\n",
    "\n",
    "#     if reason == \"unsafe_region\":\n",
    "#         print(\"Skipping:\", traj_idx)\n",
    "#         continue\n",
    "    \n",
    "#     # Gather per‐timestep data up to when it stopped\n",
    "#     for t in range(duration):\n",
    "#         steps.append({\n",
    "#             \"state\": to_py(states_over_time[t][traj_idx]),\n",
    "#             \"value\": to_py(values_over_time[t][traj_idx]),\n",
    "#             \"lie_g\": to_py(lie_g_over_time[t][traj_idx]),\n",
    "#             \"lie_f\": to_py(lie_f_over_time[t][traj_idx]),\n",
    "#             \"u_ref\": to_py(urefs_over_time[t][traj_idx]),\n",
    "#             \"u\": to_py(u_over_time[t][traj_idx]),\n",
    "#         })\n",
    "    \n",
    "#     all_output.append({\n",
    "#         \"trajectory_index\": traj_idx,\n",
    "#         \"reason\": reason,\n",
    "#         \"duration\": duration,\n",
    "#         \"steps\": steps\n",
    "#     })\n",
    "\n",
    "# with open(f\"{save_to}/{prefix}_trajectories.json\", \"w\") as jf:\n",
    "#     json.dump(all_output, jf, indent=2)\n",
    "\n",
    "# print(\"Saved\", len(all_output), \"trajectories to trajectories.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_backward_hooks: OrderedDict()\n",
      "_backward_pre_hooks: OrderedDict()\n",
      "_buffers: {}\n",
      "_forward_hooks: OrderedDict()\n",
      "_forward_hooks_always_called: OrderedDict()\n",
      "_forward_hooks_with_kwargs: OrderedDict()\n",
      "_forward_pre_hooks: OrderedDict()\n",
      "_forward_pre_hooks_with_kwargs: OrderedDict()\n",
      "_is_full_backward_hook: None\n",
      "_load_state_dict_post_hooks: OrderedDict()\n",
      "_load_state_dict_pre_hooks: OrderedDict()\n",
      "_modules: {'models': ModuleList(\n",
      "  (0-1): 2 x ConditionalSIREN(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=256, bias=True)\n",
      "      (1): Sine()\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): Sine()\n",
      "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (5): Sine()\n",
      "      (6): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "), 'all_models': ModuleList(\n",
      "  (0-11): 12 x ConditionalSIREN(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=256, bias=True)\n",
      "      (1): Sine()\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): Sine()\n",
      "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (5): Sine()\n",
      "      (6): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")}\n",
      "_non_persistent_buffers_set: set()\n",
      "_parameters: {}\n",
      "_state_dict_hooks: OrderedDict()\n",
      "_state_dict_pre_hooks: OrderedDict()\n",
      "all_bounds: tensor([[[-0.9929,  6.9890],\n",
      "         [-1.2955,  3.5994],\n",
      "         [-1.5380,  0.9037]],\n",
      "\n",
      "        [[ 1.9716,  2.5845],\n",
      "         [-1.0951, -0.4739],\n",
      "         [-0.5338, -0.0700]],\n",
      "\n",
      "        [[ 1.9431,  2.5320],\n",
      "         [-1.0234, -0.3864],\n",
      "         [-0.9965, -0.5760]],\n",
      "\n",
      "        [[ 1.9691,  2.5042],\n",
      "         [-0.7794, -0.0917],\n",
      "         [-1.0701, -0.7915]],\n",
      "\n",
      "        [[ 2.9019,  4.4942],\n",
      "         [ 0.5334,  1.5308],\n",
      "         [-1.5327, -0.2502]],\n",
      "\n",
      "        [[ 1.3412,  2.1997],\n",
      "         [ 0.2176,  1.0795],\n",
      "         [-1.4998, -0.9204]],\n",
      "\n",
      "        [[ 5.1679,  6.2397],\n",
      "         [-0.0127,  1.0038],\n",
      "         [-1.4431, -0.3101]],\n",
      "\n",
      "        [[ 2.0551,  5.0045],\n",
      "         [ 1.9441,  3.2856],\n",
      "         [-1.5321, -0.4887]],\n",
      "\n",
      "        [[ 1.3863,  2.2511],\n",
      "         [ 1.0967,  1.9574],\n",
      "         [-1.4951, -0.9089]],\n",
      "\n",
      "        [[ 5.1632,  6.2487],\n",
      "         [ 0.9806,  2.0097],\n",
      "         [-1.4594, -0.2983]],\n",
      "\n",
      "        [[ 4.9048,  5.5080],\n",
      "         [ 2.1553,  3.0361],\n",
      "         [-1.0849, -0.6814]],\n",
      "\n",
      "        [[ 4.9048,  5.5206],\n",
      "         [ 2.4668,  3.0738],\n",
      "         [-0.4708, -0.0410]]], device='cuda:0')\n",
      "all_centers_for_translations: tensor([[ 2.9991,  1.1502, -0.3157],\n",
      "        [ 2.2766, -0.7871, -0.2989],\n",
      "        [ 2.2418, -0.7039, -0.7891],\n",
      "        [ 2.2419, -0.4403, -0.9377],\n",
      "        [ 3.6988,  1.0301, -0.8899],\n",
      "        [ 1.7733,  0.6514, -1.2114],\n",
      "        [ 5.7037,  0.4963, -0.8767],\n",
      "        [ 3.5319,  2.6128, -1.0088],\n",
      "        [ 1.8177,  1.5270, -1.2056],\n",
      "        [ 5.7061,  1.4945, -0.8793],\n",
      "        [ 5.2040,  2.5932, -0.8839],\n",
      "        [ 5.2137,  2.7724, -0.2555]], device='cuda:0')\n",
      "all_configs: [{'adam_betas_find_surface': [0.9, 0.999], 'auto_clip_hist_len': 50, 'auto_clip_min_len': 50, 'auto_clip_on': False, 'auto_clip_percentile': 0.8, 'batch_size': 1, 'cbf_lambda': -0.01, 'cbf_relaxation_penalty': 5, 'check_interval_grad_mag_saddle_descent': 5, 'controller_step_range': [0.5, 2], 'dataset_dir': '/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects/0_wall', 'dbscan.eps': 0.05, 'dbscan.y_x_mag': 1e-05, 'decay_steps': 1000, 'device': 'cuda', 'diversity_loss_eps': 0.0001, 'env_val_tol': 0.1, 'envelope_sample_from': 'exterior', 'fig_path': 'img/simjeb/cond_siren', 'fig_pynb': True, 'fig_save': False, 'fig_show': True, 'fig_size': [12, 7], 'fig_wandb': False, 'find_surface_pts_converged_interval': 10, 'find_surface_pts_n_iter': 200, 'find_surface_pts_prec_eps': 1e-06, 'force_saving_shape': False, 'gpu_list': [0], 'grad_clip': 0.5, 'grad_clipping_on': True, 'graph_algo_inv_dist_eps': 0.1, 'interface_delta': 0, 'lambda_bc': 1, 'lambda_bound': 0, 'lambda_curv': 1e-07, 'lambda_descent': 1, 'lambda_div': 0, 'lambda_dom': 1, 'lambda_eikonal': 1e-09, 'lambda_env': 0, 'lambda_normal': 1e-06, 'lambda_obst': 0.0, 'lambda_outer_env': 1, 'lambda_outer_unif': 0, 'lambda_outer_var': 0.0, 'lambda_scc': 0.01, 'lambda_small_control': 0, 'lambda_vx': 0.0001, 'lambda_vxx': 0.0001, 'layers': [4, 256, 256, 256, 1], 'level_set': 0, 'load_model': False, 'loss_optim': 'fixed', 'loss_thresh': 0.001, 'lr': 0.001, 'lr_adjust_cps': 0.001, 'lr_find_cps': 0.01, 'lr_find_surface': 0.01, 'lr_saddle_descent': 0.03, 'max_domain_val': -0.1, 'max_epochs': 250, 'max_iter_find_cps': 1000, 'mc_resolution': 128, 'min_control_norm': 0.5, 'min_env_val_inner': 0.01, 'min_env_val_outer': 0.1, 'min_loss_thresh': 1e-06, 'model': 'cond_siren', 'model_load_path': '/scratch/rhm4nj/cral/ginn/all_runs/models/cond_siren/2024_10_10-23_41_01/2024_10_10-23_41_01-9cu3lc4a_2300.pth', 'model_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/0_wall/cond_siren/2025_04_30-11_11_53/2025_04_30-11_11_54-875n7ept.pth', 'model_save_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/0_wall', 'n_controller_steps': 10, 'n_iter_saddle_descent': 1000, 'n_points_descent': 16384, 'n_points_domain': 16384, 'n_points_envelope': 32768, 'n_points_find_cps': 4096, 'n_points_find_surface': 4096, 'n_points_interfaces': 8192, 'n_points_normals': 8192, 'n_points_outer': 4096, 'no_save': False, 'num_workers': 0, 'nx': 3, 'ny': 1, 'nz': 1, 'obj_name': '0_wall', 'outer_target': 0, 'perturbation_saddle_descent': 0.01, 'plot_every_n_epochs': 10, 'plot_n_shapes': 1, 'plot_secondary_plots_every_n_epochs': 500, 'plot_shape': True, 'problem': 'grid_world', 'recalc_cps_every_n_epochs': 1, 'recompute_surface_pts_every_n_epochs': 10, 'remove_penalty_points_outside_envelope': True, 'reweigh_surface_pts_close_to_interface': True, 'reweigh_surface_pts_close_to_interface_cutoff': 0.2, 'reweigh_surface_pts_close_to_interface_power': 2.0, 'save_every_n_epochs': 10, 'scc_penalty_norm_eps': 0.0001, 'scheduler_gamma': 0.5, 'seed': 17, 'show_colorbar': True, 'stop_grad_mag_saddle_descent': 1e-05, 'strain_curvature_clip_max': 1000.0, 'timer_accumulate': True, 'timer_print': False, 'use_compile': False, 'use_scheduler': True, 'use_x_and_z_arg': True, 'w0': 1.0, 'w0_initial': 8.0, 'wandb_entity_name': 'abra', 'wandb_experiment_name': '0_wall', 'wandb_project_name': 'objgen', 'wandb_save_dir': 'all_runs/wandb', 'z_sample_interval': [-0.1, 0.1], 'z_sample_method': 'uniform'}, {'adam_betas_find_surface': [0.9, 0.999], 'auto_clip_hist_len': 50, 'auto_clip_min_len': 50, 'auto_clip_on': False, 'auto_clip_percentile': 0.8, 'batch_size': 1, 'cbf_lambda': -0.01, 'cbf_relaxation_penalty': 5, 'check_interval_grad_mag_saddle_descent': 5, 'controller_step_range': [0.5, 2], 'dataset_dir': '/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects/1_lamp', 'dbscan.eps': 0.05, 'dbscan.y_x_mag': 1e-05, 'decay_steps': 1000, 'device': 'cuda', 'diversity_loss_eps': 0.0001, 'env_val_tol': 0.1, 'envelope_sample_from': 'exterior', 'fig_path': 'img/simjeb/cond_siren', 'fig_pynb': True, 'fig_save': False, 'fig_show': True, 'fig_size': [12, 7], 'fig_wandb': False, 'find_surface_pts_converged_interval': 10, 'find_surface_pts_n_iter': 200, 'find_surface_pts_prec_eps': 1e-06, 'force_saving_shape': False, 'gpu_list': [0], 'grad_clip': 0.5, 'grad_clipping_on': True, 'graph_algo_inv_dist_eps': 0.1, 'interface_delta': 0, 'lambda_bc': 1, 'lambda_bound': 0, 'lambda_curv': 1e-07, 'lambda_descent': 1, 'lambda_div': 0, 'lambda_dom': 1, 'lambda_eikonal': 1e-09, 'lambda_env': 0, 'lambda_normal': 1e-06, 'lambda_obst': 0.0, 'lambda_outer_env': 1, 'lambda_outer_unif': 0, 'lambda_outer_var': 0.0, 'lambda_scc': 0.01, 'lambda_small_control': 0, 'lambda_vx': 0.0001, 'lambda_vxx': 0.0001, 'layers': [4, 256, 256, 256, 1], 'level_set': 0, 'load_model': False, 'loss_optim': 'fixed', 'loss_thresh': 0.001, 'lr': 0.001, 'lr_adjust_cps': 0.001, 'lr_find_cps': 0.01, 'lr_find_surface': 0.01, 'lr_saddle_descent': 0.03, 'max_domain_val': -0.1, 'max_epochs': 250, 'max_iter_find_cps': 1000, 'mc_resolution': 128, 'min_control_norm': 0.5, 'min_env_val_inner': 0.01, 'min_env_val_outer': 0.1, 'min_loss_thresh': 1e-06, 'model': 'cond_siren', 'model_load_path': '/scratch/rhm4nj/cral/ginn/all_runs/models/cond_siren/2024_10_10-23_41_01/2024_10_10-23_41_01-9cu3lc4a_2300.pth', 'model_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/1_lamp/cond_siren/2025_04_30-11_11_58/2025_04_30-11_11_59-5kciqr6s.pth', 'model_save_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/1_lamp', 'n_controller_steps': 10, 'n_iter_saddle_descent': 1000, 'n_points_descent': 16384, 'n_points_domain': 16384, 'n_points_envelope': 32768, 'n_points_find_cps': 4096, 'n_points_find_surface': 4096, 'n_points_interfaces': 8192, 'n_points_normals': 8192, 'n_points_outer': 4096, 'no_save': False, 'num_workers': 0, 'nx': 3, 'ny': 1, 'nz': 1, 'obj_name': '1_lamp', 'outer_target': 0, 'perturbation_saddle_descent': 0.01, 'plot_every_n_epochs': 10, 'plot_n_shapes': 1, 'plot_secondary_plots_every_n_epochs': 500, 'plot_shape': True, 'problem': 'grid_world', 'recalc_cps_every_n_epochs': 1, 'recompute_surface_pts_every_n_epochs': 10, 'remove_penalty_points_outside_envelope': True, 'reweigh_surface_pts_close_to_interface': True, 'reweigh_surface_pts_close_to_interface_cutoff': 0.2, 'reweigh_surface_pts_close_to_interface_power': 2.0, 'save_every_n_epochs': 10, 'scc_penalty_norm_eps': 0.0001, 'scheduler_gamma': 0.5, 'seed': 17, 'show_colorbar': True, 'stop_grad_mag_saddle_descent': 1e-05, 'strain_curvature_clip_max': 1000.0, 'timer_accumulate': True, 'timer_print': False, 'use_compile': False, 'use_scheduler': True, 'use_x_and_z_arg': True, 'w0': 1.0, 'w0_initial': 8.0, 'wandb_entity_name': 'abra', 'wandb_experiment_name': '1_lamp', 'wandb_project_name': 'objgen', 'wandb_save_dir': 'all_runs/wandb', 'z_sample_interval': [-0.1, 0.1], 'z_sample_method': 'uniform'}, {'adam_betas_find_surface': [0.9, 0.999], 'auto_clip_hist_len': 50, 'auto_clip_min_len': 50, 'auto_clip_on': False, 'auto_clip_percentile': 0.8, 'batch_size': 1, 'cbf_lambda': -0.01, 'cbf_relaxation_penalty': 5, 'check_interval_grad_mag_saddle_descent': 5, 'controller_step_range': [0.5, 2], 'dataset_dir': '/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects/2_table', 'dbscan.eps': 0.05, 'dbscan.y_x_mag': 1e-05, 'decay_steps': 1000, 'device': 'cuda', 'diversity_loss_eps': 0.0001, 'env_val_tol': 0.1, 'envelope_sample_from': 'exterior', 'fig_path': 'img/simjeb/cond_siren', 'fig_pynb': True, 'fig_save': False, 'fig_show': True, 'fig_size': [12, 7], 'fig_wandb': False, 'find_surface_pts_converged_interval': 10, 'find_surface_pts_n_iter': 200, 'find_surface_pts_prec_eps': 1e-06, 'force_saving_shape': False, 'gpu_list': [0], 'grad_clip': 0.5, 'grad_clipping_on': True, 'graph_algo_inv_dist_eps': 0.1, 'interface_delta': 0, 'lambda_bc': 1, 'lambda_bound': 0, 'lambda_curv': 1e-07, 'lambda_descent': 1, 'lambda_div': 0, 'lambda_dom': 1, 'lambda_eikonal': 1e-09, 'lambda_env': 0, 'lambda_normal': 1e-06, 'lambda_obst': 0.0, 'lambda_outer_env': 1, 'lambda_outer_unif': 0, 'lambda_outer_var': 0.0, 'lambda_scc': 0.01, 'lambda_small_control': 0, 'lambda_vx': 0.0001, 'lambda_vxx': 0.0001, 'layers': [4, 256, 256, 256, 1], 'level_set': 0, 'load_model': False, 'loss_optim': 'fixed', 'loss_thresh': 0.001, 'lr': 0.001, 'lr_adjust_cps': 0.001, 'lr_find_cps': 0.01, 'lr_find_surface': 0.01, 'lr_saddle_descent': 0.03, 'max_domain_val': -0.1, 'max_epochs': 250, 'max_iter_find_cps': 1000, 'mc_resolution': 128, 'min_control_norm': 0.5, 'min_env_val_inner': 0.01, 'min_env_val_outer': 0.1, 'min_loss_thresh': 1e-06, 'model': 'cond_siren', 'model_load_path': '/scratch/rhm4nj/cral/ginn/all_runs/models/cond_siren/2024_10_10-23_41_01/2024_10_10-23_41_01-9cu3lc4a_2300.pth', 'model_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/2_table/cond_siren/2025_04_30-11_12_06/2025_04_30-11_12_08-ieijh8pr.pth', 'model_save_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/2_table', 'n_controller_steps': 10, 'n_iter_saddle_descent': 1000, 'n_points_descent': 16384, 'n_points_domain': 16384, 'n_points_envelope': 32768, 'n_points_find_cps': 4096, 'n_points_find_surface': 4096, 'n_points_interfaces': 8192, 'n_points_normals': 8192, 'n_points_outer': 4096, 'no_save': False, 'num_workers': 0, 'nx': 3, 'ny': 1, 'nz': 1, 'obj_name': '2_table', 'outer_target': 0, 'perturbation_saddle_descent': 0.01, 'plot_every_n_epochs': 10, 'plot_n_shapes': 1, 'plot_secondary_plots_every_n_epochs': 500, 'plot_shape': True, 'problem': 'grid_world', 'recalc_cps_every_n_epochs': 1, 'recompute_surface_pts_every_n_epochs': 10, 'remove_penalty_points_outside_envelope': True, 'reweigh_surface_pts_close_to_interface': True, 'reweigh_surface_pts_close_to_interface_cutoff': 0.2, 'reweigh_surface_pts_close_to_interface_power': 2.0, 'save_every_n_epochs': 10, 'scc_penalty_norm_eps': 0.0001, 'scheduler_gamma': 0.5, 'seed': 17, 'show_colorbar': True, 'stop_grad_mag_saddle_descent': 1e-05, 'strain_curvature_clip_max': 1000.0, 'timer_accumulate': True, 'timer_print': False, 'use_compile': False, 'use_scheduler': True, 'use_x_and_z_arg': True, 'w0': 1.0, 'w0_initial': 8.0, 'wandb_entity_name': 'abra', 'wandb_experiment_name': '2_table', 'wandb_project_name': 'objgen', 'wandb_save_dir': 'all_runs/wandb', 'z_sample_interval': [-0.1, 0.1], 'z_sample_method': 'uniform'}, {'adam_betas_find_surface': [0.9, 0.999], 'auto_clip_hist_len': 50, 'auto_clip_min_len': 50, 'auto_clip_on': False, 'auto_clip_percentile': 0.8, 'batch_size': 1, 'cbf_lambda': -0.01, 'cbf_relaxation_penalty': 5, 'check_interval_grad_mag_saddle_descent': 5, 'controller_step_range': [0.5, 2], 'dataset_dir': '/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects/3_table', 'dbscan.eps': 0.05, 'dbscan.y_x_mag': 1e-05, 'decay_steps': 1000, 'device': 'cuda', 'diversity_loss_eps': 0.0001, 'env_val_tol': 0.1, 'envelope_sample_from': 'exterior', 'fig_path': 'img/simjeb/cond_siren', 'fig_pynb': True, 'fig_save': False, 'fig_show': True, 'fig_size': [12, 7], 'fig_wandb': False, 'find_surface_pts_converged_interval': 10, 'find_surface_pts_n_iter': 200, 'find_surface_pts_prec_eps': 1e-06, 'force_saving_shape': False, 'gpu_list': [0], 'grad_clip': 0.5, 'grad_clipping_on': True, 'graph_algo_inv_dist_eps': 0.1, 'interface_delta': 0, 'lambda_bc': 1, 'lambda_bound': 0, 'lambda_curv': 1e-07, 'lambda_descent': 1, 'lambda_div': 0, 'lambda_dom': 1, 'lambda_eikonal': 1e-09, 'lambda_env': 0, 'lambda_normal': 1e-06, 'lambda_obst': 0.0, 'lambda_outer_env': 1, 'lambda_outer_unif': 0, 'lambda_outer_var': 0.0, 'lambda_scc': 0.01, 'lambda_small_control': 0, 'lambda_vx': 0.0001, 'lambda_vxx': 0.0001, 'layers': [4, 256, 256, 256, 1], 'level_set': 0, 'load_model': False, 'loss_optim': 'fixed', 'loss_thresh': 0.001, 'lr': 0.001, 'lr_adjust_cps': 0.001, 'lr_find_cps': 0.01, 'lr_find_surface': 0.01, 'lr_saddle_descent': 0.03, 'max_domain_val': -0.1, 'max_epochs': 250, 'max_iter_find_cps': 1000, 'mc_resolution': 128, 'min_control_norm': 0.5, 'min_env_val_inner': 0.01, 'min_env_val_outer': 0.1, 'min_loss_thresh': 1e-06, 'model': 'cond_siren', 'model_load_path': '/scratch/rhm4nj/cral/ginn/all_runs/models/cond_siren/2024_10_10-23_41_01/2024_10_10-23_41_01-9cu3lc4a_2300.pth', 'model_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/3_table/cond_siren/2025_04_30-11_11_56/2025_04_30-11_11_57-4dkdsmwq.pth', 'model_save_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/3_table', 'n_controller_steps': 10, 'n_iter_saddle_descent': 1000, 'n_points_descent': 16384, 'n_points_domain': 16384, 'n_points_envelope': 32768, 'n_points_find_cps': 4096, 'n_points_find_surface': 4096, 'n_points_interfaces': 8192, 'n_points_normals': 8192, 'n_points_outer': 4096, 'no_save': False, 'num_workers': 0, 'nx': 3, 'ny': 1, 'nz': 1, 'obj_name': '3_table', 'outer_target': 0, 'perturbation_saddle_descent': 0.01, 'plot_every_n_epochs': 10, 'plot_n_shapes': 1, 'plot_secondary_plots_every_n_epochs': 500, 'plot_shape': True, 'problem': 'grid_world', 'recalc_cps_every_n_epochs': 1, 'recompute_surface_pts_every_n_epochs': 10, 'remove_penalty_points_outside_envelope': True, 'reweigh_surface_pts_close_to_interface': True, 'reweigh_surface_pts_close_to_interface_cutoff': 0.2, 'reweigh_surface_pts_close_to_interface_power': 2.0, 'save_every_n_epochs': 10, 'scc_penalty_norm_eps': 0.0001, 'scheduler_gamma': 0.5, 'seed': 17, 'show_colorbar': True, 'stop_grad_mag_saddle_descent': 1e-05, 'strain_curvature_clip_max': 1000.0, 'timer_accumulate': True, 'timer_print': False, 'use_compile': False, 'use_scheduler': True, 'use_x_and_z_arg': True, 'w0': 1.0, 'w0_initial': 8.0, 'wandb_entity_name': 'abra', 'wandb_experiment_name': '3_table', 'wandb_project_name': 'objgen', 'wandb_save_dir': 'all_runs/wandb', 'z_sample_interval': [-0.1, 0.1], 'z_sample_method': 'uniform'}, {'adam_betas_find_surface': [0.9, 0.999], 'auto_clip_hist_len': 50, 'auto_clip_min_len': 50, 'auto_clip_on': False, 'auto_clip_percentile': 0.8, 'batch_size': 1, 'cbf_lambda': -0.01, 'cbf_relaxation_penalty': 5, 'check_interval_grad_mag_saddle_descent': 5, 'controller_step_range': [0.5, 2], 'dataset_dir': '/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects/4_table', 'dbscan.eps': 0.05, 'dbscan.y_x_mag': 1e-05, 'decay_steps': 1000, 'device': 'cuda', 'diversity_loss_eps': 0.0001, 'env_val_tol': 0.1, 'envelope_sample_from': 'exterior', 'fig_path': 'img/simjeb/cond_siren', 'fig_pynb': True, 'fig_save': False, 'fig_show': True, 'fig_size': [12, 7], 'fig_wandb': False, 'find_surface_pts_converged_interval': 10, 'find_surface_pts_n_iter': 200, 'find_surface_pts_prec_eps': 1e-06, 'force_saving_shape': False, 'gpu_list': [0], 'grad_clip': 0.5, 'grad_clipping_on': True, 'graph_algo_inv_dist_eps': 0.1, 'interface_delta': 0, 'lambda_bc': 1, 'lambda_bound': 0, 'lambda_curv': 1e-07, 'lambda_descent': 1, 'lambda_div': 0, 'lambda_dom': 1, 'lambda_eikonal': 1e-09, 'lambda_env': 0, 'lambda_normal': 1e-06, 'lambda_obst': 0.0, 'lambda_outer_env': 1, 'lambda_outer_unif': 0, 'lambda_outer_var': 0.0, 'lambda_scc': 0.01, 'lambda_small_control': 0, 'lambda_vx': 0.0001, 'lambda_vxx': 0.0001, 'layers': [4, 256, 256, 256, 1], 'level_set': 0, 'load_model': False, 'loss_optim': 'fixed', 'loss_thresh': 0.001, 'lr': 0.001, 'lr_adjust_cps': 0.001, 'lr_find_cps': 0.01, 'lr_find_surface': 0.01, 'lr_saddle_descent': 0.03, 'max_domain_val': -0.1, 'max_epochs': 250, 'max_iter_find_cps': 1000, 'mc_resolution': 128, 'min_control_norm': 0.5, 'min_env_val_inner': 0.01, 'min_env_val_outer': 0.1, 'min_loss_thresh': 1e-06, 'model': 'cond_siren', 'model_load_path': '/scratch/rhm4nj/cral/ginn/all_runs/models/cond_siren/2024_10_10-23_41_01/2024_10_10-23_41_01-9cu3lc4a_2300.pth', 'model_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/4_table/cond_siren/2025_04_30-11_11_53/2025_04_30-11_11_54-z4npbxyh.pth', 'model_save_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/4_table', 'n_controller_steps': 10, 'n_iter_saddle_descent': 1000, 'n_points_descent': 16384, 'n_points_domain': 16384, 'n_points_envelope': 32768, 'n_points_find_cps': 4096, 'n_points_find_surface': 4096, 'n_points_interfaces': 8192, 'n_points_normals': 8192, 'n_points_outer': 4096, 'no_save': False, 'num_workers': 0, 'nx': 3, 'ny': 1, 'nz': 1, 'obj_name': '4_table', 'outer_target': 0, 'perturbation_saddle_descent': 0.01, 'plot_every_n_epochs': 10, 'plot_n_shapes': 1, 'plot_secondary_plots_every_n_epochs': 500, 'plot_shape': True, 'problem': 'grid_world', 'recalc_cps_every_n_epochs': 1, 'recompute_surface_pts_every_n_epochs': 10, 'remove_penalty_points_outside_envelope': True, 'reweigh_surface_pts_close_to_interface': True, 'reweigh_surface_pts_close_to_interface_cutoff': 0.2, 'reweigh_surface_pts_close_to_interface_power': 2.0, 'save_every_n_epochs': 10, 'scc_penalty_norm_eps': 0.0001, 'scheduler_gamma': 0.5, 'seed': 17, 'show_colorbar': True, 'stop_grad_mag_saddle_descent': 1e-05, 'strain_curvature_clip_max': 1000.0, 'timer_accumulate': True, 'timer_print': False, 'use_compile': False, 'use_scheduler': True, 'use_x_and_z_arg': True, 'w0': 1.0, 'w0_initial': 8.0, 'wandb_entity_name': 'abra', 'wandb_experiment_name': '4_table', 'wandb_project_name': 'objgen', 'wandb_save_dir': 'all_runs/wandb', 'z_sample_interval': [-0.1, 0.1], 'z_sample_method': 'uniform'}, {'adam_betas_find_surface': [0.9, 0.999], 'auto_clip_hist_len': 50, 'auto_clip_min_len': 50, 'auto_clip_on': False, 'auto_clip_percentile': 0.8, 'batch_size': 1, 'cbf_lambda': -0.01, 'cbf_relaxation_penalty': 5, 'check_interval_grad_mag_saddle_descent': 5, 'controller_step_range': [0.5, 2], 'dataset_dir': '/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects/5_stool', 'dbscan.eps': 0.05, 'dbscan.y_x_mag': 1e-05, 'decay_steps': 1000, 'device': 'cuda', 'diversity_loss_eps': 0.0001, 'env_val_tol': 0.1, 'envelope_sample_from': 'exterior', 'fig_path': 'img/simjeb/cond_siren', 'fig_pynb': True, 'fig_save': False, 'fig_show': True, 'fig_size': [12, 7], 'fig_wandb': False, 'find_surface_pts_converged_interval': 10, 'find_surface_pts_n_iter': 200, 'find_surface_pts_prec_eps': 1e-06, 'force_saving_shape': False, 'gpu_list': [0], 'grad_clip': 0.5, 'grad_clipping_on': True, 'graph_algo_inv_dist_eps': 0.1, 'interface_delta': 0, 'lambda_bc': 1, 'lambda_bound': 0, 'lambda_curv': 1e-07, 'lambda_descent': 1, 'lambda_div': 0, 'lambda_dom': 1, 'lambda_eikonal': 1e-09, 'lambda_env': 0, 'lambda_normal': 1e-06, 'lambda_obst': 0.0, 'lambda_outer_env': 1, 'lambda_outer_unif': 0, 'lambda_outer_var': 0.0, 'lambda_scc': 0.01, 'lambda_small_control': 0, 'lambda_vx': 0.0001, 'lambda_vxx': 0.0001, 'layers': [4, 256, 256, 256, 1], 'level_set': 0, 'load_model': False, 'loss_optim': 'fixed', 'loss_thresh': 0.001, 'lr': 0.001, 'lr_adjust_cps': 0.001, 'lr_find_cps': 0.01, 'lr_find_surface': 0.01, 'lr_saddle_descent': 0.03, 'max_domain_val': -0.1, 'max_epochs': 250, 'max_iter_find_cps': 1000, 'mc_resolution': 128, 'min_control_norm': 0.5, 'min_env_val_inner': 0.01, 'min_env_val_outer': 0.1, 'min_loss_thresh': 1e-06, 'model': 'cond_siren', 'model_load_path': '/scratch/rhm4nj/cral/ginn/all_runs/models/cond_siren/2024_10_10-23_41_01/2024_10_10-23_41_01-9cu3lc4a_2300.pth', 'model_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/5_stool/cond_siren/2025_04_30-11_11_54/2025_04_30-11_11_55-qaso5ark.pth', 'model_save_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/5_stool', 'n_controller_steps': 10, 'n_iter_saddle_descent': 1000, 'n_points_descent': 16384, 'n_points_domain': 16384, 'n_points_envelope': 32768, 'n_points_find_cps': 4096, 'n_points_find_surface': 4096, 'n_points_interfaces': 8192, 'n_points_normals': 8192, 'n_points_outer': 4096, 'no_save': False, 'num_workers': 0, 'nx': 3, 'ny': 1, 'nz': 1, 'obj_name': '5_stool', 'outer_target': 0, 'perturbation_saddle_descent': 0.01, 'plot_every_n_epochs': 10, 'plot_n_shapes': 1, 'plot_secondary_plots_every_n_epochs': 500, 'plot_shape': True, 'problem': 'grid_world', 'recalc_cps_every_n_epochs': 1, 'recompute_surface_pts_every_n_epochs': 10, 'remove_penalty_points_outside_envelope': True, 'reweigh_surface_pts_close_to_interface': True, 'reweigh_surface_pts_close_to_interface_cutoff': 0.2, 'reweigh_surface_pts_close_to_interface_power': 2.0, 'save_every_n_epochs': 10, 'scc_penalty_norm_eps': 0.0001, 'scheduler_gamma': 0.5, 'seed': 17, 'show_colorbar': True, 'stop_grad_mag_saddle_descent': 1e-05, 'strain_curvature_clip_max': 1000.0, 'timer_accumulate': True, 'timer_print': False, 'use_compile': False, 'use_scheduler': True, 'use_x_and_z_arg': True, 'w0': 1.0, 'w0_initial': 8.0, 'wandb_entity_name': 'abra', 'wandb_experiment_name': '5_stool', 'wandb_project_name': 'objgen', 'wandb_save_dir': 'all_runs/wandb', 'z_sample_interval': [-0.1, 0.1], 'z_sample_method': 'uniform'}, {'adam_betas_find_surface': [0.9, 0.999], 'auto_clip_hist_len': 50, 'auto_clip_min_len': 50, 'auto_clip_on': False, 'auto_clip_percentile': 0.8, 'batch_size': 1, 'cbf_lambda': -0.01, 'cbf_relaxation_penalty': 5, 'check_interval_grad_mag_saddle_descent': 5, 'controller_step_range': [0.5, 2], 'dataset_dir': '/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects/6_chair', 'dbscan.eps': 0.05, 'dbscan.y_x_mag': 1e-05, 'decay_steps': 1000, 'device': 'cuda', 'diversity_loss_eps': 0.0001, 'env_val_tol': 0.1, 'envelope_sample_from': 'exterior', 'fig_path': 'img/simjeb/cond_siren', 'fig_pynb': True, 'fig_save': False, 'fig_show': True, 'fig_size': [12, 7], 'fig_wandb': False, 'find_surface_pts_converged_interval': 10, 'find_surface_pts_n_iter': 200, 'find_surface_pts_prec_eps': 1e-06, 'force_saving_shape': False, 'gpu_list': [0], 'grad_clip': 0.5, 'grad_clipping_on': True, 'graph_algo_inv_dist_eps': 0.1, 'interface_delta': 0, 'lambda_bc': 1, 'lambda_bound': 0, 'lambda_curv': 1e-07, 'lambda_descent': 1, 'lambda_div': 0, 'lambda_dom': 1, 'lambda_eikonal': 1e-09, 'lambda_env': 0, 'lambda_normal': 1e-06, 'lambda_obst': 0.0, 'lambda_outer_env': 1, 'lambda_outer_unif': 0, 'lambda_outer_var': 0.0, 'lambda_scc': 0.01, 'lambda_small_control': 0, 'lambda_vx': 0.0001, 'lambda_vxx': 0.0001, 'layers': [4, 256, 256, 256, 1], 'level_set': 0, 'load_model': False, 'loss_optim': 'fixed', 'loss_thresh': 0.001, 'lr': 0.001, 'lr_adjust_cps': 0.001, 'lr_find_cps': 0.01, 'lr_find_surface': 0.01, 'lr_saddle_descent': 0.03, 'max_domain_val': -0.1, 'max_epochs': 250, 'max_iter_find_cps': 1000, 'mc_resolution': 128, 'min_control_norm': 0.5, 'min_env_val_inner': 0.01, 'min_env_val_outer': 0.1, 'min_loss_thresh': 1e-06, 'model': 'cond_siren', 'model_load_path': '/scratch/rhm4nj/cral/ginn/all_runs/models/cond_siren/2024_10_10-23_41_01/2024_10_10-23_41_01-9cu3lc4a_2300.pth', 'model_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/6_chair/cond_siren/2025_04_30-11_11_53/2025_04_30-11_11_54-jktsb8tp.pth', 'model_save_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/6_chair', 'n_controller_steps': 10, 'n_iter_saddle_descent': 1000, 'n_points_descent': 16384, 'n_points_domain': 16384, 'n_points_envelope': 32768, 'n_points_find_cps': 4096, 'n_points_find_surface': 4096, 'n_points_interfaces': 8192, 'n_points_normals': 8192, 'n_points_outer': 4096, 'no_save': False, 'num_workers': 0, 'nx': 3, 'ny': 1, 'nz': 1, 'obj_name': '6_chair', 'outer_target': 0, 'perturbation_saddle_descent': 0.01, 'plot_every_n_epochs': 10, 'plot_n_shapes': 1, 'plot_secondary_plots_every_n_epochs': 500, 'plot_shape': True, 'problem': 'grid_world', 'recalc_cps_every_n_epochs': 1, 'recompute_surface_pts_every_n_epochs': 10, 'remove_penalty_points_outside_envelope': True, 'reweigh_surface_pts_close_to_interface': True, 'reweigh_surface_pts_close_to_interface_cutoff': 0.2, 'reweigh_surface_pts_close_to_interface_power': 2.0, 'save_every_n_epochs': 10, 'scc_penalty_norm_eps': 0.0001, 'scheduler_gamma': 0.5, 'seed': 17, 'show_colorbar': True, 'stop_grad_mag_saddle_descent': 1e-05, 'strain_curvature_clip_max': 1000.0, 'timer_accumulate': True, 'timer_print': False, 'use_compile': False, 'use_scheduler': True, 'use_x_and_z_arg': True, 'w0': 1.0, 'w0_initial': 8.0, 'wandb_entity_name': 'abra', 'wandb_experiment_name': '6_chair', 'wandb_project_name': 'objgen', 'wandb_save_dir': 'all_runs/wandb', 'z_sample_interval': [-0.1, 0.1], 'z_sample_method': 'uniform'}, {'adam_betas_find_surface': [0.9, 0.999], 'auto_clip_hist_len': 50, 'auto_clip_min_len': 50, 'auto_clip_on': False, 'auto_clip_percentile': 0.8, 'batch_size': 1, 'cbf_lambda': -0.01, 'cbf_relaxation_penalty': 5, 'check_interval_grad_mag_saddle_descent': 5, 'controller_step_range': [0.5, 2], 'dataset_dir': '/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects/7_sofa', 'dbscan.eps': 0.05, 'dbscan.y_x_mag': 1e-05, 'decay_steps': 1000, 'device': 'cuda', 'diversity_loss_eps': 0.0001, 'env_val_tol': 0.1, 'envelope_sample_from': 'exterior', 'fig_path': 'img/simjeb/cond_siren', 'fig_pynb': True, 'fig_save': False, 'fig_show': True, 'fig_size': [12, 7], 'fig_wandb': False, 'find_surface_pts_converged_interval': 10, 'find_surface_pts_n_iter': 200, 'find_surface_pts_prec_eps': 1e-06, 'force_saving_shape': False, 'gpu_list': [0], 'grad_clip': 0.5, 'grad_clipping_on': True, 'graph_algo_inv_dist_eps': 0.1, 'interface_delta': 0, 'lambda_bc': 1, 'lambda_bound': 0, 'lambda_curv': 1e-07, 'lambda_descent': 1, 'lambda_div': 0, 'lambda_dom': 1, 'lambda_eikonal': 1e-09, 'lambda_env': 0, 'lambda_normal': 1e-06, 'lambda_obst': 0.0, 'lambda_outer_env': 1, 'lambda_outer_unif': 0, 'lambda_outer_var': 0.0, 'lambda_scc': 0.01, 'lambda_small_control': 0, 'lambda_vx': 0.0001, 'lambda_vxx': 0.0001, 'layers': [4, 256, 256, 256, 1], 'level_set': 0, 'load_model': False, 'loss_optim': 'fixed', 'loss_thresh': 0.001, 'lr': 0.001, 'lr_adjust_cps': 0.001, 'lr_find_cps': 0.01, 'lr_find_surface': 0.01, 'lr_saddle_descent': 0.03, 'max_domain_val': -0.1, 'max_epochs': 250, 'max_iter_find_cps': 1000, 'mc_resolution': 128, 'min_control_norm': 0.5, 'min_env_val_inner': 0.01, 'min_env_val_outer': 0.1, 'min_loss_thresh': 1e-06, 'model': 'cond_siren', 'model_load_path': '/scratch/rhm4nj/cral/ginn/all_runs/models/cond_siren/2024_10_10-23_41_01/2024_10_10-23_41_01-9cu3lc4a_2300.pth', 'model_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/7_sofa/cond_siren/2025_04_30-11_11_53/2025_04_30-11_11_54-24qou3a8.pth', 'model_save_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/7_sofa', 'n_controller_steps': 10, 'n_iter_saddle_descent': 1000, 'n_points_descent': 16384, 'n_points_domain': 16384, 'n_points_envelope': 32768, 'n_points_find_cps': 4096, 'n_points_find_surface': 4096, 'n_points_interfaces': 8192, 'n_points_normals': 8192, 'n_points_outer': 4096, 'no_save': False, 'num_workers': 0, 'nx': 3, 'ny': 1, 'nz': 1, 'obj_name': '7_sofa', 'outer_target': 0, 'perturbation_saddle_descent': 0.01, 'plot_every_n_epochs': 10, 'plot_n_shapes': 1, 'plot_secondary_plots_every_n_epochs': 500, 'plot_shape': True, 'problem': 'grid_world', 'recalc_cps_every_n_epochs': 1, 'recompute_surface_pts_every_n_epochs': 10, 'remove_penalty_points_outside_envelope': True, 'reweigh_surface_pts_close_to_interface': True, 'reweigh_surface_pts_close_to_interface_cutoff': 0.2, 'reweigh_surface_pts_close_to_interface_power': 2.0, 'save_every_n_epochs': 10, 'scc_penalty_norm_eps': 0.0001, 'scheduler_gamma': 0.5, 'seed': 17, 'show_colorbar': True, 'stop_grad_mag_saddle_descent': 1e-05, 'strain_curvature_clip_max': 1000.0, 'timer_accumulate': True, 'timer_print': False, 'use_compile': False, 'use_scheduler': True, 'use_x_and_z_arg': True, 'w0': 1.0, 'w0_initial': 8.0, 'wandb_entity_name': 'abra', 'wandb_experiment_name': '7_sofa', 'wandb_project_name': 'objgen', 'wandb_save_dir': 'all_runs/wandb', 'z_sample_interval': [-0.1, 0.1], 'z_sample_method': 'uniform'}, {'adam_betas_find_surface': [0.9, 0.999], 'auto_clip_hist_len': 50, 'auto_clip_min_len': 50, 'auto_clip_on': False, 'auto_clip_percentile': 0.8, 'batch_size': 1, 'cbf_lambda': -0.01, 'cbf_relaxation_penalty': 5, 'check_interval_grad_mag_saddle_descent': 5, 'controller_step_range': [0.5, 2], 'dataset_dir': '/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects/8_stool', 'dbscan.eps': 0.05, 'dbscan.y_x_mag': 1e-05, 'decay_steps': 1000, 'device': 'cuda', 'diversity_loss_eps': 0.0001, 'env_val_tol': 0.1, 'envelope_sample_from': 'exterior', 'fig_path': 'img/simjeb/cond_siren', 'fig_pynb': True, 'fig_save': False, 'fig_show': True, 'fig_size': [12, 7], 'fig_wandb': False, 'find_surface_pts_converged_interval': 10, 'find_surface_pts_n_iter': 200, 'find_surface_pts_prec_eps': 1e-06, 'force_saving_shape': False, 'gpu_list': [0], 'grad_clip': 0.5, 'grad_clipping_on': True, 'graph_algo_inv_dist_eps': 0.1, 'interface_delta': 0, 'lambda_bc': 1, 'lambda_bound': 0, 'lambda_curv': 1e-07, 'lambda_descent': 1, 'lambda_div': 0, 'lambda_dom': 1, 'lambda_eikonal': 1e-09, 'lambda_env': 0, 'lambda_normal': 1e-06, 'lambda_obst': 0.0, 'lambda_outer_env': 1, 'lambda_outer_unif': 0, 'lambda_outer_var': 0.0, 'lambda_scc': 0.01, 'lambda_small_control': 0, 'lambda_vx': 0.0001, 'lambda_vxx': 0.0001, 'layers': [4, 256, 256, 256, 1], 'level_set': 0, 'load_model': False, 'loss_optim': 'fixed', 'loss_thresh': 0.001, 'lr': 0.001, 'lr_adjust_cps': 0.001, 'lr_find_cps': 0.01, 'lr_find_surface': 0.01, 'lr_saddle_descent': 0.03, 'max_domain_val': -0.1, 'max_epochs': 250, 'max_iter_find_cps': 1000, 'mc_resolution': 128, 'min_control_norm': 0.5, 'min_env_val_inner': 0.01, 'min_env_val_outer': 0.1, 'min_loss_thresh': 1e-06, 'model': 'cond_siren', 'model_load_path': '/scratch/rhm4nj/cral/ginn/all_runs/models/cond_siren/2024_10_10-23_41_01/2024_10_10-23_41_01-9cu3lc4a_2300.pth', 'model_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/8_stool/cond_siren/2025_04_30-11_11_58/2025_04_30-11_12_01-wn3vzvkx.pth', 'model_save_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/8_stool', 'n_controller_steps': 10, 'n_iter_saddle_descent': 1000, 'n_points_descent': 16384, 'n_points_domain': 16384, 'n_points_envelope': 32768, 'n_points_find_cps': 4096, 'n_points_find_surface': 4096, 'n_points_interfaces': 8192, 'n_points_normals': 8192, 'n_points_outer': 4096, 'no_save': False, 'num_workers': 0, 'nx': 3, 'ny': 1, 'nz': 1, 'obj_name': '8_stool', 'outer_target': 0, 'perturbation_saddle_descent': 0.01, 'plot_every_n_epochs': 10, 'plot_n_shapes': 1, 'plot_secondary_plots_every_n_epochs': 500, 'plot_shape': True, 'problem': 'grid_world', 'recalc_cps_every_n_epochs': 1, 'recompute_surface_pts_every_n_epochs': 10, 'remove_penalty_points_outside_envelope': True, 'reweigh_surface_pts_close_to_interface': True, 'reweigh_surface_pts_close_to_interface_cutoff': 0.2, 'reweigh_surface_pts_close_to_interface_power': 2.0, 'save_every_n_epochs': 10, 'scc_penalty_norm_eps': 0.0001, 'scheduler_gamma': 0.5, 'seed': 17, 'show_colorbar': True, 'stop_grad_mag_saddle_descent': 1e-05, 'strain_curvature_clip_max': 1000.0, 'timer_accumulate': True, 'timer_print': False, 'use_compile': False, 'use_scheduler': True, 'use_x_and_z_arg': True, 'w0': 1.0, 'w0_initial': 8.0, 'wandb_entity_name': 'abra', 'wandb_experiment_name': '8_stool', 'wandb_project_name': 'objgen', 'wandb_save_dir': 'all_runs/wandb', 'z_sample_interval': [-0.1, 0.1], 'z_sample_method': 'uniform'}, {'adam_betas_find_surface': [0.9, 0.999], 'auto_clip_hist_len': 50, 'auto_clip_min_len': 50, 'auto_clip_on': False, 'auto_clip_percentile': 0.8, 'batch_size': 1, 'cbf_lambda': -0.01, 'cbf_relaxation_penalty': 5, 'check_interval_grad_mag_saddle_descent': 5, 'controller_step_range': [0.5, 2], 'dataset_dir': '/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects/9_chair', 'dbscan.eps': 0.05, 'dbscan.y_x_mag': 1e-05, 'decay_steps': 1000, 'device': 'cuda', 'diversity_loss_eps': 0.0001, 'env_val_tol': 0.1, 'envelope_sample_from': 'exterior', 'fig_path': 'img/simjeb/cond_siren', 'fig_pynb': True, 'fig_save': False, 'fig_show': True, 'fig_size': [12, 7], 'fig_wandb': False, 'find_surface_pts_converged_interval': 10, 'find_surface_pts_n_iter': 200, 'find_surface_pts_prec_eps': 1e-06, 'force_saving_shape': False, 'gpu_list': [0], 'grad_clip': 0.5, 'grad_clipping_on': True, 'graph_algo_inv_dist_eps': 0.1, 'interface_delta': 0, 'lambda_bc': 1, 'lambda_bound': 0, 'lambda_curv': 1e-07, 'lambda_descent': 1, 'lambda_div': 0, 'lambda_dom': 1, 'lambda_eikonal': 1e-09, 'lambda_env': 0, 'lambda_normal': 1e-06, 'lambda_obst': 0.0, 'lambda_outer_env': 1, 'lambda_outer_unif': 0, 'lambda_outer_var': 0.0, 'lambda_scc': 0.01, 'lambda_small_control': 0, 'lambda_vx': 0.0001, 'lambda_vxx': 0.0001, 'layers': [4, 256, 256, 256, 1], 'level_set': 0, 'load_model': False, 'loss_optim': 'fixed', 'loss_thresh': 0.001, 'lr': 0.001, 'lr_adjust_cps': 0.001, 'lr_find_cps': 0.01, 'lr_find_surface': 0.01, 'lr_saddle_descent': 0.03, 'max_domain_val': -0.1, 'max_epochs': 250, 'max_iter_find_cps': 1000, 'mc_resolution': 128, 'min_control_norm': 0.5, 'min_env_val_inner': 0.01, 'min_env_val_outer': 0.1, 'min_loss_thresh': 1e-06, 'model': 'cond_siren', 'model_load_path': '/scratch/rhm4nj/cral/ginn/all_runs/models/cond_siren/2024_10_10-23_41_01/2024_10_10-23_41_01-9cu3lc4a_2300.pth', 'model_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/9_chair/cond_siren/2025_04_30-11_11_48/2025_04_30-11_11_53-zq9g1e8l.pth', 'model_save_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/9_chair', 'n_controller_steps': 10, 'n_iter_saddle_descent': 1000, 'n_points_descent': 16384, 'n_points_domain': 16384, 'n_points_envelope': 32768, 'n_points_find_cps': 4096, 'n_points_find_surface': 4096, 'n_points_interfaces': 8192, 'n_points_normals': 8192, 'n_points_outer': 4096, 'no_save': False, 'num_workers': 0, 'nx': 3, 'ny': 1, 'nz': 1, 'obj_name': '9_chair', 'outer_target': 0, 'perturbation_saddle_descent': 0.01, 'plot_every_n_epochs': 10, 'plot_n_shapes': 1, 'plot_secondary_plots_every_n_epochs': 500, 'plot_shape': True, 'problem': 'grid_world', 'recalc_cps_every_n_epochs': 1, 'recompute_surface_pts_every_n_epochs': 10, 'remove_penalty_points_outside_envelope': True, 'reweigh_surface_pts_close_to_interface': True, 'reweigh_surface_pts_close_to_interface_cutoff': 0.2, 'reweigh_surface_pts_close_to_interface_power': 2.0, 'save_every_n_epochs': 10, 'scc_penalty_norm_eps': 0.0001, 'scheduler_gamma': 0.5, 'seed': 17, 'show_colorbar': True, 'stop_grad_mag_saddle_descent': 1e-05, 'strain_curvature_clip_max': 1000.0, 'timer_accumulate': True, 'timer_print': False, 'use_compile': False, 'use_scheduler': True, 'use_x_and_z_arg': True, 'w0': 1.0, 'w0_initial': 8.0, 'wandb_entity_name': 'abra', 'wandb_experiment_name': '9_chair', 'wandb_project_name': 'objgen', 'wandb_save_dir': 'all_runs/wandb', 'z_sample_interval': [-0.1, 0.1], 'z_sample_method': 'uniform'}, {'adam_betas_find_surface': [0.9, 0.999], 'auto_clip_hist_len': 50, 'auto_clip_min_len': 50, 'auto_clip_on': False, 'auto_clip_percentile': 0.8, 'batch_size': 1, 'cbf_lambda': -0.01, 'cbf_relaxation_penalty': 5, 'check_interval_grad_mag_saddle_descent': 5, 'controller_step_range': [0.5, 2], 'dataset_dir': '/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects/10_table', 'dbscan.eps': 0.05, 'dbscan.y_x_mag': 1e-05, 'decay_steps': 1000, 'device': 'cuda', 'diversity_loss_eps': 0.0001, 'env_val_tol': 0.1, 'envelope_sample_from': 'exterior', 'fig_path': 'img/simjeb/cond_siren', 'fig_pynb': True, 'fig_save': False, 'fig_show': True, 'fig_size': [12, 7], 'fig_wandb': False, 'find_surface_pts_converged_interval': 10, 'find_surface_pts_n_iter': 200, 'find_surface_pts_prec_eps': 1e-06, 'force_saving_shape': False, 'gpu_list': [0], 'grad_clip': 0.5, 'grad_clipping_on': True, 'graph_algo_inv_dist_eps': 0.1, 'interface_delta': 0, 'lambda_bc': 1, 'lambda_bound': 0, 'lambda_curv': 1e-07, 'lambda_descent': 1, 'lambda_div': 0, 'lambda_dom': 1, 'lambda_eikonal': 1e-09, 'lambda_env': 0, 'lambda_normal': 1e-06, 'lambda_obst': 0.0, 'lambda_outer_env': 1, 'lambda_outer_unif': 0, 'lambda_outer_var': 0.0, 'lambda_scc': 0.01, 'lambda_small_control': 0, 'lambda_vx': 0.0001, 'lambda_vxx': 0.0001, 'layers': [4, 256, 256, 256, 1], 'level_set': 0, 'load_model': False, 'loss_optim': 'fixed', 'loss_thresh': 0.001, 'lr': 0.001, 'lr_adjust_cps': 0.001, 'lr_find_cps': 0.01, 'lr_find_surface': 0.01, 'lr_saddle_descent': 0.03, 'max_domain_val': -0.1, 'max_epochs': 250, 'max_iter_find_cps': 1000, 'mc_resolution': 128, 'min_control_norm': 0.5, 'min_env_val_inner': 0.01, 'min_env_val_outer': 0.1, 'min_loss_thresh': 1e-06, 'model': 'cond_siren', 'model_load_path': '/scratch/rhm4nj/cral/ginn/all_runs/models/cond_siren/2024_10_10-23_41_01/2024_10_10-23_41_01-9cu3lc4a_2300.pth', 'model_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/10_table/cond_siren/2025_04_30-11_11_48/2025_04_30-11_11_53-x6l12tyu.pth', 'model_save_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/10_table', 'n_controller_steps': 10, 'n_iter_saddle_descent': 1000, 'n_points_descent': 16384, 'n_points_domain': 16384, 'n_points_envelope': 32768, 'n_points_find_cps': 4096, 'n_points_find_surface': 4096, 'n_points_interfaces': 8192, 'n_points_normals': 8192, 'n_points_outer': 4096, 'no_save': False, 'num_workers': 0, 'nx': 3, 'ny': 1, 'nz': 1, 'obj_name': '10_table', 'outer_target': 0, 'perturbation_saddle_descent': 0.01, 'plot_every_n_epochs': 10, 'plot_n_shapes': 1, 'plot_secondary_plots_every_n_epochs': 500, 'plot_shape': True, 'problem': 'grid_world', 'recalc_cps_every_n_epochs': 1, 'recompute_surface_pts_every_n_epochs': 10, 'remove_penalty_points_outside_envelope': True, 'reweigh_surface_pts_close_to_interface': True, 'reweigh_surface_pts_close_to_interface_cutoff': 0.2, 'reweigh_surface_pts_close_to_interface_power': 2.0, 'save_every_n_epochs': 10, 'scc_penalty_norm_eps': 0.0001, 'scheduler_gamma': 0.5, 'seed': 17, 'show_colorbar': True, 'stop_grad_mag_saddle_descent': 1e-05, 'strain_curvature_clip_max': 1000.0, 'timer_accumulate': True, 'timer_print': False, 'use_compile': False, 'use_scheduler': True, 'use_x_and_z_arg': True, 'w0': 1.0, 'w0_initial': 8.0, 'wandb_entity_name': 'abra', 'wandb_experiment_name': '10_table', 'wandb_project_name': 'objgen', 'wandb_save_dir': 'all_runs/wandb', 'z_sample_interval': [-0.1, 0.1], 'z_sample_method': 'uniform'}, {'adam_betas_find_surface': [0.9, 0.999], 'auto_clip_hist_len': 50, 'auto_clip_min_len': 50, 'auto_clip_on': False, 'auto_clip_percentile': 0.8, 'batch_size': 1, 'cbf_lambda': -0.01, 'cbf_relaxation_penalty': 5, 'check_interval_grad_mag_saddle_descent': 5, 'controller_step_range': [0.5, 2], 'dataset_dir': '/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects/11_lamp', 'dbscan.eps': 0.05, 'dbscan.y_x_mag': 1e-05, 'decay_steps': 1000, 'device': 'cuda', 'diversity_loss_eps': 0.0001, 'env_val_tol': 0.1, 'envelope_sample_from': 'exterior', 'fig_path': 'img/simjeb/cond_siren', 'fig_pynb': True, 'fig_save': False, 'fig_show': True, 'fig_size': [12, 7], 'fig_wandb': False, 'find_surface_pts_converged_interval': 10, 'find_surface_pts_n_iter': 200, 'find_surface_pts_prec_eps': 1e-06, 'force_saving_shape': False, 'gpu_list': [0], 'grad_clip': 0.5, 'grad_clipping_on': True, 'graph_algo_inv_dist_eps': 0.1, 'interface_delta': 0, 'lambda_bc': 1, 'lambda_bound': 0, 'lambda_curv': 1e-07, 'lambda_descent': 1, 'lambda_div': 0, 'lambda_dom': 1, 'lambda_eikonal': 1e-09, 'lambda_env': 0, 'lambda_normal': 1e-06, 'lambda_obst': 0.0, 'lambda_outer_env': 1, 'lambda_outer_unif': 0, 'lambda_outer_var': 0.0, 'lambda_scc': 0.01, 'lambda_small_control': 0, 'lambda_vx': 0.0001, 'lambda_vxx': 0.0001, 'layers': [4, 256, 256, 256, 1], 'level_set': 0, 'load_model': False, 'loss_optim': 'fixed', 'loss_thresh': 0.001, 'lr': 0.001, 'lr_adjust_cps': 0.001, 'lr_find_cps': 0.01, 'lr_find_surface': 0.01, 'lr_saddle_descent': 0.03, 'max_domain_val': -0.1, 'max_epochs': 250, 'max_iter_find_cps': 1000, 'mc_resolution': 128, 'min_control_norm': 0.5, 'min_env_val_inner': 0.01, 'min_env_val_outer': 0.1, 'min_loss_thresh': 1e-06, 'model': 'cond_siren', 'model_load_path': '/scratch/rhm4nj/cral/ginn/all_runs/models/cond_siren/2024_10_10-23_41_01/2024_10_10-23_41_01-9cu3lc4a_2300.pth', 'model_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/11_lamp/cond_siren/2025_04_30-11_11_48/2025_04_30-11_11_53-5ojbo2lq.pth', 'model_save_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/11_lamp', 'n_controller_steps': 10, 'n_iter_saddle_descent': 1000, 'n_points_descent': 16384, 'n_points_domain': 16384, 'n_points_envelope': 32768, 'n_points_find_cps': 4096, 'n_points_find_surface': 4096, 'n_points_interfaces': 8192, 'n_points_normals': 8192, 'n_points_outer': 4096, 'no_save': False, 'num_workers': 0, 'nx': 3, 'ny': 1, 'nz': 1, 'obj_name': '11_lamp', 'outer_target': 0, 'perturbation_saddle_descent': 0.01, 'plot_every_n_epochs': 10, 'plot_n_shapes': 1, 'plot_secondary_plots_every_n_epochs': 500, 'plot_shape': True, 'problem': 'grid_world', 'recalc_cps_every_n_epochs': 1, 'recompute_surface_pts_every_n_epochs': 10, 'remove_penalty_points_outside_envelope': True, 'reweigh_surface_pts_close_to_interface': True, 'reweigh_surface_pts_close_to_interface_cutoff': 0.2, 'reweigh_surface_pts_close_to_interface_power': 2.0, 'save_every_n_epochs': 10, 'scc_penalty_norm_eps': 0.0001, 'scheduler_gamma': 0.5, 'seed': 17, 'show_colorbar': True, 'stop_grad_mag_saddle_descent': 1e-05, 'strain_curvature_clip_max': 1000.0, 'timer_accumulate': True, 'timer_print': False, 'use_compile': False, 'use_scheduler': True, 'use_x_and_z_arg': True, 'w0': 1.0, 'w0_initial': 8.0, 'wandb_entity_name': 'abra', 'wandb_experiment_name': '11_lamp', 'wandb_project_name': 'objgen', 'wandb_save_dir': 'all_runs/wandb', 'z_sample_interval': [-0.1, 0.1], 'z_sample_method': 'uniform'}]\n",
      "all_n: 12\n",
      "all_scale_factors: tensor([4.1869, 0.5177, 0.5232, 0.5549, 1.0042, 0.6363, 0.7711, 1.6795, 0.6357,\n",
      "        0.7833, 0.6502, 0.5197], device='cuda:0')\n",
      "alpha: 4\n",
      "bounds: GradTrackingTensor(lvl=-2, value=\n",
      "    tensor([[[-0.9929,  6.9890],\n",
      "             [-1.2955,  3.5994],\n",
      "             [-1.5380,  0.9037]],\n",
      "\n",
      "            [[ 2.0551,  5.0045],\n",
      "             [ 1.9441,  3.2856],\n",
      "             [-1.5321, -0.4887]]], device='cuda:0')\n",
      ")\n",
      "centers_for_translations: GradTrackingTensor(lvl=-2, value=\n",
      "    tensor([[ 2.9991,  1.1502, -0.3157],\n",
      "            [ 3.5319,  2.6128, -1.0088]], device='cuda:0')\n",
      ")\n",
      "configs: [{'adam_betas_find_surface': [0.9, 0.999], 'auto_clip_hist_len': 50, 'auto_clip_min_len': 50, 'auto_clip_on': False, 'auto_clip_percentile': 0.8, 'batch_size': 1, 'cbf_lambda': -0.01, 'cbf_relaxation_penalty': 5, 'check_interval_grad_mag_saddle_descent': 5, 'controller_step_range': [0.5, 2], 'dataset_dir': '/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects/0_wall', 'dbscan.eps': 0.05, 'dbscan.y_x_mag': 1e-05, 'decay_steps': 1000, 'device': 'cuda', 'diversity_loss_eps': 0.0001, 'env_val_tol': 0.1, 'envelope_sample_from': 'exterior', 'fig_path': 'img/simjeb/cond_siren', 'fig_pynb': True, 'fig_save': False, 'fig_show': True, 'fig_size': [12, 7], 'fig_wandb': False, 'find_surface_pts_converged_interval': 10, 'find_surface_pts_n_iter': 200, 'find_surface_pts_prec_eps': 1e-06, 'force_saving_shape': False, 'gpu_list': [0], 'grad_clip': 0.5, 'grad_clipping_on': True, 'graph_algo_inv_dist_eps': 0.1, 'interface_delta': 0, 'lambda_bc': 1, 'lambda_bound': 0, 'lambda_curv': 1e-07, 'lambda_descent': 1, 'lambda_div': 0, 'lambda_dom': 1, 'lambda_eikonal': 1e-09, 'lambda_env': 0, 'lambda_normal': 1e-06, 'lambda_obst': 0.0, 'lambda_outer_env': 1, 'lambda_outer_unif': 0, 'lambda_outer_var': 0.0, 'lambda_scc': 0.01, 'lambda_small_control': 0, 'lambda_vx': 0.0001, 'lambda_vxx': 0.0001, 'layers': [4, 256, 256, 256, 1], 'level_set': 0, 'load_model': False, 'loss_optim': 'fixed', 'loss_thresh': 0.001, 'lr': 0.001, 'lr_adjust_cps': 0.001, 'lr_find_cps': 0.01, 'lr_find_surface': 0.01, 'lr_saddle_descent': 0.03, 'max_domain_val': -0.1, 'max_epochs': 250, 'max_iter_find_cps': 1000, 'mc_resolution': 128, 'min_control_norm': 0.5, 'min_env_val_inner': 0.01, 'min_env_val_outer': 0.1, 'min_loss_thresh': 1e-06, 'model': 'cond_siren', 'model_load_path': '/scratch/rhm4nj/cral/ginn/all_runs/models/cond_siren/2024_10_10-23_41_01/2024_10_10-23_41_01-9cu3lc4a_2300.pth', 'model_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/0_wall/cond_siren/2025_04_30-11_11_53/2025_04_30-11_11_54-875n7ept.pth', 'model_save_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/0_wall', 'n_controller_steps': 10, 'n_iter_saddle_descent': 1000, 'n_points_descent': 16384, 'n_points_domain': 16384, 'n_points_envelope': 32768, 'n_points_find_cps': 4096, 'n_points_find_surface': 4096, 'n_points_interfaces': 8192, 'n_points_normals': 8192, 'n_points_outer': 4096, 'no_save': False, 'num_workers': 0, 'nx': 3, 'ny': 1, 'nz': 1, 'obj_name': '0_wall', 'outer_target': 0, 'perturbation_saddle_descent': 0.01, 'plot_every_n_epochs': 10, 'plot_n_shapes': 1, 'plot_secondary_plots_every_n_epochs': 500, 'plot_shape': True, 'problem': 'grid_world', 'recalc_cps_every_n_epochs': 1, 'recompute_surface_pts_every_n_epochs': 10, 'remove_penalty_points_outside_envelope': True, 'reweigh_surface_pts_close_to_interface': True, 'reweigh_surface_pts_close_to_interface_cutoff': 0.2, 'reweigh_surface_pts_close_to_interface_power': 2.0, 'save_every_n_epochs': 10, 'scc_penalty_norm_eps': 0.0001, 'scheduler_gamma': 0.5, 'seed': 17, 'show_colorbar': True, 'stop_grad_mag_saddle_descent': 1e-05, 'strain_curvature_clip_max': 1000.0, 'timer_accumulate': True, 'timer_print': False, 'use_compile': False, 'use_scheduler': True, 'use_x_and_z_arg': True, 'w0': 1.0, 'w0_initial': 8.0, 'wandb_entity_name': 'abra', 'wandb_experiment_name': '0_wall', 'wandb_project_name': 'objgen', 'wandb_save_dir': 'all_runs/wandb', 'z_sample_interval': [-0.1, 0.1], 'z_sample_method': 'uniform'}, {'adam_betas_find_surface': [0.9, 0.999], 'auto_clip_hist_len': 50, 'auto_clip_min_len': 50, 'auto_clip_on': False, 'auto_clip_percentile': 0.8, 'batch_size': 1, 'cbf_lambda': -0.01, 'cbf_relaxation_penalty': 5, 'check_interval_grad_mag_saddle_descent': 5, 'controller_step_range': [0.5, 2], 'dataset_dir': '/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/room_0_objects/7_sofa', 'dbscan.eps': 0.05, 'dbscan.y_x_mag': 1e-05, 'decay_steps': 1000, 'device': 'cuda', 'diversity_loss_eps': 0.0001, 'env_val_tol': 0.1, 'envelope_sample_from': 'exterior', 'fig_path': 'img/simjeb/cond_siren', 'fig_pynb': True, 'fig_save': False, 'fig_show': True, 'fig_size': [12, 7], 'fig_wandb': False, 'find_surface_pts_converged_interval': 10, 'find_surface_pts_n_iter': 200, 'find_surface_pts_prec_eps': 1e-06, 'force_saving_shape': False, 'gpu_list': [0], 'grad_clip': 0.5, 'grad_clipping_on': True, 'graph_algo_inv_dist_eps': 0.1, 'interface_delta': 0, 'lambda_bc': 1, 'lambda_bound': 0, 'lambda_curv': 1e-07, 'lambda_descent': 1, 'lambda_div': 0, 'lambda_dom': 1, 'lambda_eikonal': 1e-09, 'lambda_env': 0, 'lambda_normal': 1e-06, 'lambda_obst': 0.0, 'lambda_outer_env': 1, 'lambda_outer_unif': 0, 'lambda_outer_var': 0.0, 'lambda_scc': 0.01, 'lambda_small_control': 0, 'lambda_vx': 0.0001, 'lambda_vxx': 0.0001, 'layers': [4, 256, 256, 256, 1], 'level_set': 0, 'load_model': False, 'loss_optim': 'fixed', 'loss_thresh': 0.001, 'lr': 0.001, 'lr_adjust_cps': 0.001, 'lr_find_cps': 0.01, 'lr_find_surface': 0.01, 'lr_saddle_descent': 0.03, 'max_domain_val': -0.1, 'max_epochs': 250, 'max_iter_find_cps': 1000, 'mc_resolution': 128, 'min_control_norm': 0.5, 'min_env_val_inner': 0.01, 'min_env_val_outer': 0.1, 'min_loss_thresh': 1e-06, 'model': 'cond_siren', 'model_load_path': '/scratch/rhm4nj/cral/ginn/all_runs/models/cond_siren/2024_10_10-23_41_01/2024_10_10-23_41_01-9cu3lc4a_2300.pth', 'model_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/7_sofa/cond_siren/2025_04_30-11_11_53/2025_04_30-11_11_54-24qou3a8.pth', 'model_save_path': '/scratch/rhm4nj/cral/cral-ginn/ginn/all_runs/models/experiments/2025-04-30_11-11-10_room_0_objects_final/7_sofa', 'n_controller_steps': 10, 'n_iter_saddle_descent': 1000, 'n_points_descent': 16384, 'n_points_domain': 16384, 'n_points_envelope': 32768, 'n_points_find_cps': 4096, 'n_points_find_surface': 4096, 'n_points_interfaces': 8192, 'n_points_normals': 8192, 'n_points_outer': 4096, 'no_save': False, 'num_workers': 0, 'nx': 3, 'ny': 1, 'nz': 1, 'obj_name': '7_sofa', 'outer_target': 0, 'perturbation_saddle_descent': 0.01, 'plot_every_n_epochs': 10, 'plot_n_shapes': 1, 'plot_secondary_plots_every_n_epochs': 500, 'plot_shape': True, 'problem': 'grid_world', 'recalc_cps_every_n_epochs': 1, 'recompute_surface_pts_every_n_epochs': 10, 'remove_penalty_points_outside_envelope': True, 'reweigh_surface_pts_close_to_interface': True, 'reweigh_surface_pts_close_to_interface_cutoff': 0.2, 'reweigh_surface_pts_close_to_interface_power': 2.0, 'save_every_n_epochs': 10, 'scc_penalty_norm_eps': 0.0001, 'scheduler_gamma': 0.5, 'seed': 17, 'show_colorbar': True, 'stop_grad_mag_saddle_descent': 1e-05, 'strain_curvature_clip_max': 1000.0, 'timer_accumulate': True, 'timer_print': False, 'use_compile': False, 'use_scheduler': True, 'use_x_and_z_arg': True, 'w0': 1.0, 'w0_initial': 8.0, 'wandb_entity_name': 'abra', 'wandb_experiment_name': '7_sofa', 'wandb_project_name': 'objgen', 'wandb_save_dir': 'all_runs/wandb', 'z_sample_interval': [-0.1, 0.1], 'z_sample_method': 'uniform'}]\n",
      "device: cuda:0\n",
      "do_mask: True\n",
      "jacobian: None\n",
      "mask_dist: 0.4\n",
      "model2mesh: {}\n",
      "n: 2\n",
      "netp: <models.net_w_partials.NetWithPartials object at 0x7fc18bf8eb50>\n",
      "scale: 1\n",
      "scale_factors: GradTrackingTensor(lvl=-2, value=\n",
      "    tensor([4.1869, 1.6795], device='cuda:0')\n",
      ")\n",
      "training: True\n",
      "upper_bound: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a2166339a44ca2b43c0d4ef9bbd297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TraitError",
     "evalue": "The 'positions' trait of a Points instance expected a numpy array or a dict, not the Tensor tensor([ 6.1381,  2.9646, -1.3000], device='cuda:0').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTraitError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m         new_plot \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m k3d\u001b[38;5;241m.\u001b[39mpoints(wp_targets[i], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0x00AFFa\u001b[39m, point_size\u001b[38;5;241m=\u001b[39mpoint_size)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# start - aqua\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m point \u001b[38;5;241m=\u001b[39m \u001b[43mk3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_positions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoint_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoint_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0x00FFFF\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m new_plot \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m point\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# goal - green\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/rhm4nj/.conda/final_ginn_env/lib/python3.11/site-packages/k3d/factory.py:620\u001b[0m, in \u001b[0;36mpoints\u001b[0;34m(positions, colors, color, point_size, point_sizes, shader, opacity, opacities, attribute, color_map, color_range, opacity_function, name, group, custom_data, compression_level, mesh_detail, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m attribute \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    614\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(attribute, np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\n\u001b[1;32m    615\u001b[0m         attribute) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m attribute\n\u001b[1;32m    616\u001b[0m )\n\u001b[1;32m    617\u001b[0m color_range \u001b[38;5;241m=\u001b[39m check_attribute_color_range(attribute, color_range)\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m process_transform_arguments(\n\u001b[0;32m--> 620\u001b[0m     \u001b[43mPoints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoint_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoint_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoint_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoint_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopacity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopacity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopacities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopacities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmesh_detail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmesh_detail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattribute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopacity_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopacity_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    640\u001b[0m )\n",
      "File \u001b[0;32m/scratch/rhm4nj/.conda/final_ginn_env/lib/python3.11/site-packages/k3d/objects.py:735\u001b[0m, in \u001b[0;36mPoints.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 735\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mPoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_trait(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPoints\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/scratch/rhm4nj/.conda/final_ginn_env/lib/python3.11/site-packages/k3d/objects.py:194\u001b[0m, in \u001b[0;36mDrawableWithCallback.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDrawableWithCallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_msg(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_custom_msg)\n",
      "File \u001b[0;32m/scratch/rhm4nj/.conda/final_ginn_env/lib/python3.11/site-packages/k3d/objects.py:108\u001b[0m, in \u001b[0;36mDrawable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDrawable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ipywidgets/widgets/widget.py:503\u001b[0m, in \u001b[0;36mWidget.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Public constructor\"\"\"\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_id \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m Widget\u001b[38;5;241m.\u001b[39m_call_widget_constructed(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/traitlets/traitlets.py:1355\u001b[0m, in \u001b[0;36mHasTraits.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_trait(key):\n\u001b[0;32m-> 1355\u001b[0m         \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value)\n\u001b[1;32m   1356\u001b[0m         changes[key] \u001b[38;5;241m=\u001b[39m Bunch(\n\u001b[1;32m   1357\u001b[0m             name\u001b[38;5;241m=\u001b[39mkey,\n\u001b[1;32m   1358\u001b[0m             old\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchange\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1362\u001b[0m         )\n\u001b[1;32m   1363\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1364\u001b[0m         \u001b[38;5;66;03m# passthrough args that don't set traits to super\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/traitlets/traitlets.py:716\u001b[0m, in \u001b[0;36mTraitType.__set__\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_only:\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TraitError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m trait is read-only.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m--> 716\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/traitlets/traitlets.py:690\u001b[0m, in \u001b[0;36mTraitType.set\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: HasTraits, value: S) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 690\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/traitlets/traitlets.py:722\u001b[0m, in \u001b[0;36mTraitType._validate\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 722\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_cross_validation_lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    724\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross_validate(obj, value)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/traitlets/traitlets.py:2460\u001b[0m, in \u001b[0;36mUnion.validate\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m   2458\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m TraitError:\n\u001b[1;32m   2459\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 2460\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/traitlets/traitlets.py:831\u001b[0m, in \u001b[0;36mTraitType.error\u001b[0;34m(self, obj, value, error, info)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    826\u001b[0m     e \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m trait expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, not \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    827\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    828\u001b[0m         info \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo(),\n\u001b[1;32m    829\u001b[0m         describe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe\u001b[39m\u001b[38;5;124m\"\u001b[39m, value),\n\u001b[1;32m    830\u001b[0m     )\n\u001b[0;32m--> 831\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TraitError(e)\n",
      "\u001b[0;31mTraitError\u001b[0m: The 'positions' trait of a Points instance expected a numpy array or a dict, not the Tensor tensor([ 6.1381,  2.9646, -1.3000], device='cuda:0')."
     ]
    }
   ],
   "source": [
    "def downsample_point_cloud_random(point_cloud, num_points):\n",
    "    if point_cloud.shape[0] <= num_points:\n",
    "        return point_cloud  # Already small enough\n",
    "\n",
    "    indices = np.random.choice(point_cloud.shape[0], num_points, replace=False)\n",
    "    return point_cloud[indices]\n",
    "\n",
    "def print_model_attributes(m):\n",
    "    for name, val in sorted(vars(m).items()):\n",
    "        print(f\"{name}: {val}\")\n",
    "print_model_attributes(model)\n",
    "\n",
    "new_plot = k3d.plot(camera_auto_fit=False)\n",
    "new_plot.display()\n",
    "model.reset_submodels()\n",
    "\n",
    "CBFModel.device = 'cuda'\n",
    "CBFModel.update_plot(model, z_div, new_plot, mc_resolution=80, w=25)\n",
    "CBFModel.device = 'cpu'\n",
    "\n",
    "new_plot.camera = [11.05572016086761, -10.92883132467544, 0.43506265386600385, 3.0019142627716064, 1.151877522468567, -0.3703179359436035, 0, 0, 1]\n",
    "\n",
    "small_pcd = downsample_point_cloud_random(point_cloud, min(point_cloud.shape[0], 200000))\n",
    "# new_plot += k3d.points(positions=small_pcd.astype(np.float32), point_size=0.01, color=0xff0000)\n",
    "new_plot += k3d.points(positions=small_pcd.astype(np.float32), point_size=0.01)\n",
    "\n",
    "point_size = 0.15\n",
    "\n",
    "if do_optimal:\n",
    "    for i, p in enumerate(all_paths):\n",
    "        if i != target_index: continue\n",
    "        new_plot += k3d.line(p, color=0xaaddaa, width=0.05)\n",
    "        new_plot += k3d.points(p, color=0xaaddaa, point_size=point_size)\n",
    "        new_plot += k3d.points(wp_targets[i], color=0x00AFFa, point_size=point_size)\n",
    "\n",
    "# start - aqua\n",
    "point = k3d.points(positions=start_positions[target_index], point_size=point_size, color=0x00FFFF)\n",
    "new_plot += point\n",
    "\n",
    "# goal - green\n",
    "goal_point = k3d.points(positions=goal_positions[target_index], point_size=point_size, color=0x00FF00)\n",
    "new_plot += goal_point\n",
    "\n",
    "print(start_positions[target_index], goal_positions[target_index])\n",
    "\n",
    "trajectories = {}\n",
    "start_pt_new = [2.75, -0.5, -1.8]\n",
    "end_pt_new = [4.4, -0.5, -1]\n",
    "\n",
    "# start_pt_new = small_pcd.mean(axis=0)\n",
    "new_interactive_point = InteractivePoint(start_pt_new, new_plot, point_size=0.15, color=0xFFFF00)\n",
    "new_interactive_point = InteractivePoint(end_pt_new, new_plot, point_size=0.15, color=0xFF0FF0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.05572016086761, -10.92883132467544, 0.43506265386600385, 3.0019142627716064, 1.151877522468567, -0.3703179359436035, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(new_plot.camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added points to graph\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19960f214d949c38c8af56c1af94d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, description='time step', max=180)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f511900225a42a1b656c5f0c4c1e8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, description='model idx', max=11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6ea4ee8d4b434d91fa84c39ed317f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='x', max=20.0, min=-20.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a365016483ad4c3983318f89bb6b8ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='y', max=20.0, min=-20.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489a66cc3260499c8697059719e9bd4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='z', max=20.0, min=-20.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01eb0eb0cb114546b3daf8b405e7f46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a88190c1e4d4018b37d4bd1cbc47f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, '0_wall'], [1, '1_lamp'], [2, '2_table'], [3, '3_table'], [4, '4_table'], [5, '5_stool'], [6, '6_chair'], [7, '7_sofa'], [8, '8_stool'], [9, '9_chair'], [10, '10_table'], [11, '11_lamp'], [12, '12_ceiling'], [13, '13_floor']]\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from copy import deepcopy\n",
    "\n",
    "show_fails = True\n",
    "\n",
    "def add_trajectory(plot, points: np.ndarray, i:int, name: str = None, color=0x0fff00, width=0.05, show_points = True):\n",
    "    if name is None:\n",
    "        name = str(uuid.uuid4())  # Generate a unique ID if no name is given\n",
    "\n",
    "    if name in trajectories:\n",
    "        raise ValueError(f\"A trajectory with the name '{name}' already exists.\")\n",
    "\n",
    "    # Create trajectory line\n",
    "    trajectory = k3d.line(points, color=color, width=width)\n",
    "\n",
    "    plot += trajectory\n",
    "    if show_points:\n",
    "        start_point = k3d.points(positions=points[0], point_size=3*width, color=color)\n",
    "        goal_point = k3d.points(positions=goal_positions[i], point_size=3*width, color=color)\n",
    "\n",
    "        trajectories[name + \"start\"] = start_point\n",
    "        trajectories[name + \"end\"] = goal_point\n",
    "        plot += start_point\n",
    "        plot += goal_point\n",
    "        print(\"added points to graph\")\n",
    "\n",
    "    trajectories[name] = trajectory\n",
    "    if show_points:\n",
    "        trajectories[name + \"start\"] = start_point\n",
    "        trajectories[name + \"end\"] = goal_point\n",
    "\n",
    "    # print(f\"Trajectory '{name}' added.\")\n",
    "    return name\n",
    "\n",
    "def remove_trajectory(plot, name: str):\n",
    "    if name in trajectories:\n",
    "        plot -= trajectories[name]\n",
    "\n",
    "        if name + \"start\" in trajectories:\n",
    "            plot -= trajectories[name + \"start\"]\n",
    "            plot -= trajectories[name + \"end\"]\n",
    "\n",
    "            del trajectories[name]\n",
    "            del trajectories[name + \"start\"]\n",
    "            del trajectories[name + \"end\"]\n",
    "\n",
    "        print(f\"Trajectory '{name}' removed.\")\n",
    "    else:\n",
    "        print(f\"No trajectory found with the name '{name}'.\")\n",
    "\n",
    "traj_copy = {t: v for t, v in trajectories.items()}\n",
    "for traj in traj_copy: remove_trajectory(new_plot, traj)\n",
    "if show_fails:\n",
    "    for i, traj in enumerate(all_trajectories):\n",
    "        if inactivation_reasons[i] != \"goal_reached\":\n",
    "            add_trajectory(new_plot, traj, i, color=0xfff000)\n",
    "            \n",
    "        else:\n",
    "            add_trajectory(new_plot, traj, i, color=0x0000ff)\n",
    "\n",
    "add_trajectory(new_plot, trajectory, target_index, show_points=False)\n",
    "\n",
    "max_outs = 1\n",
    "n_outs = 0\n",
    "n_steps = durations[target_index]\n",
    "\n",
    "if len(trajectory) > 0:\n",
    "    point.positions = trajectory[0].astype(np.float32).tolist()\n",
    "    goal_point.positions = goal_positions[target_index].astype(np.float32).tolist()\n",
    "    # goal_point.point_size = 0.75\n",
    "    # goal_point.color=0x00FF00\n",
    "\n",
    "out_widget = widgets.Output()\n",
    "\n",
    "def move_point(positions):\n",
    "    for i in tqdm(range(positions.shape[0]), desc=\"episode\"):  # Time steps\n",
    "        point.positions = positions[i].astype(np.float32).tolist() \n",
    "        time.sleep(0.1)\n",
    "\n",
    "@out_widget.capture()\n",
    "def update_graph(idx):\n",
    "    global out_widget, n_outs\n",
    "\n",
    "    n_outs += 1\n",
    "    if n_outs >= max_outs:\n",
    "        out_widget.clear_output()\n",
    "\n",
    "    idx = int(idx)\n",
    "    if len(trajectory) > 0:\n",
    "        point.positions = trajectory[idx].astype(np.float32).tolist()\n",
    "        print(\"safety:\", trajectory_values[idx].tolist())\n",
    "        print(\"position\", trajectory[idx])\n",
    "        print(\"Lg_V\", trajectory_lie_g[idx].tolist())\n",
    "        print(\"Lg_F\", trajectory_lie_f[idx].tolist())\n",
    "        print(\"u_ref\", trajectory_urefs[idx].tolist())\n",
    "        print(\"u\", trajectory_us[idx].tolist())\n",
    "\n",
    "\n",
    "@out_widget.capture()\n",
    "def move_graph_model(idx, x, y, z):\n",
    "    global out_widget, n_outs\n",
    "    # model.reset_submodels()\n",
    "    n_outs += 1\n",
    "    if n_outs >= 10:\n",
    "        out_widget.clear_output()\n",
    "\n",
    "    step = torch.tensor([x, y, z]).to(model.device)\n",
    "    model.move_model(idx, model.all_centers_for_translations[idx] + step)\n",
    "    print(idx)\n",
    "\n",
    "    # CBFModel.device = 'cuda'\n",
    "    # CBFModel.update_plot(model, z_div, new_plot, mc_resolution=46, w=25)\n",
    "    # CBFModel.device = 'cpu'\n",
    "\n",
    "slider = widgets.IntSlider(\n",
    "    value=0,  # Initial value\n",
    "    min=0,    # Minimum value\n",
    "    max=n_steps,    # Maximum value\n",
    "    step=1,   # Step size\n",
    "    description=\"time step\",\n",
    ")\n",
    "\n",
    "w = 20\n",
    "obj_slider_x = widgets.FloatSlider(\n",
    "    value=0,  # Initial value\n",
    "    min=-w,    # Minimum value\n",
    "    max=w,    # Maximum value\n",
    "    step=0.1,   # Step size\n",
    "    description=\"x\",\n",
    ")\n",
    "\n",
    "obj_slider_y = widgets.FloatSlider(\n",
    "    value=0,  # Initial value\n",
    "    min=-w,    # Minimum value\n",
    "    max=w,    # Maximum value\n",
    "    step=0.1,   # Step size\n",
    "    description=\"y\",\n",
    ")\n",
    "\n",
    "obj_slider_z = widgets.FloatSlider(\n",
    "    value=0,  # Initial value\n",
    "    min=-w,    # Minimum value\n",
    "    max=w,    # Maximum value\n",
    "    step=0.1,   # Step size\n",
    "    description=\"z\",\n",
    ")\n",
    "\n",
    "obj_slider_idx = widgets.IntSlider(\n",
    "    value=0,  # Initial value\n",
    "    min=0,    # Minimum value\n",
    "    max=len(model.models)-1,    # Maximum value\n",
    "    step=1,   # Step size\n",
    "    description=\"model idx\",\n",
    ")\n",
    "\n",
    "widgets.interactive(update_graph, idx=slider)\n",
    "widgets.interactive(move_graph_model, idx=obj_slider_idx, x=obj_slider_x, y=obj_slider_y, z=obj_slider_z)\n",
    "    \n",
    "display(slider)\n",
    "display(obj_slider_idx)\n",
    "display(obj_slider_x)\n",
    "display(obj_slider_y)\n",
    "display(obj_slider_z)\n",
    "\n",
    "display(out_widget)\n",
    "\n",
    "new_plot.display()\n",
    "\n",
    "print([[i, obj_name] for i, obj_name in enumerate(obj_names)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.7162043  2.6881256 -0.85     ]\n",
      "Point V [ 1.7162043  2.6881256 -0.85     ] [0.608356237411499]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_2d_grid_with_model(x_range, y_range, steps, model, points=None, z_level=0, z_div=None, arrows=None):\n",
    "    # Generate x and y linspace\n",
    "    x_values = torch.linspace(*x_range, steps)\n",
    "    y_values = torch.linspace(*y_range, steps)\n",
    "    X, Y = torch.meshgrid(x_values, y_values, indexing=\"ij\")\n",
    "    \n",
    "    # Flatten the grid for model input\n",
    "    flattened_X = X.flatten()\n",
    "    flattened_Y = Y.flatten()\n",
    "    flattened_Z = torch.full_like(flattened_X, z_level)\n",
    "    \n",
    "    # Prepare inputs for the model\n",
    "    xy_inputs = torch.stack([flattened_X, flattened_Y, flattened_Z], dim=1)\n",
    "    z_inputs = torch.full((xy_inputs.shape[0], 1), z_div.item())\n",
    "\n",
    "    output = model(xy_inputs, z_inputs)\n",
    "    Z = output.view(steps, steps).detach().cpu().numpy()\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    norm = mcolors.TwoSlopeNorm(vmin=-1, vcenter=0, vmax=1)\n",
    "    # norm = mcolors.TwoSlopeNorm(vmin=-1e-10, vcenter=0, vmax=1e-10)\n",
    "    c = ax.pcolormesh(X.numpy(), Y.numpy(), Z, shading='auto', cmap='bwr', norm=norm)\n",
    "    plt.colorbar(c, ax=ax, label='Model Output')\n",
    "    ax.set_xlabel('X-axis')\n",
    "    ax.set_ylabel('Y-axis')\n",
    "    ax.set_title('2D Grid of Model Outputs')\n",
    "\n",
    "    # Plot individual points if provided\n",
    "    if points:\n",
    "        for point in points:\n",
    "            print(\"Point V\", point, model(torch.tensor([point]), z_div.unsqueeze(0)).cpu().tolist())\n",
    "        points_x, points_y, points_z = zip(*points)  # Unpack the points into x and y coordinates\n",
    "        ax.scatter(points_x, points_y, color='green', s=50, label='Points')\n",
    "\n",
    "    # Plot the arrow if provided\n",
    "    if arrows:\n",
    "        for arrow in arrows:\n",
    "            (x_start, y_start), (x_end, y_end), color = arrow\n",
    "            ax.arrow(x_start, y_start, x_end - x_start, y_end - y_start, \n",
    "                    head_width=0.2, head_length=0.3, fc=color, ec=color, linewidth=2, label='Arrow')\n",
    "\n",
    "    # Add legend if points or arrow are plotted\n",
    "    if points or arrows:\n",
    "        ax.legend()\n",
    "\n",
    "    plt.savefig(\"cylinder_safety.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# model.upper_bound = 15\n",
    "width = 5\n",
    "t = int(slider.value)\n",
    "\n",
    "# point.positions = [-20.5, 39.2, 3]\n",
    "new_interactive_point.point = point.positions\n",
    "# new_interactive_point.point[2] = -0.99\n",
    "# print(new_interactive_point.point)\n",
    "\n",
    "# new_interactive_point.point = small_pcd.mean(axis=0)\n",
    "# new_interactive_point.point[2] = -0.75\n",
    "\n",
    "print(new_interactive_point.point)\n",
    "\n",
    "arrow_start = (new_interactive_point.point[0], new_interactive_point.point[1])\n",
    "arrow_end = (new_interactive_point.point[0] + trajectory_us[t][0], new_interactive_point.point[1] + trajectory_us[t][1])\n",
    "arrow_u = (arrow_start, arrow_end, 'black')\n",
    "\n",
    "arrow_start = (new_interactive_point.point[0], new_interactive_point.point[1])\n",
    "arrow_end = (new_interactive_point.point[0] + trajectory_urefs[t][0], new_interactive_point.point[1] + trajectory_urefs[t][1])\n",
    "arrow_uref = (arrow_start, arrow_end, 'green')\n",
    "\n",
    "plot_2d_grid_with_model(\n",
    "    x_range=(new_interactive_point.point[0] - width, new_interactive_point.point[0] + width),\n",
    "    y_range=(new_interactive_point.point[1] - width, new_interactive_point.point[1] + width),\n",
    "    steps=200,\n",
    "    z_div = z_div,\n",
    "    model=model,\n",
    "    z_level=new_interactive_point.point[2],\n",
    "    points=[new_interactive_point.point],\n",
    "    # points=[[1, 1.1,-1.1]],\n",
    "    arrows=[arrow_u, arrow_uref]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.7162043  2.6881256 -0.85     ]\n",
      "Point V [ 1.7162043  2.6881256 -0.85     ] [0.608356237411499]\n",
      "Point V [ 1.7162043  2.6881256 -0.85     ] [0.608356237411499]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_2d_grid_zx_section(x_range, z_range, steps, model, points=None, y_level=0, z_div=None, arrows=None):\n",
    "    # Generate x and z linspace\n",
    "    x_values = torch.linspace(*x_range, steps)\n",
    "    z_values = torch.linspace(*z_range, steps)\n",
    "    X, Z = torch.meshgrid(x_values, z_values, indexing=\"ij\")\n",
    "    \n",
    "    # Flatten the grid for model input.\n",
    "    # We fix y to the given y_level.\n",
    "    flattened_X = X.flatten()\n",
    "    flattened_Z = Z.flatten()\n",
    "    flattened_Y = torch.full_like(flattened_X, y_level)\n",
    "    \n",
    "    # Prepare inputs for the model: note the order [x, y, z]\n",
    "    inputs = torch.stack([flattened_X, flattened_Y, flattened_Z], dim=1)\n",
    "    z_inputs = torch.full((inputs.shape[0], 1), z_div.item())\n",
    "\n",
    "    output = model(inputs, z_inputs)\n",
    "    output_grid = output.view(steps, steps).detach().cpu().numpy()\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    # norm = mcolors.TwoSlopeNorm(vmin=-model.upper_bound, vcenter=0, vmax=model.upper_bound)\n",
    "    norm = mcolors.TwoSlopeNorm(vmin=-1e-10, vcenter=0, vmax=1e-10)\n",
    "    c = ax.pcolormesh(X.numpy(), Z.numpy(), output_grid, shading='auto', cmap='bwr', norm=norm)\n",
    "    plt.colorbar(c, ax=ax, label='Model Output')\n",
    "    ax.set_xlabel('X-axis')\n",
    "    ax.set_ylabel('Z-axis')\n",
    "    ax.set_title('2D ZX Cross Section of Model Outputs')\n",
    "\n",
    "    # Plot individual points if provided (using x and z coordinates)\n",
    "    if points:\n",
    "        for point in points:\n",
    "            print(\"Point V\", point, model(torch.tensor([point]), z_div.unsqueeze(0)).cpu().tolist())\n",
    "        # Unpack points (assumed to be (x, y, z) tuples) and plot using x and z.\n",
    "        points_x, points_y, points_z = zip(*points)\n",
    "        ax.scatter(points_x, points_z, color='green', s=50, label='Points')\n",
    "\n",
    "    # Plot arrows if provided (arrows should be given in ZX coordinates)\n",
    "    if arrows:\n",
    "        for arrow in arrows:\n",
    "            (x_start, z_start), (x_end, z_end), color = arrow\n",
    "            ax.arrow(x_start, z_start, x_end - x_start, z_end - z_start, \n",
    "                     head_width=0.2, head_length=0.3, fc=color, ec=color, linewidth=2, label='Arrow')\n",
    "\n",
    "    if points or arrows:\n",
    "        ax.legend()\n",
    "\n",
    "    plt.savefig(\"cylinder_safety_zx.png\")\n",
    "    plt.show()\n",
    "\n",
    "print(point.positions)\n",
    "\n",
    "arrow_start = (point.positions[0], point.positions[2])\n",
    "arrow_end = (point.positions[0] + trajectory_us[t][0], point.positions[2] + trajectory_us[t][2])\n",
    "arrow_u = (arrow_start, arrow_end, 'black')\n",
    "\n",
    "arrow_start = (point.positions[0], point.positions[2])\n",
    "arrow_end = (point.positions[0] + trajectory_urefs[t][0], point.positions[2] + trajectory_urefs[t][2])\n",
    "arrow_uref = (arrow_start, arrow_end, 'green')\n",
    "\n",
    "# Example usage\n",
    "# model.upper_bound = 15\n",
    "width = 2\n",
    "t = int(slider.value)\n",
    "\n",
    "# positions = [-20, 40, 0.6]\n",
    "positions = point.positions\n",
    "\n",
    "plot_2d_grid_zx_section(\n",
    "    x_range=(new_interactive_point.point[0] - width, new_interactive_point.point[0] + width),\n",
    "    z_range=(new_interactive_point.point[2] - width, new_interactive_point.point[2] + width),\n",
    "    steps=200,\n",
    "    z_div = z_div,\n",
    "    model=model,\n",
    "    y_level=new_interactive_point.point[1],\n",
    "    points=[new_interactive_point.point, positions],\n",
    "    arrows=[arrow_u, arrow_uref]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as mcolors\n",
    "# import torch\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# def plot_2d_grid_with_model(x_range, y_range, steps, model, points=None, z_level=0, z_div=None, arrows=None):\n",
    "#     # Generate x and y linspace\n",
    "#     x_values = torch.linspace(*x_range, steps)\n",
    "#     y_values = torch.linspace(*y_range, steps)\n",
    "#     X, Y = torch.meshgrid(x_values, y_values, indexing=\"ij\")\n",
    "    \n",
    "#     # Flatten the grid for model input\n",
    "#     flattened_X = X.flatten()\n",
    "#     flattened_Y = Y.flatten()\n",
    "#     flattened_Z = torch.full_like(flattened_X, z_level)\n",
    "    \n",
    "#     # Prepare inputs for the model\n",
    "#     xy_inputs = torch.stack([flattened_X, flattened_Y, flattened_Z], dim=1)\n",
    "#     z_inputs = torch.full((xy_inputs.shape[0], 1), z_div.item())\n",
    "\n",
    "#     output = model(xy_inputs, z_inputs)\n",
    "#     # output = torch.clamp(output, max=model.upper_bound, min=-model.upper_bound)\n",
    "#     Z = output.view(steps, steps).detach().numpy()\n",
    "\n",
    "#     # Plotting\n",
    "#     fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#     norm = mcolors.TwoSlopeNorm(vmin=min(-model.upper_bound, -0.5), vcenter=0, vmax=1)\n",
    "#     c = ax.pcolormesh(X.numpy(), Y.numpy(), Z, shading='auto', cmap='bwr', norm=norm)\n",
    "#     plt.colorbar(c, ax=ax, label='Model Output')\n",
    "#     ax.set_xlabel('X-axis')\n",
    "#     ax.set_ylabel('Y-axis')\n",
    "#     ax.set_title('2D Grid of Model Outputs')\n",
    "\n",
    "#     # Plot individual points if provided\n",
    "#     if points:\n",
    "#         for point in points:\n",
    "#             print(\"Point V\", point, model(torch.tensor([point]), z_div.unsqueeze(0), calc_jacobian=False).cpu().tolist())\n",
    "#         points_x, points_y, points_z = zip(*points)  # Unpack the points into x and y coordinates\n",
    "#         ax.scatter(points_x, points_y, color='green', s=50, label='Points')\n",
    "\n",
    "#     # Plot the arrow if provided\n",
    "#     if arrows:\n",
    "#         for arrow in arrows:\n",
    "#             (x_start, y_start), (x_end, y_end), color = arrow\n",
    "#             ax.arrow(x_start, y_start, x_end - x_start, y_end - y_start, \n",
    "#                     head_width=0.2, head_length=0.3, fc=color, ec=color, linewidth=2, label='Arrow')\n",
    "\n",
    "#     # Add legend if points or arrow are plotted\n",
    "#     if points or arrows:\n",
    "#         ax.legend()\n",
    "\n",
    "#     plt.savefig(\"cylinder_safety.png\")\n",
    "#     plt.show()\n",
    "\n",
    "# # Example usage\n",
    "# # model.upper_bound = 15\n",
    "# width = 4\n",
    "# center = [-18, 39]\n",
    "# plot_2d_grid_with_model(\n",
    "#     x_range=(center[0] - width, center[0] + width),\n",
    "#     y_range=(center[1] - width, center[1] + width),\n",
    "#     steps=200,\n",
    "#     z_div = z_div,\n",
    "#     model=model,\n",
    "#     z_level=0.6,\n",
    "#     points = [[-15.867135,38.902016,0.5692017]]\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_ginn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
