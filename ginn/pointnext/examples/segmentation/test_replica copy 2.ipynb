{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import yaml\n",
    "import argparse\n",
    "import logging\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import struct\n",
    "import warnings\n",
    "from random import randint\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import ConvexHull, Delaunay, cKDTree, KDTree\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import open3d as o3d\n",
    "import trimesh\n",
    "import k3d\n",
    "import wandb\n",
    "\n",
    "from plyfile import PlyData\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from plyfile import PlyData\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import k3d\n",
    "import trimesh\n",
    "import random\n",
    "\n",
    "# === Paths ===\n",
    "data_root = \"/scratch/rhm4nj/cral/datasets/Replica-Dataset/ReplicaSDK\"\n",
    "room_name = \"office_4\"\n",
    "room_path = Path(data_root) / room_name\n",
    "rm_floor = False\n",
    "\n",
    "def rgb_to_uint(rgb):\n",
    "    r, g, b = rgb\n",
    "    return (int(r) << 16) + (int(g) << 8) + int(b)\n",
    "\n",
    "def calculate_bounds(points):\n",
    "    x_min, x_max = np.min(points[:, 0]), np.max(points[:, 0])\n",
    "    y_min, y_max = np.min(points[:, 1]), np.max(points[:, 1])\n",
    "    z_min, z_max = np.min(points[:, 2]), np.max(points[:, 2])\n",
    "    return np.array([[x_min, x_max], [y_min, y_max], [z_min, z_max]]), (np.array([x_min, y_min, z_min]), np.array([x_max, y_max, z_max]))\n",
    "\n",
    "def get_upper_xy_plane_points(point_cloud, bbox_min, bbox_max, z_tol=1e-3):\n",
    "    z_max = bbox_max[2]\n",
    "    return np.abs(point_cloud[:, 2] - z_max) < z_tol\n",
    "\n",
    "def get_lower_xy_plane_points(point_cloud, bbox_min, bbox_max, z_tol=1e-3):\n",
    "    z_min = bbox_min[2]\n",
    "    return np.abs(point_cloud[:, 2] - z_min) < z_tol\n",
    "\n",
    "def downsample_random_indices(points, K):\n",
    "    indices = np.random.choice(points.shape[0], K, replace=False)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load semantic metadata ===\n",
    "ply_path = room_path / \"habitat\" / \"mesh_semantic.ply\"\n",
    "info_path = room_path / \"habitat\" / \"info_semantic.json\"\n",
    "\n",
    "with open(info_path, \"r\") as f:\n",
    "    info = json.load(f)\n",
    "\n",
    "class_mapping = {}\n",
    "for ele in info[\"classes\"]:\n",
    "    class_mapping[ele[\"id\"]] = ele[\"name\"]\n",
    "for ele in info[\"objects\"]:\n",
    "    class_mapping[ele[\"id\"]] = ele[\"class_name\"]\n",
    "\n",
    "# === Load mesh ===\n",
    "plydata = PlyData.read(str(ply_path))\n",
    "vertex_array = np.stack([\n",
    "    plydata['vertex']['x'],\n",
    "    plydata['vertex']['y'],\n",
    "    plydata['vertex']['z']\n",
    "], axis=-1)\n",
    "\n",
    "face_data = plydata['face'].data\n",
    "face_indices = [f[0] for f in face_data]\n",
    "object_ids = np.array([f[1] for f in face_data], dtype=np.uint16)\n",
    "\n",
    "# Assign vertex labels\n",
    "vertex_object_ids = np.zeros(vertex_array.shape[0], dtype=np.uint16)\n",
    "used = np.zeros(vertex_array.shape[0], dtype=bool)\n",
    "for face, oid in zip(face_indices, object_ids):\n",
    "    for v in face:\n",
    "        if not used[v]:\n",
    "            vertex_object_ids[v] = oid\n",
    "            used[v] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding 251742 vertices\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac28d165c48b40af9050baea8a44be26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "room_points = vertex_array  # treat entire mesh as room\n",
    "\n",
    "_, (bbox_min, bbox_max) = calculate_bounds(room_points)\n",
    "\n",
    "# Identify ceiling and floor\n",
    "ceiling_mask = get_upper_xy_plane_points(room_points, bbox_min, bbox_max, z_tol=0.45)\n",
    "exclude_mask = ceiling_mask\n",
    "\n",
    "if rm_floor:\n",
    "    floor_mask = get_lower_xy_plane_points(room_points, bbox_min, bbox_max, z_tol=1e-1)\n",
    "    exclude_mask = ceiling_mask | floor_mask\n",
    "\n",
    "# Exclude those points by index\n",
    "excluded_indices = np.where(exclude_mask)[0]\n",
    "excluded_index_set = set(excluded_indices.tolist())\n",
    "\n",
    "print(f\"Excluding {len(excluded_index_set)} vertices\")\n",
    "excluded_points = room_points[exclude_mask]\n",
    "\n",
    "# Create a plot\n",
    "plot = k3d.plot()\n",
    "plot += k3d.points(\n",
    "    positions=room_points[~exclude_mask],\n",
    "    point_size=0.01,\n",
    "    color=0xff0000,  # red for excluded\n",
    "    name=\"all points\"\n",
    ")\n",
    "plot += k3d.points(\n",
    "    positions=room_points[ceiling_mask].astype(np.float32),\n",
    "    point_size=0.01,\n",
    "    color=0x0000ff,  # blue = ceiling\n",
    "    name=\"ceiling\"\n",
    ")\n",
    "\n",
    "if rm_floor:\n",
    "    plot += k3d.points(\n",
    "        positions=room_points[floor_mask].astype(np.float32),\n",
    "        point_size=0.01,\n",
    "        color=0x00ff00,  # green = floor\n",
    "        name=\"floor\"\n",
    "    )\n",
    "\n",
    "plot.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting object fragments: 100%|██████████| 94/94 [00:06<00:00, 13.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "MIN_POINTS = 40  # filter threshold\n",
    "all_fragments = []\n",
    "\n",
    "oid_to_faces = defaultdict(list)\n",
    "for face, oid in zip(face_indices, object_ids):\n",
    "    oid_to_faces[oid].append(face)\n",
    "\n",
    "for oid, faces in tqdm(oid_to_faces.items(), desc=\"Extracting object fragments\"):\n",
    "    valid_faces = []\n",
    "    for face in faces:\n",
    "        if all(v in excluded_index_set for v in face):\n",
    "            continue  # skip face on ceiling or floor\n",
    "        valid_faces.append(face)\n",
    "\n",
    "    if not valid_faces:\n",
    "        continue\n",
    "\n",
    "    faces = np.array(valid_faces)\n",
    "\n",
    "    unique_vertex_indices, inverse_indices = np.unique(faces.flatten(), return_inverse=True)\n",
    "    local_vertices = vertex_array[unique_vertex_indices]\n",
    "    local_faces = inverse_indices.reshape(faces.shape)\n",
    "\n",
    "    db = DBSCAN(eps=0.05, min_samples=5).fit(local_vertices)\n",
    "    labels = db.labels_\n",
    "\n",
    "    num_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    class_name = class_mapping.get(oid, f\"unknown_{oid}\")\n",
    "\n",
    "    for cluster_id in range(num_clusters):\n",
    "        mask = (labels == cluster_id)\n",
    "        num_pts = mask.sum()\n",
    "\n",
    "        if num_pts < MIN_POINTS:\n",
    "            continue\n",
    "\n",
    "        cluster_points = local_vertices[mask]\n",
    "        all_fragments.append({\n",
    "            \"points\": cluster_points,\n",
    "            \"centroid\": cluster_points.mean(axis=0),\n",
    "            \"oid\": oid,\n",
    "            \"class_name\": class_name,\n",
    "            \"num_points\": num_pts\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 smallest fragments (after filtering):\n",
      "- Class: wall-plug, Points: 54\n",
      "- Class: wall-plug, Points: 54\n",
      "- Class: wall-plug, Points: 54\n",
      "- Class: wall-plug, Points: 70\n",
      "- Class: wall-plug, Points: 77\n",
      "- Class: unknown_0, Points: 85\n",
      "- Class: lamp, Points: 95\n",
      "- Class: undefined, Points: 101\n",
      "- Class: lamp, Points: 111\n",
      "- Class: undefined, Points: 121\n"
     ]
    }
   ],
   "source": [
    "# === Print 5 smallest fragments ===\n",
    "sorted_frags = sorted(all_fragments, key=lambda f: f[\"num_points\"])\n",
    "print(\"5 smallest fragments (after filtering):\")\n",
    "for frag in sorted_frags[:10]:\n",
    "    print(f\"- Class: {frag['class_name']}, Points: {frag['num_points']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building contact graph (fast)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:23<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 superclusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import KDTree, cKDTree\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Precompute bounding boxes\n",
    "bbox_centers = []\n",
    "bbox_extents = []\n",
    "for frag in all_fragments:\n",
    "    pts = frag[\"points\"]\n",
    "    bounds = np.stack([pts.min(axis=0), pts.max(axis=0)])\n",
    "    center = bounds.mean(axis=0)\n",
    "    extent = bounds[1] - bounds[0]\n",
    "    bbox_centers.append(center)\n",
    "    bbox_extents.append(extent)\n",
    "\n",
    "bbox_centers = np.stack(bbox_centers)\n",
    "bbox_extents = np.stack(bbox_extents)\n",
    "\n",
    "# Build KDTree over bounding box centers\n",
    "tree = KDTree(bbox_centers)\n",
    "touch_threshold = 0.02\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(len(all_fragments)))\n",
    "\n",
    "print(\"Building contact graph (fast)...\")\n",
    "\n",
    "for i in tqdm(range(len(all_fragments))):\n",
    "    # Search neighbors within radius (center distance + extent fudge factor)\n",
    "    extent_radius = np.linalg.norm(bbox_extents[i]) / 2 + 1.0  # generous margin\n",
    "    neighbors = tree.query_ball_point(bbox_centers[i], r=extent_radius)\n",
    "\n",
    "    pi = all_fragments[i][\"points\"]\n",
    "    pi_tree = cKDTree(pi)\n",
    "\n",
    "    for j in neighbors:\n",
    "        if j <= i:\n",
    "            continue\n",
    "\n",
    "        pj = all_fragments[j][\"points\"]\n",
    "        dists, _ = pi_tree.query(pj, k=1)\n",
    "        if np.any(dists < touch_threshold):\n",
    "            G.add_edge(i, j)\n",
    "            # print(\"Connecting edges\", all_fragments[i]['class_name'], all_fragments[j]['class_name'], dists[dists < touch_threshold].min())\n",
    "\n",
    "components = list(nx.connected_components(G))\n",
    "super_clusters = []\n",
    "\n",
    "for i, component in enumerate(components):\n",
    "    component = list(component)\n",
    "    fragment_names = [f\"{all_fragments[idx]['class_name']}_frag{idx}\" for idx in component]\n",
    "    fragment_sizes = [all_fragments[idx]['points'].shape[0] for idx in component]\n",
    "\n",
    "    # Find largest fragment\n",
    "    largest_idx = component[np.argmax(fragment_sizes)]\n",
    "    key_name = f\"{all_fragments[largest_idx]['class_name']}\"\n",
    "\n",
    "    # Concatenate all points in the component\n",
    "    merged_points = np.vstack([all_fragments[idx][\"points\"] for idx in component])\n",
    "    super_clusters.append((key_name, merged_points))\n",
    "\n",
    "room_points = vertex_array  # assuming this is the full mesh still\n",
    "super_clusters.append((\"ceiling\", room_points[ceiling_mask]))\n",
    "if rm_floor:\n",
    "    super_clusters.append((\"floor\", room_points[floor_mask]))\n",
    "\n",
    "print(f\"Found {len(super_clusters)} superclusters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = k3d.plot()\n",
    "color_map = {key: random.randint(0, 0xFFFFFF) for key in range(len(super_clusters))}\n",
    "\n",
    "for i, (key, component) in enumerate(super_clusters):\n",
    "    plot += k3d.points(\n",
    "        positions=component.astype(np.float32),\n",
    "        point_size=0.01,\n",
    "        color=color_map[i],\n",
    "        name=key\n",
    "    )\n",
    "\n",
    "plot.display()\n",
    "\n",
    "print([(key, component.shape) for key, component in super_clusters])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_nearest_neighbor_distance(points):\n",
    "    tree = cKDTree(points)\n",
    "    distances, _ = tree.query(points, k=2)\n",
    "    nn_distances = distances[:, 1]\n",
    "    return np.mean(nn_distances), np.std(nn_distances)\n",
    "\n",
    "def remove_outliers(point_cloud, method=\"statistical\", nb_neighbors=25, std_ratio=1.5, radius=0.1, min_neighbors=5, ret_indices=False):\n",
    "    # Convert to Open3D point cloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(point_cloud)\n",
    "\n",
    "    if method == \"statistical\":\n",
    "        # Statistical Outlier Removal (SOR)\n",
    "        clean_pcd, inlier_indices = pcd.remove_statistical_outlier(nb_neighbors=nb_neighbors, std_ratio=std_ratio)\n",
    "    elif method == \"radius\":\n",
    "        # Radius Outlier Removal (ROR)\n",
    "        clean_pcd, inlier_indices = pcd.remove_radius_outlier(nb_points=min_neighbors, radius=radius)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Use 'statistical' or 'radius'.\")\n",
    "\n",
    "    if ret_indices:\n",
    "        return np.asarray(clean_pcd.points), np.asarray(inlier_indices)\n",
    "\n",
    "    return np.asarray(clean_pcd.points)\n",
    "\n",
    "def filtered_point_cloud_indices(A, B, min_distance=0.1, tree=None, ret_dist=False):\n",
    "    if tree is None:\n",
    "        tree = cKDTree(A)\n",
    "    distances, _ = tree.query(B)\n",
    "    if ret_dist:\n",
    "        return distances > min_distance, distances[distances > min_distance]\n",
    "    \n",
    "    return distances > min_distance\n",
    "\n",
    "def sample_states_and_controls_timed(inner_point_cloud, point_cloud, N, K, min_dot=0.25):\n",
    "    def sample_vector():\n",
    "        vec = np.random.randn(3)\n",
    "        return vec / np.linalg.norm(vec)\n",
    "\n",
    "    idx = np.random.choice(point_cloud.shape[0], N, replace=False)\n",
    "    sampled_points = point_cloud[idx]\n",
    "    kdtree = cKDTree(inner_point_cloud)\n",
    "    distances, nearest_indices = kdtree.query(sampled_points, k=2)\n",
    "    nearest_neighbors = inner_point_cloud[nearest_indices[:, 1]]\n",
    "    sampled_data = []\n",
    "\n",
    "    for i in range(N):\n",
    "        x, y, z = sampled_points[i]\n",
    "        uc = nearest_neighbors[i] - sampled_points[i]\n",
    "        uc = uc / np.linalg.norm(uc)\n",
    "        sampled_data.append([x, y, z, uc[0], uc[1], uc[2]])\n",
    "        for _ in range(K - 1):\n",
    "            random_vector = sample_vector()\n",
    "            while np.dot(random_vector, uc) < min_dot:\n",
    "                random_vector = -random_vector\n",
    "                if np.dot(random_vector, uc) < min_dot:\n",
    "                    random_vector = sample_vector()\n",
    "            sampled_data.append([x, y, z, random_vector[0], random_vector[1], random_vector[2]])\n",
    "\n",
    "    return np.array(sampled_data)\n",
    "\n",
    "def compute_interface_normals(interface_filtered, normal_radius, max_nn):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(interface_filtered)\n",
    "    pcd.estimate_normals(\n",
    "        search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=normal_radius, max_nn=max_nn)\n",
    "    )\n",
    "    pcd.normalize_normals()\n",
    "    normals = np.asarray(pcd.normals)\n",
    "    print(\"Interface / Normals\", interface_filtered.shape, normals.shape)\n",
    "    return normals\n",
    "\n",
    "def compute_pts_on_env(domain_filtered, all_outers_filtered, interface_density, pts_on_env_thickness):\n",
    "    ao_env = all_outers_filtered[\n",
    "        filtered_point_cloud_indices(domain_filtered, all_outers_filtered, interface_density)\n",
    "    ]\n",
    "    pts_on_env = ao_env[\n",
    "        ~filtered_point_cloud_indices(domain_filtered, ao_env, pts_on_env_thickness)\n",
    "    ]\n",
    "    print(\"Done with pts_on_env\", pts_on_env.shape)\n",
    "    return pts_on_env\n",
    "\n",
    "def compute_outer_points(domain_filtered, all_outers_filtered, outer_density):\n",
    "    outers = all_outers_filtered[\n",
    "        filtered_point_cloud_indices(domain_filtered, all_outers_filtered, outer_density)\n",
    "    ]\n",
    "    print(\"Done with outers/envelope\", outers.shape)\n",
    "    return outers\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def compute_oriented_bbox(points, margin=0.0):\n",
    "    center = points.mean(axis=0)\n",
    "    centered = points - center\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(centered)\n",
    "    rotation = pca.components_.T  # each column is an axis\n",
    "\n",
    "    rotated = centered @ rotation\n",
    "    min_corner = rotated.min(axis=0) - margin\n",
    "    max_corner = rotated.max(axis=0) + margin\n",
    "\n",
    "    # Get 8 corners in PCA space\n",
    "    corners_pca = np.array([\n",
    "        [min_corner[0], min_corner[1], min_corner[2]],\n",
    "        [max_corner[0], min_corner[1], min_corner[2]],\n",
    "        [max_corner[0], max_corner[1], min_corner[2]],\n",
    "        [min_corner[0], max_corner[1], min_corner[2]],\n",
    "        [min_corner[0], min_corner[1], max_corner[2]],\n",
    "        [max_corner[0], min_corner[1], max_corner[2]],\n",
    "        [max_corner[0], max_corner[1], max_corner[2]],\n",
    "        [min_corner[0], max_corner[1], max_corner[2]],\n",
    "    ])\n",
    "\n",
    "    # Transform corners back to world space\n",
    "    corners_world = (corners_pca @ rotation.T) + center\n",
    "    return corners_world\n",
    "\n",
    "def sample_inside_oriented_bbox(corners, num_points=1000):\n",
    "    origin = corners[0]\n",
    "    edge_x = corners[1] - corners[0]  # along x\n",
    "    edge_y = corners[3] - corners[0]  # along y\n",
    "    edge_z = corners[4] - corners[0]  # along z\n",
    "    u = np.random.uniform(0, 1, (num_points, 1))\n",
    "    v = np.random.uniform(0, 1, (num_points, 1))\n",
    "    w = np.random.uniform(0, 1, (num_points, 1))\n",
    "    samples = origin + u * edge_x + v * edge_y + w * edge_z\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "floor (929159, 3)\n",
      "Done with inner layer (372731, 3)\n",
      "Done with all points (906181, 3)\n",
      "Done with interface (47243, 3)\n",
      "Interface / Normals (47243, 3) (47243, 3)\n",
      "Done with pts_on_env (43855, 3) (43855,)\n",
      "Done with outers/envelope (740583, 3) (740583,)\n",
      "Done with control (29970, 3)\n",
      "Done with bounds, scaling, translation: (array([-5.37709478, -6.18531035, -1.49541925]), array([3.80649449, 3.53755585, 1.70945948])) 4.861433096259059 [-0.78530014 -1.32387725  0.10702012]\n",
      "undefined (59, 3)\n",
      "Done with inner layer (268, 3)\n",
      "Done with all points (570, 3)\n",
      "Done with interface (33, 3)\n",
      "Interface / Normals (33, 3) (33, 3)\n",
      "Done with pts_on_env (111, 3) (111,)\n",
      "Done with outers/envelope (338, 3) (338,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 164\u001b[0m\n\u001b[1;32m    162\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m    163\u001b[0m control_outs_env \u001b[38;5;241m=\u001b[39m sample_states_and_controls_timed(domain_filtered, envelope_filtered, N \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m, K)\n\u001b[0;32m--> 164\u001b[0m control_outs_on_env \u001b[38;5;241m=\u001b[39m \u001b[43msample_states_and_controls_timed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdomain_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpts_on_env_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m control_outs_interface \u001b[38;5;241m=\u001b[39m sample_states_and_controls_timed(domain_filtered, interface_filtered, N \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m, K)\n\u001b[1;32m    166\u001b[0m control_outs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([control_outs_env, control_outs_interface, control_outs_on_env])\n",
      "Cell \u001b[0;32mIn[13], line 40\u001b[0m, in \u001b[0;36msample_states_and_controls_timed\u001b[0;34m(inner_point_cloud, point_cloud, N, K, min_dot)\u001b[0m\n\u001b[1;32m     37\u001b[0m     vec \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vec \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(vec)\n\u001b[0;32m---> 40\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint_cloud\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m sampled_points \u001b[38;5;241m=\u001b[39m point_cloud[idx]\n\u001b[1;32m     42\u001b[0m kdtree \u001b[38;5;241m=\u001b[39m cKDTree(inner_point_cloud)\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:1020\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "augemented_points = []\n",
    "class_pts = super_clusters\n",
    "\n",
    "def thicken_point_cloud_outward(points, num_augmented=3, noise_scale=0.01):\n",
    "    N, _ = points.shape\n",
    "    centroid = points.mean(axis=0)\n",
    "    expanded_points = [points]  # include original\n",
    "    for _ in range(num_augmented):\n",
    "        # Direction from centroid to each point\n",
    "        directions = points - centroid\n",
    "        directions = directions / (np.linalg.norm(directions, axis=1, keepdims=True) + 1e-6)\n",
    "\n",
    "        # Apply directional noise\n",
    "        noise = directions * (np.random.rand(N, 1) * noise_scale)\n",
    "        new_points = points + noise\n",
    "        expanded_points.append(new_points)\n",
    "\n",
    "    return np.vstack(expanded_points)\n",
    "\n",
    "\n",
    "for cname, points in class_pts:\n",
    "    print(cname, points.shape)\n",
    "    # if cname != 'wall': continue\n",
    "    indices = downsample_random_indices(points, min(points.shape[0], 300_000))\n",
    "    points = np.ascontiguousarray(points, dtype=np.float64)\n",
    "    points = points[indices]\n",
    "\n",
    "    interface_thickness=0.05\n",
    "    pts_on_env_thickness = 0.05\n",
    "    pts_on_env_gap = 0.075\n",
    "    inner_thickness=0.025\n",
    "    normal_radius=0.025\n",
    "    max_nn=30\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.estimate_normals(\n",
    "        search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=normal_radius, max_nn=max_nn)\n",
    "    )\n",
    "    pcd.normalize_normals()\n",
    "    normals = np.asarray(pcd.normals)\n",
    "\n",
    "    # outer_extras = []\n",
    "    # bounds, bounds_box = calculate_bounds(points)\n",
    "    # widths = bounds[:, 1] - bounds[:, 0]  # [x_width, y_width, z_width]\n",
    "    # outer_extras_thickness = np.max(widths)\n",
    "    # for step in np.linspace(1e-1, outer_extras_thickness, 30):\n",
    "    #     sampled_indices = \n",
    "    # \n",
    "    # \n",
    "    # \n",
    "    # (points, min(points.shape[0], 20_000))\n",
    "    #     points_tmp = points[sampled_indices]\n",
    "    #     normals_tmp = normals[sampled_indices]\n",
    "        \n",
    "    #     outer_extras.append(points_tmp + normals_tmp  * step)\n",
    "    #     outer_extras.append(points_tmp - normals_tmp  * step)\n",
    "    # envelope = np.vstack(outer_extras)\n",
    "\n",
    "    inners = []\n",
    "    for step in np.linspace(1e-3, inner_thickness, 5):\n",
    "        inners.append(points + normals * step)\n",
    "        inners.append(points - normals * step)\n",
    "\n",
    "    domain = np.vstack(inners)  # And the opposite direction\n",
    "    inner_m, inner_std = average_nearest_neighbor_distance(domain)\n",
    "    inner_density = inner_m + inner_std * 3\n",
    "\n",
    "    # interface_thickness = inner_thickness + interface_thickness\n",
    "    # outers = []\n",
    "    # normals_interface = []\n",
    "    # for step in np.linspace(interface_thickness, interface_thickness + 0.25 + inner_density, 10):\n",
    "    #     outers.append(points + normals  * step)\n",
    "    #     outers.append(points - normals  * step)\n",
    "    # interface_inp = np.vstack(outers)\n",
    "    # normals_interface = np.vstack([normals] * len(outers))\n",
    "\n",
    "    # pts_on_env_thickness = interface_thickness + pts_on_env_thickness\n",
    "    # pts_on_envs = []\n",
    "    # for step in np.linspace(pts_on_env_thickness, pts_on_env_thickness + 0.4 + inner_density):\n",
    "    #     pts_on_envs.append(points + normals  * step)\n",
    "    #     pts_on_envs.append(points - normals  * step)\n",
    "    # pts_on_env = np.vstack(pts_on_envs)\n",
    "\n",
    "    min_neighbors = 8\n",
    "\n",
    "    # inner layer\n",
    "    domain_filtered = domain[downsample_random_indices(domain, min(points.shape[0] * 5, 400_000))]\n",
    "    domain_filtered = remove_outliers(domain_filtered, radius=inner_density, min_neighbors=min_neighbors)\n",
    "    inner_m, inner_std = average_nearest_neighbor_distance(domain_filtered)\n",
    "    inner_density = inner_m + inner_std * 3 + 0.05\n",
    "    print(\"Done with inner layer\", domain_filtered.shape)\n",
    "\n",
    "    # all points\n",
    "    bbox_offset = 0.25\n",
    "    n_all_outers = min(points.shape[0] * 10, 1_000_000)\n",
    "    _, bounds_box = calculate_bounds(domain_filtered)\n",
    "    expanded_bounds = bounds_box[0] - bbox_offset, bounds_box[1] + bbox_offset\n",
    "    all_outers = np.random.uniform(low=expanded_bounds[0], high=expanded_bounds[1], size=(n_all_outers, 3))\n",
    "\n",
    "    domain_tree = cKDTree(domain_filtered)\n",
    "    all_outers_filtered = all_outers[\n",
    "        filtered_point_cloud_indices(domain_filtered, all_outers, inner_density, tree=domain_tree)\n",
    "    ]\n",
    "    print(\"Done with all points\", all_outers_filtered.shape)\n",
    "\n",
    "    # interface\n",
    "    interface_thickness = inner_density + interface_thickness\n",
    "    # interface_inp = thicken_point_cloud_outward(domain_filtered, 10, noise_scale=0.75)\n",
    "    # interface_inp = interface_inp[downsample_random_indices(interface_inp, min(interface_inp.shape[0] * 5, 400_000))]\n",
    "    interface_filtered = all_outers_filtered[\n",
    "        ~filtered_point_cloud_indices(domain_filtered, all_outers_filtered, interface_thickness)\n",
    "    ]\n",
    "    print(\"Done with interface\", interface_filtered.shape)\n",
    "\n",
    "    # Prepare variables for parallel work\n",
    "    interface_density = interface_thickness\n",
    "    pts_on_env_thickness = interface_density + pts_on_env_thickness\n",
    "    outer_density = pts_on_env_thickness + inner_density\n",
    "\n",
    "    # # Run them in parallel\n",
    "    # with ThreadPoolExecutor() as executor:\n",
    "    #     futures = [\n",
    "    #         executor.submit(compute_interface_normals, interface_filtered, normal_radius, max_nn),\n",
    "    #         executor.submit(compute_pts_on_env, domain_filtered, all_outers_filtered, interface_density, pts_on_env_thickness),\n",
    "    #         executor.submit(compute_outer_points, domain_filtered, all_outers_filtered, outer_density)\n",
    "    #     ]\n",
    "    # normals_filtered = compute_interface_normals(interface_filtered, normal_radius, max_nn)\n",
    "    # pts_on_env_filtered = compute_pts_on_env(domain_filtered, all_outers_filtered, interface_density, pts_on_env_thickness)\n",
    "    # envelope_filtered = compute_outer_points(domain_filtered, all_outers_filtered, outer_density)\n",
    "\n",
    "    # Normals\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(interface_filtered)\n",
    "    pcd.estimate_normals(\n",
    "        search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=normal_radius, max_nn=max_nn)\n",
    "    )\n",
    "    pcd.normalize_normals()\n",
    "    normals_filtered = np.asarray(pcd.normals)\n",
    "    print(\"Interface / Normals\", interface_filtered.shape, normals_filtered.shape)\n",
    "\n",
    "    interface_tree = cKDTree(interface_filtered)\n",
    "    # pts_on_env\n",
    "    ao_env = all_outers_filtered[\n",
    "        filtered_point_cloud_indices(domain_filtered, all_outers_filtered, interface_density + pts_on_env_gap)\n",
    "    ]\n",
    "    pts_on_env_filtered = ao_env[\n",
    "        ~filtered_point_cloud_indices(domain_filtered, ao_env, pts_on_env_thickness + pts_on_env_gap)\n",
    "    ]\n",
    "    pts_on_env_filtered_dists, _ = interface_tree.query(pts_on_env_filtered)\n",
    "    print(\"Done with pts_on_env\", pts_on_env_filtered.shape, pts_on_env_filtered_dists.shape)\n",
    "\n",
    "    # envelope_filtered\n",
    "    envelope_filtered = all_outers_filtered[\n",
    "        filtered_point_cloud_indices(domain_filtered, all_outers_filtered, outer_density)\n",
    "    ]\n",
    "    envelope_filtered_dists, _ = interface_tree.query(envelope_filtered)\n",
    "    print(\"Done with outers/envelope\", envelope_filtered.shape, envelope_filtered_dists.shape)\n",
    "\n",
    "    # control\n",
    "    N = 1000\n",
    "    K = 30\n",
    "    control_outs_env = sample_states_and_controls_timed(domain_filtered, envelope_filtered, N // 3, K)\n",
    "    control_outs_on_env = sample_states_and_controls_timed(domain_filtered, pts_on_env_filtered, N // 3, K)\n",
    "    control_outs_interface = sample_states_and_controls_timed(domain_filtered, interface_filtered, N // 3, K)\n",
    "    control_outs = np.vstack([control_outs_env, control_outs_interface, control_outs_on_env])\n",
    "    control_points, controls = control_outs[:, :3], control_outs[:, 3:]\n",
    "    print(\"Done with control\", control_points.shape)\n",
    "\n",
    "    # bounds, scaling, translation\n",
    "    all_points = np.vstack([domain, interface_filtered, pts_on_env_filtered, envelope_filtered])\n",
    "    bounds_og, bounds_coords = calculate_bounds(all_points)\n",
    "    bbox_min, bbox_max = bounds_coords\n",
    "    bounds = bounds_og.copy()\n",
    "\n",
    "    all_points_obj = np.vstack([domain, interface_filtered])\n",
    "    bounds_obj, _ = calculate_bounds(all_points_obj)\n",
    "\n",
    "    center_for_translation = (bbox_max + bbox_min) / 2\n",
    "    scale_factor = max(bbox_max - bbox_min) / 2\n",
    "\n",
    "    print(\"Done with bounds, scaling, translation:\", bounds_coords, scale_factor, center_for_translation)\n",
    "\n",
    "    augemented_points.append({\n",
    "        \"class\": cname,\n",
    "        \"pts_inside\": domain_filtered,\n",
    "        \"env_outside_pts\": envelope_filtered,\n",
    "        \"pts_on_env\": pts_on_env_filtered,\n",
    "        \"pts_on_env_dists\": pts_on_env_filtered_dists,\n",
    "        \"env_outside_pts_dists\": envelope_filtered_dists,\n",
    "        \"outside_points_dists\": envelope_filtered_dists,\n",
    "        \"outside_points\": envelope_filtered,\n",
    "        \"control_points\": control_outs,\n",
    "        \"control_points_on_env\": control_outs_on_env,\n",
    "        \"control_points_env\": control_outs_env,\n",
    "        \"control_points_interface\": control_outs_interface,\n",
    "        \"original\": points,\n",
    "        \"interface_pts\": interface_filtered,\n",
    "        \"interface_normals\": normals_filtered,\n",
    "        \"bounds\": bounds,\n",
    "        \"bounds_obj\": bounds_obj,\n",
    "        \"scale_factor\": scale_factor,\n",
    "        \"center_for_translation\": center_for_translation\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de62a91a591f4f6f98cfbdc630e40075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plotting object 0: wall\n",
      "pts_inside bounds: min [-5.12783915 -5.94758605 -1.14830821], max [3.55740448 3.28797493 1.40793548]\n",
      "ADDED pts_inside (371518, 3)\n",
      "pts_on_env bounds: min [-5.37152505 -6.18475788 -1.39297572], max [3.7992476  3.53445482 1.6457066 ]\n",
      "ADDED pts_on_env (34091, 3)\n",
      "interface_pts bounds: min [-5.2475521  -6.05277293 -1.26552357], max [3.68101965 3.40999327 1.52239191]\n",
      "ADDED interface_pts (31902, 3)\n",
      "\n",
      "Plotting object 1: table\n",
      "\n",
      "Plotting object 2: table\n",
      "\n",
      "Plotting object 3: chair\n",
      "\n",
      "Plotting object 4: tv-stand\n",
      "\n",
      "Plotting object 5: chair\n",
      "\n",
      "Plotting object 6: chair\n",
      "\n",
      "Plotting object 7: chair\n",
      "\n",
      "Plotting object 8: ceiling\n",
      "\n",
      "Plotting object 9: floor\n"
     ]
    }
   ],
   "source": [
    "import k3d\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "plot = k3d.plot()\n",
    "\n",
    "colors = {\n",
    "    # \"original\": 0xff0000,             # Red\n",
    "    \"pts_inside\": 0x00ff00,           # Green\n",
    "    \"interface_pts\": 0x0000ff,        # Blue\n",
    "    # \"env_outside_pts\": 0xffff00,      # Yellow\n",
    "    \"pts_on_env\": 0xff00ff,           # Magenta\n",
    "    # \"outside_points\": 0x00ffff,       # Cyan\n",
    "    # \"control_points\": 0x808080,       # Gray\n",
    "    # \"control_points_on_env\": 0xFFA500,# Orange\n",
    "    # \"control_points_env\": 0x800080,   # Purple\n",
    "    # \"control_points_interface\": 0x008000 # Dark Green\n",
    "}\n",
    "\n",
    "# print(domain.shape, domain_normals.shape)\n",
    "# # plot += k3d.vectors(domain[:domain_normals.shape[0]], domain_normals, color=0x0000ff, head_size=0.1)  # Blue\n",
    "# print(interface_filtered.shape, normals_filtered.shape)\n",
    "# plot += k3d.vectors(interface_filtered, normals_filtered / 10, color=0xFFA500, head_size=0.25, line_width=0.001)  # Blue\n",
    "# plot += k3d.points(interface_tmp, point_size=0.01, color=0x808080)\n",
    "# plot += k3d.points(pts_on_env_tmp, point_size=0.01, color=0x008000)\n",
    "\n",
    "# plot += k3d.points(bounds_obj.T, point_size=0.05, color=0x008000)\n",
    "plot.display()\n",
    "for i, data_dict in enumerate(augemented_points):\n",
    "    print(f\"\\nPlotting object {i}: {data_dict.get('class', 'Unknown')}\")\n",
    "    if data_dict.get('class', 'Unknown') != 'wall':\n",
    "        continue\n",
    "    \n",
    "    for key, value in data_dict.items():\n",
    "        if not isinstance(value, np.ndarray):\n",
    "            continue\n",
    "        \n",
    "        if value.ndim == 2 and value.shape[1] >= 3:\n",
    "            pts = value[:, :3]\n",
    "            col = colors.get(key, -1)\n",
    "            if col != -1:\n",
    "                plot += k3d.points(pts, point_size=0.05, color=col)\n",
    "                print(f\"{key} bounds: min {pts.min(axis=0)}, max {pts.max(axis=0)}\")\n",
    "                print(\"ADDED\", key, pts.shape)\n",
    "\n",
    "# plot += k3d.points(interface_tmp_big, point_size=0.01, color=0x008000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39cf79cf71a44469e582440f4a93809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import k3d\n",
    "from k3d.colormaps import matplotlib_color_maps\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Concatenate points and distances\n",
    "env_pts_all = []\n",
    "env_dists_all = []\n",
    "int_all = []\n",
    "\n",
    "for data_dict in augemented_points:\n",
    "    if not isinstance(data_dict, dict):\n",
    "        continue\n",
    "    if data_dict.get('class', 'Unknown') != 'wall':\n",
    "        continue\n",
    "\n",
    "    env_pts = data_dict.get(\"env_outside_pts\")\n",
    "    env_dists = data_dict.get(\"env_outside_pts_dists\")\n",
    "    on_env_pts = data_dict.get(\"pts_on_env\")\n",
    "    on_env_dists = data_dict.get(\"pts_on_env_dists\")\n",
    "    interface = data_dict.get(\"interface_pts\")\n",
    "\n",
    "    if env_pts is not None and env_dists is not None and env_pts.shape[0] == env_dists.shape[0]:\n",
    "        env_pts_all.append(env_pts)\n",
    "        env_dists_all.append(env_dists)\n",
    "\n",
    "    if on_env_pts is not None and on_env_dists is not None and on_env_pts.shape[0] == on_env_dists.shape[0]:\n",
    "        env_pts_all.append(on_env_pts)\n",
    "        env_dists_all.append(on_env_dists)\n",
    "    \n",
    "    int_all.append(interface)\n",
    "\n",
    "# Step 2: Stack arrays\n",
    "if env_pts_all and env_dists_all:\n",
    "    all_pts = np.vstack(env_pts_all).astype(np.float32)\n",
    "    all_dists = np.concatenate(env_dists_all).astype(np.float32)\n",
    "    int_all = np.vstack(int_all).astype(np.float32)\n",
    "\n",
    "    # Step 3: Create a separate plot\n",
    "    env_plot = k3d.plot()\n",
    "    env_plot += k3d.points(\n",
    "        all_pts,\n",
    "        attribute=all_dists,\n",
    "        point_size=0.05,\n",
    "        color_map=matplotlib_color_maps.Inferno\n",
    "    )\n",
    "    env_plot += k3d.points(int_all, point_size=0.05, color=0x0000ff)\n",
    "    env_plot.display()\n",
    "else:\n",
    "    print(\"No envelope or on-env points found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: /scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen/replica/office_3_objects\n",
      "Saving to 0_wall: class\n",
      "Saving to 0_wall: pts_inside\n",
      "Saving to 0_wall: env_outside_pts\n",
      "Saving to 0_wall: pts_on_env\n",
      "Saving to 0_wall: pts_on_env_dists\n",
      "Saving to 0_wall: env_outside_pts_dists\n",
      "Saving to 0_wall: outside_points_dists\n",
      "Saving to 0_wall: outside_points\n",
      "Saving to 0_wall: control_points\n",
      "Saving to 0_wall: control_points_on_env\n",
      "Saving to 0_wall: control_points_env\n",
      "Saving to 0_wall: control_points_interface\n",
      "Saving to 0_wall: original\n",
      "Saving to 0_wall: interface_pts\n",
      "Saving to 0_wall: interface_normals\n",
      "Saving to 0_wall: bounds\n",
      "Saving to 0_wall: bounds_obj\n",
      "Saving to 0_wall: scale_factor\n",
      "Saving to 0_wall: center_for_translation\n",
      "Saving to 1_table: class\n",
      "Saving to 1_table: pts_inside\n",
      "Saving to 1_table: env_outside_pts\n",
      "Saving to 1_table: pts_on_env\n",
      "Saving to 1_table: pts_on_env_dists\n",
      "Saving to 1_table: env_outside_pts_dists\n",
      "Saving to 1_table: outside_points_dists\n",
      "Saving to 1_table: outside_points\n",
      "Saving to 1_table: control_points\n",
      "Saving to 1_table: control_points_on_env\n",
      "Saving to 1_table: control_points_env\n",
      "Saving to 1_table: control_points_interface\n",
      "Saving to 1_table: original\n",
      "Saving to 1_table: interface_pts\n",
      "Saving to 1_table: interface_normals\n",
      "Saving to 1_table: bounds\n",
      "Saving to 1_table: bounds_obj\n",
      "Saving to 1_table: scale_factor\n",
      "Saving to 1_table: center_for_translation\n",
      "Saving to 2_table: class\n",
      "Saving to 2_table: pts_inside\n",
      "Saving to 2_table: env_outside_pts\n",
      "Saving to 2_table: pts_on_env\n",
      "Saving to 2_table: pts_on_env_dists\n",
      "Saving to 2_table: env_outside_pts_dists\n",
      "Saving to 2_table: outside_points_dists\n",
      "Saving to 2_table: outside_points\n",
      "Saving to 2_table: control_points\n",
      "Saving to 2_table: control_points_on_env\n",
      "Saving to 2_table: control_points_env\n",
      "Saving to 2_table: control_points_interface\n",
      "Saving to 2_table: original\n",
      "Saving to 2_table: interface_pts\n",
      "Saving to 2_table: interface_normals\n",
      "Saving to 2_table: bounds\n",
      "Saving to 2_table: bounds_obj\n",
      "Saving to 2_table: scale_factor\n",
      "Saving to 2_table: center_for_translation\n",
      "Saving to 3_chair: class\n",
      "Saving to 3_chair: pts_inside\n",
      "Saving to 3_chair: env_outside_pts\n",
      "Saving to 3_chair: pts_on_env\n",
      "Saving to 3_chair: pts_on_env_dists\n",
      "Saving to 3_chair: env_outside_pts_dists\n",
      "Saving to 3_chair: outside_points_dists\n",
      "Saving to 3_chair: outside_points\n",
      "Saving to 3_chair: control_points\n",
      "Saving to 3_chair: control_points_on_env\n",
      "Saving to 3_chair: control_points_env\n",
      "Saving to 3_chair: control_points_interface\n",
      "Saving to 3_chair: original\n",
      "Saving to 3_chair: interface_pts\n",
      "Saving to 3_chair: interface_normals\n",
      "Saving to 3_chair: bounds\n",
      "Saving to 3_chair: bounds_obj\n",
      "Saving to 3_chair: scale_factor\n",
      "Saving to 3_chair: center_for_translation\n",
      "Saving to 4_tv-stand: class\n",
      "Saving to 4_tv-stand: pts_inside\n",
      "Saving to 4_tv-stand: env_outside_pts\n",
      "Saving to 4_tv-stand: pts_on_env\n",
      "Saving to 4_tv-stand: pts_on_env_dists\n",
      "Saving to 4_tv-stand: env_outside_pts_dists\n",
      "Saving to 4_tv-stand: outside_points_dists\n",
      "Saving to 4_tv-stand: outside_points\n",
      "Saving to 4_tv-stand: control_points\n",
      "Saving to 4_tv-stand: control_points_on_env\n",
      "Saving to 4_tv-stand: control_points_env\n",
      "Saving to 4_tv-stand: control_points_interface\n",
      "Saving to 4_tv-stand: original\n",
      "Saving to 4_tv-stand: interface_pts\n",
      "Saving to 4_tv-stand: interface_normals\n",
      "Saving to 4_tv-stand: bounds\n",
      "Saving to 4_tv-stand: bounds_obj\n",
      "Saving to 4_tv-stand: scale_factor\n",
      "Saving to 4_tv-stand: center_for_translation\n",
      "Saving to 5_chair: class\n",
      "Saving to 5_chair: pts_inside\n",
      "Saving to 5_chair: env_outside_pts\n",
      "Saving to 5_chair: pts_on_env\n",
      "Saving to 5_chair: pts_on_env_dists\n",
      "Saving to 5_chair: env_outside_pts_dists\n",
      "Saving to 5_chair: outside_points_dists\n",
      "Saving to 5_chair: outside_points\n",
      "Saving to 5_chair: control_points\n",
      "Saving to 5_chair: control_points_on_env\n",
      "Saving to 5_chair: control_points_env\n",
      "Saving to 5_chair: control_points_interface\n",
      "Saving to 5_chair: original\n",
      "Saving to 5_chair: interface_pts\n",
      "Saving to 5_chair: interface_normals\n",
      "Saving to 5_chair: bounds\n",
      "Saving to 5_chair: bounds_obj\n",
      "Saving to 5_chair: scale_factor\n",
      "Saving to 5_chair: center_for_translation\n",
      "Saving to 6_chair: class\n",
      "Saving to 6_chair: pts_inside\n",
      "Saving to 6_chair: env_outside_pts\n",
      "Saving to 6_chair: pts_on_env\n",
      "Saving to 6_chair: pts_on_env_dists\n",
      "Saving to 6_chair: env_outside_pts_dists\n",
      "Saving to 6_chair: outside_points_dists\n",
      "Saving to 6_chair: outside_points\n",
      "Saving to 6_chair: control_points\n",
      "Saving to 6_chair: control_points_on_env\n",
      "Saving to 6_chair: control_points_env\n",
      "Saving to 6_chair: control_points_interface\n",
      "Saving to 6_chair: original\n",
      "Saving to 6_chair: interface_pts\n",
      "Saving to 6_chair: interface_normals\n",
      "Saving to 6_chair: bounds\n",
      "Saving to 6_chair: bounds_obj\n",
      "Saving to 6_chair: scale_factor\n",
      "Saving to 6_chair: center_for_translation\n",
      "Saving to 7_chair: class\n",
      "Saving to 7_chair: pts_inside\n",
      "Saving to 7_chair: env_outside_pts\n",
      "Saving to 7_chair: pts_on_env\n",
      "Saving to 7_chair: pts_on_env_dists\n",
      "Saving to 7_chair: env_outside_pts_dists\n",
      "Saving to 7_chair: outside_points_dists\n",
      "Saving to 7_chair: outside_points\n",
      "Saving to 7_chair: control_points\n",
      "Saving to 7_chair: control_points_on_env\n",
      "Saving to 7_chair: control_points_env\n",
      "Saving to 7_chair: control_points_interface\n",
      "Saving to 7_chair: original\n",
      "Saving to 7_chair: interface_pts\n",
      "Saving to 7_chair: interface_normals\n",
      "Saving to 7_chair: bounds\n",
      "Saving to 7_chair: bounds_obj\n",
      "Saving to 7_chair: scale_factor\n",
      "Saving to 7_chair: center_for_translation\n",
      "Saving to 8_ceiling: class\n",
      "Saving to 8_ceiling: pts_inside\n",
      "Saving to 8_ceiling: env_outside_pts\n",
      "Saving to 8_ceiling: pts_on_env\n",
      "Saving to 8_ceiling: pts_on_env_dists\n",
      "Saving to 8_ceiling: env_outside_pts_dists\n",
      "Saving to 8_ceiling: outside_points_dists\n",
      "Saving to 8_ceiling: outside_points\n",
      "Saving to 8_ceiling: control_points\n",
      "Saving to 8_ceiling: control_points_on_env\n",
      "Saving to 8_ceiling: control_points_env\n",
      "Saving to 8_ceiling: control_points_interface\n",
      "Saving to 8_ceiling: original\n",
      "Saving to 8_ceiling: interface_pts\n",
      "Saving to 8_ceiling: interface_normals\n",
      "Saving to 8_ceiling: bounds\n",
      "Saving to 8_ceiling: bounds_obj\n",
      "Saving to 8_ceiling: scale_factor\n",
      "Saving to 8_ceiling: center_for_translation\n",
      "Saving to 9_floor: class\n",
      "Saving to 9_floor: pts_inside\n",
      "Saving to 9_floor: env_outside_pts\n",
      "Saving to 9_floor: pts_on_env\n",
      "Saving to 9_floor: pts_on_env_dists\n",
      "Saving to 9_floor: env_outside_pts_dists\n",
      "Saving to 9_floor: outside_points_dists\n",
      "Saving to 9_floor: outside_points\n",
      "Saving to 9_floor: control_points\n",
      "Saving to 9_floor: control_points_on_env\n",
      "Saving to 9_floor: control_points_env\n",
      "Saving to 9_floor: control_points_interface\n",
      "Saving to 9_floor: original\n",
      "Saving to 9_floor: interface_pts\n",
      "Saving to 9_floor: interface_normals\n",
      "Saving to 9_floor: bounds\n",
      "Saving to 9_floor: bounds_obj\n",
      "Saving to 9_floor: scale_factor\n",
      "Saving to 9_floor: center_for_translation\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "name = room_name + \"_objects\"\n",
    "out_path = os.path.join(\n",
    "    \"/scratch/rhm4nj/cral/cral-ginn/ginn/myvis/data_gen\", \n",
    "    \"replica\",\n",
    "    name\n",
    ")\n",
    "print(\"Saving to:\", out_path)\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "else:\n",
    "    shutil.rmtree(out_path)\n",
    "\n",
    "skips_names = []\n",
    "\n",
    "for idx, values in enumerate(augemented_points):\n",
    "    folder_name = f\"{idx}_{values['class']}\"\n",
    "    folder_path = os.path.join(out_path, folder_name)\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "    for name, arrays in values.items():\n",
    "        if name in skips_names: continue\n",
    "\n",
    "        print(f'Saving to {folder_name}:', name)\n",
    "        np.save(f'{folder_path}/{name}.npy', arrays)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ginn_env11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
