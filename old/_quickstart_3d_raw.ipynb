{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "## For setup\n",
    "import torch\n",
    "from configs.get_config import get_config_from_yml\n",
    "from GINN.shape_boundary_helper import ShapeBoundaryHelper\n",
    "from GINN.helpers.mp_manager import MPManager\n",
    "from GINN.helpers.timer_helper import TimerHelper\n",
    "from GINN.morse.scc_surfacenet_manager import SCCSurfaceNetManager\n",
    "from GINN.problem_sampler import ProblemSampler\n",
    "from GINN.visualize.plotter_3d import Plotter3d\n",
    "from train.train_utils.autoclip import AutoClip\n",
    "from utils import get_model, get_stateless_net_with_partials\n",
    "\n",
    "## For extracting and plotting a mesh\n",
    "import k3d\n",
    "from notebooks.notebook_utils import get_mesh_for_latent\n",
    "\n",
    "## For running a training loop\n",
    "import einops\n",
    "from tqdm import trange\n",
    "from models.model_utils import tensor_product_xz\n",
    "from train.losses import closest_shape_diversity_loss, eikonal_loss, envelope_loss, interface_loss, normal_loss_euclidean, obstacle_interior_loss, strain_curvature_loss\n",
    "from train.train_utils.latent_sampler import sample_new_z\n",
    "from utils import set_all_seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(5)\n",
    "## Set the device\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_device(device)\n",
    "\n",
    "## Read the config\n",
    "yml_path = '_quickstart/raw_config_3d.yml'\n",
    "config = get_config_from_yml(yml_path)\n",
    "config['device'] = device\n",
    "\n",
    "## Create the model and stateless functions and load a checkpoint\n",
    "model = get_model(config)\n",
    "netp = get_stateless_net_with_partials(model, use_x_and_z_arg=config['use_x_and_z_arg'])\n",
    "# model.load_state_dict(torch.load('_quickstart/trained_model_3d.pt', map_location=device))\n",
    "\n",
    "## Create different helpers for ...\n",
    "## ... the problem definition\n",
    "p_sampler = ProblemSampler(config)\n",
    "## ... multiprocessing to create plots on a non-blocking thread\n",
    "mp_manager = MPManager(config)\n",
    "## ... recording timings\n",
    "timer_helper = TimerHelper(config, lock=mp_manager.get_lock())\n",
    "mp_manager.set_timer_helper(timer_helper)  ## weak circular reference\n",
    "## ... plotting\n",
    "plotter = Plotter3d(config)\n",
    "## ... connectedness computation\n",
    "scc_manager = SCCSurfaceNetManager(config, netp, mp_manager, plotter, timer_helper, p_sampler, device)\n",
    "## ... sampling from the shape boundary\n",
    "shapeb_helper = ShapeBoundaryHelper(config, netp, mp_manager, plotter, timer_helper, p_sampler.sample_from_interface()[0], device)\n",
    "## ... clipping the gradients\n",
    "auto_clip = AutoClip(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fdd76fb44042b68f6ff00c24b2ddbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.tensor([-0.1])\n",
    "mesh_checkpoint = get_mesh_for_latent(netp.f_, netp.params_, z, config['bounds'], mc_resolution=128, device=device, chunks=1)\n",
    "\n",
    "fig = k3d.plot()\n",
    "fig += k3d.mesh(*mesh_checkpoint, color=0xff0000, side='double')\n",
    "fig.display()\n",
    "fig.camera_auto_fit = False\n",
    "fig.camera = [0.8042741481976844,\n",
    "            -1.040350835893895,\n",
    "            0.7038650223301532,\n",
    "            0.08252720725551285,\n",
    "            -0.08146462547370059,\n",
    "            -0.1973267630672968,\n",
    "            -0.3986658507677483,\n",
    "            0.39231188503442904,\n",
    "            0.8289492893370278]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial z: tensor([[-0.1000]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[33m          \u001b[0m| 0/10 [00:00<?, ?it/s]INFO:cp_helper:=== Recomputing the graph ===\n",
      "INFO:cp_helper:(0) SUCCESS\n",
      "Descending to CPs: 2.02e+02: 100%|██████████| 1000/1000 [00:13<00:00, 74.82it/s]\n",
      "INFO:cp_helper:(1) SUCCESS\n",
      "INFO:cp_helper:(2) FAIL: no good clusters\n",
      "Flow to surface points: 6.05e-03: 100%|██████████| 200/200 [00:01<00:00, 146.77it/s]\n",
      " 10%|\u001b[33m█         \u001b[0m| 1/10 [00:15<02:18, 15.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_env: 0.06626007705926895\n",
      "loss_if: 1.6091159582138062\n",
      "loss_if_normal: 5.4652464314131066e-05\n",
      "loss_obst: 0.0\n",
      "loss_eikonal: 1.6943101854849374e-07\n",
      "loss_scc: 0.0\n",
      "loss_curv: 0.0\n",
      "loss_div: 0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cp_helper:=== Recomputing the graph ===\n",
      "INFO:cp_helper:(0) SUCCESS\n",
      "Descending to CPs: 1.79e+02:   0%|          | 1/1000 [00:00<00:26, 37.79it/s]\n",
      "INFO:cp_helper:(1) FAIL: did not find any cp candidates\n",
      " 20%|\u001b[33m██        \u001b[0m| 2/10 [00:15<00:53,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_env: 0.046797942370176315\n",
      "loss_if: 0.18930093944072723\n",
      "loss_if_normal: 4.376908327685669e-05\n",
      "loss_obst: 0.0\n",
      "loss_eikonal: 1.577691364218481e-07\n",
      "loss_scc: 0.0\n",
      "loss_curv: 0.0\n",
      "loss_div: 0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cp_helper:=== Recomputing the graph ===\n",
      "INFO:cp_helper:(0) SUCCESS\n",
      "Descending to CPs: 1.76e+02:   0%|          | 1/1000 [00:00<00:12, 78.99it/s]\n",
      "INFO:cp_helper:(1) FAIL: did not find any cp candidates\n",
      " 30%|\u001b[33m███       \u001b[0m| 3/10 [00:16<00:27,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_env: 0.04378074035048485\n",
      "loss_if: 0.39341509342193604\n",
      "loss_if_normal: 3.987945456174202e-05\n",
      "loss_obst: 0.0\n",
      "loss_eikonal: 1.4855086760690028e-07\n",
      "loss_scc: 0.0\n",
      "loss_curv: 0.0\n",
      "loss_div: 0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cp_helper:=== Recomputing the graph ===\n",
      "INFO:cp_helper:(0) SUCCESS\n",
      "Descending to CPs: 1.73e+02:   0%|          | 1/1000 [00:00<00:08, 112.89it/s]\n",
      "INFO:cp_helper:(1) FAIL: did not find any cp candidates\n",
      " 40%|\u001b[33m████      \u001b[0m| 4/10 [00:17<00:15,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_env: 0.04236834496259689\n",
      "loss_if: 0.5095442533493042\n",
      "loss_if_normal: 3.30993025272619e-05\n",
      "loss_obst: 0.0\n",
      "loss_eikonal: 1.4863195474390523e-07\n",
      "loss_scc: 0.0\n",
      "loss_curv: 0.0\n",
      "loss_div: 0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cp_helper:=== Recomputing the graph ===\n",
      "INFO:cp_helper:(0) SUCCESS\n",
      "Descending to CPs: 1.63e+02:   0%|          | 1/1000 [00:00<00:26, 37.64it/s]\n",
      "INFO:cp_helper:(1) FAIL: did not find any cp candidates\n",
      " 50%|\u001b[33m█████     \u001b[0m| 5/10 [00:17<00:09,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_env: 0.03861580416560173\n",
      "loss_if: 0.3631066381931305\n",
      "loss_if_normal: 2.686792504391633e-05\n",
      "loss_obst: 0.0\n",
      "loss_eikonal: 1.4628092515067692e-07\n",
      "loss_scc: 0.0\n",
      "loss_curv: 0.0\n",
      "loss_div: 0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cp_helper:=== Recomputing the graph ===\n",
      "INFO:cp_helper:(0) SUCCESS\n",
      "Descending to CPs: 1.64e+02:   0%|          | 1/1000 [00:00<00:09, 108.17it/s]\n",
      "INFO:cp_helper:(1) FAIL: did not find any cp candidates\n",
      " 60%|\u001b[33m██████    \u001b[0m| 6/10 [00:18<00:05,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_env: 0.035059817135334015\n",
      "loss_if: 0.17542065680027008\n",
      "loss_if_normal: 2.1883442968828604e-05\n",
      "loss_obst: 0.0\n",
      "loss_eikonal: 1.382431946694851e-07\n",
      "loss_scc: 0.0\n",
      "loss_curv: 0.0\n",
      "loss_div: 0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cp_helper:=== Recomputing the graph ===\n",
      "INFO:cp_helper:(0) SUCCESS\n",
      "Descending to CPs: 1.59e+02:   0%|          | 1/1000 [00:00<00:07, 136.03it/s]\n",
      "INFO:cp_helper:(1) FAIL: did not find any cp candidates\n",
      " 70%|\u001b[33m███████   \u001b[0m| 7/10 [00:18<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_env: 0.03284372761845589\n",
      "loss_if: 0.11900916695594788\n",
      "loss_if_normal: 1.8996273865923285e-05\n",
      "loss_obst: 0.0\n",
      "loss_eikonal: 1.332030308276444e-07\n",
      "loss_scc: 0.0\n",
      "loss_curv: 0.0\n",
      "loss_div: 0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cp_helper:=== Recomputing the graph ===\n",
      "INFO:cp_helper:(0) SUCCESS\n",
      "Descending to CPs: 1.52e+02:   0%|          | 1/1000 [00:00<00:12, 79.08it/s]\n",
      "INFO:cp_helper:(1) FAIL: did not find any cp candidates\n",
      " 80%|\u001b[33m████████  \u001b[0m| 8/10 [00:19<00:01,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_env: 0.028973815962672234\n",
      "loss_if: 0.12858977913856506\n",
      "loss_if_normal: 1.7214237232110463e-05\n",
      "loss_obst: 0.0\n",
      "loss_eikonal: 1.3238374663160357e-07\n",
      "loss_scc: 0.0\n",
      "loss_curv: 0.0\n",
      "loss_div: 0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cp_helper:=== Recomputing the graph ===\n",
      "INFO:cp_helper:(0) SUCCESS\n",
      "Descending to CPs: 1.46e+02:   0%|          | 1/1000 [00:00<00:44, 22.27it/s]\n",
      "INFO:cp_helper:(1) FAIL: did not find any cp candidates\n",
      " 90%|\u001b[33m█████████ \u001b[0m| 9/10 [00:20<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_env: 0.028646066784858704\n",
      "loss_if: 0.10889074951410294\n",
      "loss_if_normal: 1.585815152793657e-05\n",
      "loss_obst: 0.0\n",
      "loss_eikonal: 1.256674124761048e-07\n",
      "loss_scc: 0.0\n",
      "loss_curv: 0.0\n",
      "loss_div: 0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cp_helper:=== Recomputing the graph ===\n",
      "INFO:cp_helper:(0) SUCCESS\n",
      "Descending to CPs: 1.42e+02:   0%|          | 1/1000 [00:00<00:13, 72.97it/s]\n",
      "INFO:cp_helper:(1) FAIL: did not find any cp candidates\n",
      "100%|\u001b[33m██████████\u001b[0m| 10/10 [00:20<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_env: 0.02672136388719082\n",
      "loss_if: 0.06999719887971878\n",
      "loss_if_normal: 1.4765311789233238e-05\n",
      "loss_obst: 0.0\n",
      "loss_eikonal: 1.2534903248706541e-07\n",
      "loss_scc: 0.0\n",
      "loss_curv: 0.0\n",
      "loss_div: 0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_loss_items = 0\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "# opt.load_state_dict(torch.load('_quickstart/opt_3d.pt', map_location=device))\n",
    "z = sample_new_z(config, is_init=True)\n",
    "print(f'Initial z: {z}')\n",
    "p_surface = None\n",
    "cur_plot_epoch = 0\n",
    "plots_dict_at_last_epoch = None\n",
    "log_history_dict = {}\n",
    "for epoch in (pbar := trange(config['max_epochs'], leave=True, position=0, colour=\"yellow\")):\n",
    "    mp_manager.update_epoch(epoch)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    plotter.reset_output(p_sampler.recalc_output(netp.f_, netp.params_, z), epoch=epoch)\n",
    "    plotter.plot_shape(p_sampler.constr_pts_dict)\n",
    "    \n",
    "    loss_scc = torch.tensor(0.0)\n",
    "    if config['lambda_scc'] > 0:\n",
    "        success, res_tup = scc_manager.get_scc_pts_to_penalize(z, epoch)\n",
    "        if success:\n",
    "            p_penalize, p_penalties = res_tup\n",
    "            print(f'penalize DCs with {len(p_penalize)} points')\n",
    "            y_saddles_opt = model(p_penalize.data, p_penalize.z_in(z)).squeeze(1)\n",
    "            loss_scc = config['lambda_scc'] *  (y_saddles_opt * p_penalties.data).mean()\n",
    "\n",
    "    ## Design region loss                \n",
    "    loss_env = torch.tensor(0.0)\n",
    "    if config['lambda_env'] > 0:\n",
    "        ys_env = model(*tensor_product_xz(p_sampler.sample_from_envelope(), z)).squeeze(1)\n",
    "        loss_env = config['lambda_env'] * envelope_loss(ys_env)\n",
    "\n",
    "    ## Interface loss\n",
    "    loss_if = torch.tensor(0.0)\n",
    "    if config['lambda_bc'] > 0:\n",
    "        ys_BC = model(*tensor_product_xz(p_sampler.sample_from_interface()[0], z)).squeeze(1)\n",
    "        loss_if = config['lambda_bc'] * interface_loss(ys_BC)\n",
    "        \n",
    "    ## Interface normal loss\n",
    "    loss_if_normal = torch.tensor(0.0)\n",
    "    if config['lambda_normal'] > 0:\n",
    "        pts_normal, target_normal = p_sampler.sample_from_interface()\n",
    "        ys_normal = netp.vf_x(*tensor_product_xz(pts_normal, z)).squeeze(1)\n",
    "        loss_if_normal = config['lambda_normal'] * normal_loss_euclidean(ys_normal, torch.cat([target_normal for _ in range(config['batch_size'])]))\n",
    "\n",
    "    ## Obstacle loss (for debugging purposes, it's not considered part of the envelope) TODO: do we leave it like this?\n",
    "    loss_obst = torch.tensor(0.0)\n",
    "    if config['lambda_obst'] > 0:\n",
    "        ys_obst = model(*tensor_product_xz(p_sampler.sample_from_obstacles(), z))\n",
    "        loss_obst = config['lambda_obst'] * obstacle_interior_loss(ys_obst)\n",
    "\n",
    "    ## Sample points from the domain if necessary TODO: I think diversity doesnt need domain points anymore? TODO: can we move this up so that all the losses come after each other?\n",
    "    if config['lambda_eikonal'] > 0 or config['lambda_div'] > 0:\n",
    "        xs_domain = p_sampler.sample_from_domain()\n",
    "\n",
    "    ## Eikonal loss    \n",
    "    loss_eikonal = torch.tensor(0.0)\n",
    "    if config['lambda_eikonal'] > 0:\n",
    "        y_x_eikonal = netp.vf_x(*tensor_product_xz(xs_domain, z))\n",
    "        loss_eikonal = config['lambda_eikonal'] * eikonal_loss(y_x_eikonal)\n",
    "\n",
    "    ## Sample points from the 0-levelset if necessary TODO: can we move this up?\n",
    "    if config['lambda_div'] > 0 or config['lambda_curv'] > 0:\n",
    "        if p_surface is None or epoch % config['recompute_surface_pts_every_n_epochs'] == 0:\n",
    "            p_surface, weights_surf_pts = shapeb_helper.get_surface_pts(z)\n",
    "    \n",
    "    ## Curvature loss\n",
    "    loss_curv = torch.tensor(0.0)\n",
    "    if config['lambda_curv'] > 0:\n",
    "        if p_surface is None:\n",
    "            print('No surface points found - skipping curvature loss')\n",
    "        else:\n",
    "            y_x_surf = netp.vf_x(p_surface.data, p_surface.z_in(z)).squeeze(1)\n",
    "            y_xx_surf = netp.vf_xx(p_surface.data, p_surface.z_in(z)).squeeze(1)\n",
    "            loss_curv = config['lambda_curv'] * strain_curvature_loss(y_x_surf, y_xx_surf, clip_max_value=config['strain_curvature_clip_max'],\n",
    "                                                                            weights=weights_surf_pts)\n",
    "    ## Diversity loss\n",
    "    loss_div = torch.tensor(0.0)\n",
    "    if config['lambda_div'] > 0 and config['batch_size'] > 1:\n",
    "        if p_surface is None:\n",
    "            print('No surface points found - skipping diversity loss')\n",
    "        else:\n",
    "            y_div = model(*tensor_product_xz(p_surface.data, z)).squeeze(1)  # [(bz k)] whereas k is n_surface_points; evaluate model at all surface points for each shape\n",
    "            loss_div = config['lambda_div'] * closest_shape_diversity_loss(einops.rearrange(y_div, '(bz k)-> bz k', bz=config['batch_size']), \n",
    "                                                                                weights=weights_surf_pts)\n",
    "            if torch.isnan(loss_div) or torch.isinf(loss_div):\n",
    "                print(f'NaN or Inf loss_div: {loss_div}')\n",
    "                loss_div = torch.tensor(0.0) if torch.isnan(loss_div) or torch.isinf(loss_div) else loss_div \n",
    "\n",
    "    loss = loss_env + loss_if + loss_if_normal + loss_obst + loss_eikonal + loss_scc + loss_curv + loss_div\n",
    "    print(f'loss_env: {loss_env}')\n",
    "    print(f'loss_if: {loss_if}')\n",
    "    print(f'loss_if_normal: {loss_if_normal}')\n",
    "    print(f'loss_obst: {loss_obst}')\n",
    "    print(f'loss_eikonal: {loss_eikonal}')\n",
    "    print(f'loss_scc: {loss_scc}')\n",
    "    print(f'loss_curv: {loss_curv}')\n",
    "    print(f'loss_div: {loss_div}')\n",
    "    \n",
    "    ## Gradients with clipping\n",
    "    loss.backward()\n",
    "    grad_norm = auto_clip.grad_norm(model.parameters())\n",
    "    if auto_clip.grad_clip_enabled:\n",
    "        auto_clip.update_gradient_norm_history(grad_norm)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), auto_clip.get_clip_value())\n",
    "        \n",
    "    ## Update the parameters\n",
    "    opt.step()\n",
    "\n",
    "    total_loss_items += loss_scc.item()\n",
    "    \n",
    "    ## Look at debugging plots\n",
    "    ## For this you have to enable plots in the config; note: this will slow down the training\n",
    "    # if mp_manager.are_plots_available_for_epoch(epoch):\n",
    "    #     plots_dict_at_last_epoch = mp_manager.pop_plots_dict(epoch)\n",
    "\n",
    "    print(total_loss_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the updated and the old mesh\n",
    "The old mesh is red, the new one in green. In the \"K3D Panel\" of the plot you can click on \"Objects\". If you want to do make the updated shape visible, you can click the \"visible\" tickbox of the according shape. This way you can see the difference in the updates better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a71d276ddb4471b39243121e36604d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## NOTE: 8GB is not enough CUDA memory to perform marching cubes after training. Maybe we release some tensors? Alt: I would love to understand what these tensors\n",
    "## TODO: smaller update?\n",
    "\n",
    "z = torch.tensor([-0.1])\n",
    "mesh_update = get_mesh_for_latent(netp.f_, netp.params_, z, config['bounds'], mc_resolution=128, device=device, chunks=1)\n",
    "\n",
    "fig = k3d.plot()\n",
    "fig += k3d.mesh(*mesh_checkpoint, color=0xff0000, side='double', opacity=0.5, name='Original shape')\n",
    "fig += k3d.mesh(*mesh_update, color=0x00ff00, side='double', opacity=0.5, name='Updated shape')\n",
    "fig.display()\n",
    "fig.camera_auto_fit = False\n",
    "fig.camera = [0.8042741481976844,\n",
    "            -1.040350835893895,\n",
    "            0.7038650223301532,\n",
    "            0.08252720725551285,\n",
    "            -0.08146462547370059,\n",
    "            -0.1973267630672968,\n",
    "            -0.3986658507677483,\n",
    "            0.39231188503442904,\n",
    "            0.8289492893370278]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access plots of the last training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plots_dict_at_last_epoch is not None:\n",
    "    # check if variable is set\n",
    "    print(f'Available plot keys:')\n",
    "    for k in sorted(plots_dict_at_last_epoch.keys()):\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plots_dict_at_last_epoch is not None:\n",
    "    plot_key = 'Characterized critical points'\n",
    "    plots_dict_at_last_epoch[plot_key].display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
